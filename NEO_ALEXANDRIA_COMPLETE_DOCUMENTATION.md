# Neo Alexandria 2.0 - Complete Documentation

**Generated:** December 28, 2025 at 08:19:49

---

# Table of Contents

1. [Agent Context Management](#agent-context-management)
2. [Product Overview](#product-overview)
3. [Technical Stack](#technical-stack)
4. [Repository Structure](#repository-structure)
5. [Backend Documentation Index](#backend-documentation-index)
6. [API Overview](#api-overview)
7. [Resources API](#resources-api)
8. [Search API](#search-api)
9. [Collections API](#collections-api)
10. [Annotations API](#annotations-api)
11. [Taxonomy API](#taxonomy-api)
12. [Graph API](#graph-api)
13. [Recommendations API](#recommendations-api)
14. [Quality API](#quality-api)
15. [Scholarly API](#scholarly-api)
16. [Authority API](#authority-api)
17. [Curation API](#curation-api)
18. [Monitoring API](#monitoring-api)
19. [Architecture Overview](#architecture-overview)
20. [Database Architecture](#database-architecture)
21. [Event System](#event-system)
22. [Event Catalog](#event-catalog)
23. [Module Architecture](#module-architecture)
24. [Architecture Decisions](#architecture-decisions)
25. [Setup Guide](#setup-guide)
26. [Development Workflows](#development-workflows)
27. [Testing Guide](#testing-guide)
28. [Deployment Guide](#deployment-guide)
29. [Troubleshooting](#troubleshooting)
30. [Backend Overview](#backend-overview)

---



# 1. Agent Context Management

*Source: `AGENTS.md`*

---

# Agent Context Management

## Purpose

This document provides routing rules for AI agents working with Neo Alexandria 2.0. It ensures efficient context usage and points to the right documentation.

## Token Hygiene Rules

1. **Never load entire files** unless explicitly needed for the current task
2. **Use targeted reads** with line ranges when possible
3. **Reference documentation** by path rather than loading it
4. **Close completed specs** - archive or mark as done when features are implemented
5. **Rotate context** - only keep active work in focus

## Documentation Structure

```
AGENTS.md (this file)          # Routing and hygiene rules
.kiro/steering/
  â”œâ”€â”€ product.md               # Product vision and goals
  â”œâ”€â”€ tech.md                  # Tech stack and constraints
  â””â”€â”€ structure.md             # Repo map and truth sources
.kiro/specs/
  â”œâ”€â”€ [feature-name]/          # Active feature specs
  â”‚   â”œâ”€â”€ requirements.md
  â”‚   â”œâ”€â”€ design.md
  â”‚   â””â”€â”€ tasks.md
  â””â”€â”€ README.md                # Spec organization
backend/docs/
  â”œâ”€â”€ index.md                 # Documentation index
  â”œâ”€â”€ api/                     # API reference (split by domain)
  â”œâ”€â”€ architecture/            # System architecture
  â””â”€â”€ guides/                  # Developer guides
frontend/                      # Frontend-specific docs
```

## Finding the Right Documentation

### For Product Questions
â†’ Read `.kiro/steering/product.md`

### For Tech Stack Questions
â†’ Read `.kiro/steering/tech.md`

### For Repo Navigation
â†’ Read `.kiro/steering/structure.md`

### For Feature Work
â†’ Read `.kiro/specs/[feature-name]/requirements.md` and `design.md`

### For API Documentation
â†’ Read `backend/docs/index.md` then navigate to specific domain
â†’ Example: `backend/docs/api/search.md` for search endpoints

### For Architecture Details
â†’ Read `backend/docs/architecture/overview.md`
â†’ Example: `backend/docs/architecture/database.md` for schema

### For Development Guides
â†’ Read `backend/docs/guides/setup.md` for getting started
â†’ Example: `backend/docs/guides/testing.md` for test strategies

## Working with Specs

### Active Specs Only
Only load specs that are:
- Currently being worked on
- Explicitly requested by the user
- Needed for context on current task

### Completed Specs
Specs in `.kiro/specs/` that are fully implemented should be:
- Marked as complete in their README
- Referenced by path only (not loaded)
- Archived if no longer relevant

### Creating New Specs
Follow the spec workflow:
1. Create `.kiro/specs/[feature-name]/` directory
2. Write `requirements.md` first
3. Then `design.md`
4. Finally `tasks.md`
5. Execute tasks incrementally

## Context Budget Guidelines

- **Small tasks** (<5 files): Load files directly
- **Medium tasks** (5-15 files): Load selectively, reference others
- **Large tasks** (>15 files): Use structure.md as map, load only what's needed
- **Exploratory work**: Start with structure.md, drill down as needed

## Quick Reference

| Need | Read |
|------|------|
| What is this project? | `.kiro/steering/product.md` |
| What tech do we use? | `.kiro/steering/tech.md` |
| Where is X located? | `.kiro/steering/structure.md` |
| How do I implement Y? | `.kiro/specs/[feature]/design.md` |
| What's the API? | `backend/docs/index.md` â†’ `api/` |
| What's the architecture? | `backend/docs/architecture/overview.md` |
| How do I set up dev env? | `backend/docs/guides/setup.md` |
| How do I test? | `backend/docs/guides/testing.md` |

## Anti-Patterns to Avoid

âŒ Loading all specs at once
âŒ Reading entire backend/README.md for simple questions
âŒ Loading documentation "just in case"
âŒ Keeping completed spec context open
âŒ Reading files without a specific purpose

âœ… Load only what's needed for current task
âœ… Use structure.md as a map
âœ… Reference docs by path
âœ… Close completed work
âœ… Ask user if unsure what's needed


<div style='page-break-after: always;'></div>

---



# 2. Product Overview

*Source: `.kiro/steering/product.md`*

---

# Neo Alexandria 2.0 - Product Overview

## Purpose

Neo Alexandria 2.0 is an advanced knowledge management system that combines traditional information retrieval with modern AI-powered features to deliver intelligent content processing, advanced search, and personalized recommendations.

## Target Users

1. **Researchers** - Academic and industry researchers managing papers, articles, and datasets
2. **Knowledge Workers** - Professionals curating domain-specific knowledge bases
3. **Students** - Learners organizing study materials and research
4. **Teams** - Collaborative knowledge management for organizations

## Core Value Propositions

### Intelligent Content Processing
- Automatic summarization, tagging, and classification
- Quality assessment and metadata extraction
- Multi-format support (HTML, PDF, plain text)

### Advanced Discovery
- Hybrid search combining keyword and semantic approaches
- Knowledge graph for relationship exploration
- Citation network analysis
- Personalized recommendations

### Active Reading & Annotation
- Precise text highlighting with notes
- Semantic search across annotations
- Export to external tools (Markdown, JSON)

### Organization & Curation
- Flexible collection management
- Hierarchical taxonomy
- Quality-based filtering
- Batch operations

## Non-Goals

### What We Are NOT Building

âŒ **Social Network** - No user profiles, followers, or social features
âŒ **Content Creation Platform** - No authoring tools or publishing workflows
âŒ **File Storage Service** - No general-purpose file hosting
âŒ **Real-time Collaboration** - No simultaneous editing or live cursors
âŒ **Mobile Apps** - Web-first, responsive design only
âŒ **Enterprise SSO** - Simple authentication only
âŒ **Multi-tenancy** - Single-user or small team focus
âŒ **Blockchain/Web3** - Traditional database architecture
âŒ **Video/Audio Processing** - Text and document focus only

## Product Principles

1. **API-First** - All features accessible via RESTful API
2. **Privacy-Focused** - User data stays local or self-hosted
3. **Open Source** - Transparent, extensible, community-driven
4. **Performance** - Fast response times (<200ms for most operations)
5. **Simplicity** - Clean interfaces, minimal configuration
6. **Extensibility** - Plugin architecture for custom features

## Success Metrics

- **Search Quality**: nDCG > 0.7 for hybrid search
- **Response Time**: P95 < 200ms for API endpoints
- **Classification Accuracy**: > 85% for ML taxonomy
- **User Satisfaction**: Qualitative feedback from early adopters
- **System Reliability**: 99.9% uptime for self-hosted deployments

## Roadmap Themes

### Current Focus (Phase 13-14)
- PostgreSQL migration for production scalability
- Test suite stabilization
- Vertical slice architecture refactoring
- Frontend-backend integration

### Near-term (Next 3-6 months)
- Enhanced ML classification with active learning
- Advanced graph intelligence features
- Improved recommendation algorithms
- Performance optimization

### Long-term Vision
- Multi-language support
- Advanced visualization tools
- Plugin ecosystem
- Community-contributed models


<div style='page-break-after: always;'></div>

---



# 3. Technical Stack

*Source: `.kiro/steering/tech.md`*

---

# Neo Alexandria 2.0 - Technical Stack

## Architecture

**Type**: Modular Monolith with Event-Driven Communication
**Pattern**: Vertical slices with shared kernel
**Deployment**: Self-hosted, containerized

### Architectural Principles

1. **Vertical Slice Architecture**: Each module is self-contained with its own models, schemas, services, and routes
2. **Event-Driven Communication**: Modules communicate via event bus (no direct imports)
3. **Shared Kernel**: Cross-cutting concerns (database, cache, embeddings, AI) in shared layer
4. **Zero Circular Dependencies**: Enforced by module isolation rules
5. **API-First Design**: All functionality exposed via REST API

### Module Structure

**13 Domain Modules**:
- Annotations, Authority, Collections, Curation, Graph
- Monitoring, Quality, Recommendations, Resources, Scholarly
- Search, Taxonomy

**Each Module Contains**:
- `router.py` - FastAPI endpoints
- `service.py` - Business logic
- `schema.py` - Pydantic models
- `model.py` - SQLAlchemy models
- `handlers.py` - Event handlers
- `README.md` - Documentation

**Shared Kernel**:
- Database session management
- Event bus (in-memory, async)
- Vector embeddings
- AI operations (summarization, extraction)
- Redis caching

### Event-Driven Communication

**Event Bus**: In-memory, async, <1ms latency (p95)

**Event Categories**:
- Resource lifecycle: `resource.created`, `resource.updated`, `resource.deleted`
- Collections: `collection.created`, `collection.resource_added`
- Annotations: `annotation.created`, `annotation.updated`, `annotation.deleted`
- Quality: `quality.computed`, `quality.outlier_detected`
- Classification: `resource.classified`, `taxonomy.model_trained`
- Graph: `citation.extracted`, `graph.updated`, `hypothesis.discovered`
- Recommendations: `recommendation.generated`, `user.profile_updated`
- Curation: `curation.reviewed`, `curation.approved`
- Metadata: `metadata.extracted`, `equations.parsed`, `tables.extracted`

**Event Flow Example**:
```
1. User creates resource â†’ resources module emits resource.created
2. Quality module subscribes â†’ computes quality scores
3. Taxonomy module subscribes â†’ auto-classifies resource
4. Scholarly module subscribes â†’ extracts metadata
5. Graph module subscribes â†’ extracts citations
6. All happen asynchronously, no blocking
```

## Backend Stack

### Core Framework
- **Python 3.8+** - Primary language
- **FastAPI** - Web framework for REST API
- **Uvicorn** - ASGI server
- **Pydantic** - Data validation and serialization

### Database
- **SQLite** - Development and small deployments
- **PostgreSQL 15+** - Production deployments
- **Alembic** - Database migrations
- **SQLAlchemy 2.0** - ORM with async support

### AI/ML
- **Transformers (Hugging Face)** - NLP models
- **PyTorch** - Deep learning framework
- **Sentence-Transformers** - Embedding generation
- **FAISS** - Vector similarity search
- **spaCy** - NLP processing

### Task Processing
- **Celery** - Async task queue
- **Redis** - Cache and message broker

### Testing
- **pytest** - Test framework
- **pytest-asyncio** - Async test support
- **pytest-cov** - Coverage reporting
- **hypothesis** - Property-based testing (planned)

## Frontend Stack

### Core Framework
- **React 18** - UI library
- **TypeScript 5** - Type safety
- **Vite 5** - Build tool and dev server

### Routing & State
- **React Router 6** - Client-side routing
- **Zustand** - Lightweight state management
- **React Query** - Server state management

### Styling
- **CSS Modules** - Component styling
- **Tailwind CSS** - Utility-first CSS
- **Framer Motion** - Animations

### Testing
- **Vitest** - Unit testing
- **React Testing Library** - Component testing

## Development Tools

### Code Quality
- **Ruff** - Python linter and formatter
- **ESLint** - JavaScript/TypeScript linter
- **Prettier** - Code formatter
- **pre-commit** - Git hooks for quality checks

### Version Control
- **Git** - Source control
- **GitHub** - Repository hosting
- **GitHub Actions** - CI/CD pipelines

### Containerization
- **Docker** - Container runtime
- **Docker Compose** - Multi-container orchestration

## Key Constraints

### Performance Requirements
- API response time: P95 < 200ms
- Search latency: < 500ms for hybrid search
- Embedding generation: < 2s per document
- Database queries: < 100ms for most operations
- Event emission + delivery: < 1ms (p95)
- Module startup: < 10 seconds total

### Scalability Targets
- 100K+ resources in database
- 10K+ concurrent embeddings
- 1K+ collections per user
- 100+ requests/second

### Resource Limits
- Memory: 4GB minimum, 8GB recommended
- Storage: 10GB minimum for models and data
- CPU: 2+ cores recommended
- GPU: Optional, improves ML performance 10x

## Database Strategy

### SQLite (Development)
```bash
DATABASE_URL=sqlite:///./backend.db
```
- Zero configuration
- File-based, portable
- Limited concurrency
- No advanced features

### PostgreSQL (Production)
```bash
DATABASE_URL=postgresql://user:pass@host:5432/db
```
- High concurrency
- JSONB support
- Full-text search
- Advanced indexing
- Connection pooling

### Migration Path
- Maintain SQLite compatibility
- Test against both databases
- Use Alembic for schema changes
- Provide migration scripts

## Common Commands

### Backend Development
```bash
# Start dev server
cd backend
uvicorn app.main:app --reload

# Run migrations
alembic upgrade head

# Run tests
pytest tests/ -v

# Run module-specific tests
pytest tests/modules/test_resources_endpoints.py -v

# Run with coverage
pytest tests/ --cov=app --cov-report=html

# Lint and format
ruff check .
ruff format .

# Check module isolation
python scripts/check_module_isolation.py

# Verify all modules load
python test_app_startup.py
```

### Module Development
```bash
# Create new module structure
mkdir -p app/modules/mymodule
touch app/modules/mymodule/{__init__.py,router.py,service.py,schema.py,model.py,handlers.py,README.md}

# Register module in main.py
# Add to register_all_modules() function

# Test module endpoints
pytest tests/modules/test_mymodule_endpoints.py -v

# Verify module isolation
python scripts/check_module_isolation.py
```

### Frontend Development
```bash
# Start dev server
cd frontend
npm run dev

# Build for production
npm run build

# Run tests
npm test

# Lint
npm run lint
```

### Docker
```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Rebuild
docker-compose up -d --build
```

### Database
```bash
# Create migration
cd backend
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# Backup SQLite
cp backend.db backend.db.backup

# Backup PostgreSQL
pg_dump -U user -d database > backup.sql
```

## Environment Variables

### Required
```bash
DATABASE_URL=sqlite:///./backend.db
```

### Optional (with defaults)
```bash
# AI Models
EMBEDDING_MODEL_NAME=nomic-ai/nomic-embed-text-v1
SUMMARIZER_MODEL=facebook/bart-large-cnn

# Search
DEFAULT_HYBRID_SEARCH_WEIGHT=0.5
EMBEDDING_CACHE_SIZE=1000

# Graph
GRAPH_WEIGHT_VECTOR=0.6
GRAPH_WEIGHT_TAGS=0.3
GRAPH_WEIGHT_CLASSIFICATION=0.1

# Testing
TEST_DATABASE_URL=sqlite:///:memory:
```

## API Standards

### REST Conventions
- Use standard HTTP methods (GET, POST, PUT, DELETE)
- Return appropriate status codes (200, 201, 400, 404, 500)
- Use JSON for request/response bodies
- Include pagination for list endpoints
- Provide filtering and sorting options

### Response Format
```json
{
  "data": {},
  "meta": {
    "total": 100,
    "page": 1,
    "per_page": 25
  }
}
```

### Error Format
```json
{
  "detail": "Error description",
  "error_code": "VALIDATION_ERROR",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

## Security Considerations

- Input validation with Pydantic
- SQL injection prevention via ORM
- XSS protection in frontend
- CORS configuration for API
- Rate limiting (planned)
- API key authentication (planned)

## Monitoring & Observability

- Structured logging with JSON format
- Health check endpoints per module
- Database connection pool monitoring
- ML model performance tracking
- Event bus metrics (throughput, latency)
- Module dependency graph validation
- Error tracking and alerting (planned)

## Module Isolation Rules

### Allowed Imports
âœ… Modules can import from:
- `app.shared.*` - Shared kernel only
- `app.events.*` - Event system
- `app.domain.*` - Domain objects
- Standard library and third-party packages

### Forbidden Imports
âŒ Modules CANNOT import from:
- Other modules (`app.modules.*`)
- Legacy layers (`app.routers.*`, `app.services.*`, `app.schemas.*`)

### Communication Pattern
- **Direct calls**: Use shared kernel services
- **Cross-module**: Use event bus only
- **Example**: Quality module needs resource data â†’ subscribe to `resource.created` event

### Validation
```bash
# Check all modules for violations
python scripts/check_module_isolation.py

# Generates dependency graph
# Fails if circular dependencies or direct module imports found
```

### CI/CD Integration
- Module isolation checker runs on every commit
- Build fails if violations detected
- Dependency graph generated and archived


<div style='page-break-after: always;'></div>

---



# 4. Repository Structure

*Source: `.kiro/steering/structure.md`*

---

# Neo Alexandria 2.0 - Repository Structure

## Repository Map

```
neo-alexandria-2.0/
â”œâ”€â”€ AGENTS.md                          # Agent routing and context rules
â”œâ”€â”€ .kiro/                             # Kiro IDE configuration
â”‚   â”œâ”€â”€ steering/                      # Project steering docs
â”‚   â”‚   â”œâ”€â”€ product.md                 # Product vision and goals
â”‚   â”‚   â”œâ”€â”€ tech.md                    # Tech stack and constraints
â”‚   â”‚   â””â”€â”€ structure.md               # This file
â”‚   â””â”€â”€ specs/                         # Feature specifications
â”‚       â”œâ”€â”€ backend/                   # Backend feature specs (21)
â”‚       â”œâ”€â”€ frontend/                  # Frontend feature specs (6)
â”‚       â””â”€â”€ README.md                  # Spec organization guide
â”œâ”€â”€ backend/                           # Python/FastAPI backend
â”‚   â”œâ”€â”€ app/                           # Application code
â”‚   â”‚   â”œâ”€â”€ modules/                   # Vertical slice modules (13 total)
â”‚   â”‚   â”‚   â”œâ”€â”€ annotations/           # Text highlights and notes
â”‚   â”‚   â”‚   â”œâ”€â”€ authority/             # Subject authority trees
â”‚   â”‚   â”‚   â”œâ”€â”€ collections/           # Collection management
â”‚   â”‚   â”‚   â”œâ”€â”€ curation/              # Content review
â”‚   â”‚   â”‚   â”œâ”€â”€ graph/                 # Knowledge graph and citations
â”‚   â”‚   â”‚   â”œâ”€â”€ monitoring/            # System health and metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ quality/               # Quality assessment
â”‚   â”‚   â”‚   â”œâ”€â”€ recommendations/       # Hybrid recommendations
â”‚   â”‚   â”‚   â”œâ”€â”€ resources/             # Resource CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ scholarly/             # Academic metadata
â”‚   â”‚   â”‚   â”œâ”€â”€ search/                # Hybrid search
â”‚   â”‚   â”‚   â””â”€â”€ taxonomy/              # ML classification
â”‚   â”‚   â”œâ”€â”€ shared/                    # Shared kernel
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py            # Database sessions
â”‚   â”‚   â”‚   â”œâ”€â”€ event_bus.py           # Event system
â”‚   â”‚   â”‚   â”œâ”€â”€ base_model.py          # Base models
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py          # Vector embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ ai_core.py             # AI operations
â”‚   â”‚   â”‚   â””â”€â”€ cache.py               # Redis cache
â”‚   â”‚   â”œâ”€â”€ database/                  # Database models and config
â”‚   â”‚   â”œâ”€â”€ domain/                    # Domain objects
â”‚   â”‚   â”œâ”€â”€ events/                    # Event system
â”‚   â”‚   â””â”€â”€ main.py                    # FastAPI app entry point
â”‚   â”œâ”€â”€ tests/                         # Test suite
â”‚   â”‚   â”œâ”€â”€ unit/                      # Unit tests
â”‚   â”‚   â”œâ”€â”€ integration/               # Integration tests
â”‚   â”‚   â”œâ”€â”€ performance/               # Performance tests
â”‚   â”‚   â””â”€â”€ conftest.py                # Pytest configuration
â”‚   â”œâ”€â”€ docs/                          # Technical documentation
â”‚   â”‚   â”œâ”€â”€ index.md                   # Documentation hub
â”‚   â”‚   â”œâ”€â”€ api/                       # API reference (modular)
â”‚   â”‚   â”‚   â”œâ”€â”€ overview.md            # Base URL, auth, errors
â”‚   â”‚   â”‚   â”œâ”€â”€ resources.md           # Resource endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ search.md              # Search endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ collections.md         # Collection endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ annotations.md         # Annotation endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ taxonomy.md            # Taxonomy endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.md               # Graph/citation endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ recommendations.md     # Recommendation endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ quality.md             # Quality endpoints
â”‚   â”‚   â”‚   â””â”€â”€ monitoring.md          # Health/monitoring endpoints
â”‚   â”‚   â”œâ”€â”€ architecture/              # Architecture documentation
â”‚   â”‚   â”‚   â”œâ”€â”€ overview.md            # System architecture
â”‚   â”‚   â”‚   â”œâ”€â”€ database.md            # Schema and models
â”‚   â”‚   â”‚   â”œâ”€â”€ event-system.md        # Event bus
â”‚   â”‚   â”‚   â”œâ”€â”€ modules.md             # Vertical slices
â”‚   â”‚   â”‚   â””â”€â”€ decisions.md           # ADRs
â”‚   â”‚   â”œâ”€â”€ guides/                    # Developer guides
â”‚   â”‚   â”‚   â”œâ”€â”€ setup.md               # Installation
â”‚   â”‚   â”‚   â”œâ”€â”€ workflows.md           # Development tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ testing.md             # Testing strategies
â”‚   â”‚   â”‚   â”œâ”€â”€ deployment.md          # Docker/production
â”‚   â”‚   â”‚   â””â”€â”€ troubleshooting.md     # FAQ and issues
â”‚   â”‚   â”œâ”€â”€ POSTGRESQL_MIGRATION_GUIDE.md
â”‚   â”‚   â””â”€â”€ ...                        # Other technical docs
â”‚   â”œâ”€â”€ scripts/                       # Utility scripts
â”‚   â”‚   â”œâ”€â”€ training/                  # ML training scripts
â”‚   â”‚   â”œâ”€â”€ evaluation/                # Evaluation scripts
â”‚   â”‚   â””â”€â”€ deployment/                # Deployment scripts
â”‚   â”œâ”€â”€ alembic/                       # Database migrations
â”‚   â”œâ”€â”€ requirements.txt               # Python dependencies
â”‚   â””â”€â”€ README.md                      # Backend overview
â”œâ”€â”€ frontend/                          # React/TypeScript frontend
â”‚   â”œâ”€â”€ src/                           # Source code
â”‚   â”‚   â”œâ”€â”€ components/                # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ features/              # Feature components
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/                    # UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ layout/                # Layout components
â”‚   â”‚   â”‚   â””â”€â”€ common/                # Common components
â”‚   â”‚   â”œâ”€â”€ lib/                       # Utilities and helpers
â”‚   â”‚   â”‚   â”œâ”€â”€ api/                   # API client
â”‚   â”‚   â”‚   â”œâ”€â”€ hooks/                 # Custom React hooks
â”‚   â”‚   â”‚   â””â”€â”€ utils/                 # Utility functions
â”‚   â”‚   â”œâ”€â”€ styles/                    # Global styles
â”‚   â”‚   â”œâ”€â”€ types/                     # TypeScript types
â”‚   â”‚   â””â”€â”€ App.tsx                    # App entry point
â”‚   â”œâ”€â”€ package.json                   # Node dependencies
â”‚   â””â”€â”€ README.md                      # Frontend overview
â””â”€â”€ docker/                            # Docker configuration
    â”œâ”€â”€ docker-compose.yml             # Multi-container setup
    â””â”€â”€ Dockerfile                     # Container image
```

## Truth Sources

### Product & Vision
**Source**: `.kiro/steering/product.md`
- Product purpose and goals
- Target users
- Non-goals and boundaries
- Success metrics

### Technical Stack
**Source**: `.kiro/steering/tech.md`
- Technology choices
- Development tools
- Common commands
- Environment variables

### API Reference
**Source**: `backend/docs/api/` (modular structure)
- `overview.md` - Base URL, authentication, error handling
- `resources.md` - Resource CRUD endpoints
- `search.md` - Search and hybrid search endpoints
- `collections.md` - Collection management endpoints
- `annotations.md` - Annotation endpoints
- `taxonomy.md` - Taxonomy and classification endpoints
- `graph.md` - Knowledge graph and citation endpoints
- `recommendations.md` - Recommendation endpoints
- `quality.md` - Quality assessment endpoints
- `monitoring.md` - Health and monitoring endpoints

### Architecture
**Source**: `backend/docs/architecture/` (modular structure)
- `overview.md` - High-level system architecture
- `database.md` - Schema, models, migrations
- `event-system.md` - Event bus and handlers
- `modules.md` - Vertical slice module structure
- `decisions.md` - Architecture decision records

### Developer Guides
**Source**: `backend/docs/guides/` (modular structure)
- `setup.md` - Installation and environment setup
- `workflows.md` - Common development tasks
- `testing.md` - Testing strategies and patterns
- `deployment.md` - Docker and production deployment
- `troubleshooting.md` - Common issues and FAQ

### Database Schema
**Source**: `backend/alembic/versions/`
- Migration history
- Schema changes
- Current schema state

### Feature Specifications
**Source**: `.kiro/specs/[feature-name]/`
- Requirements (user stories, acceptance criteria)
- Design (technical architecture)
- Tasks (implementation checklist)

## Key Directories Explained

### Backend Modules (`backend/app/modules/`)

**Purpose**: Vertical slice architecture for feature isolation

Each module contains:
- `model.py` - Database models
- `schema.py` - Pydantic schemas
- `service.py` - Business logic
- `router.py` - API endpoints
- `handlers.py` - Event handlers
- `README.md` - Module documentation

**Complete Module List (13 modules)**:
- `annotations/` - Text highlights, notes, and tags on resources
- `authority/` - Subject authority and classification trees
- `collections/` - Collection management and resource organization
- `curation/` - Content review and batch operations
- `graph/` - Knowledge graph, citations, and discovery
- `monitoring/` - System health, metrics, and observability
- `quality/` - Multi-dimensional quality assessment
- `recommendations/` - Hybrid recommendation engine (NCF, content, graph)
- `resources/` - Resource CRUD operations and metadata
- `scholarly/` - Academic metadata extraction (equations, tables, citations)
- `search/` - Hybrid search (keyword, semantic, full-text)
- `taxonomy/` - ML-based classification and taxonomy management

**Module Communication**: All modules communicate via event bus (no direct imports)

### Backend Shared Kernel (`backend/app/shared/`)

**Purpose**: Cross-cutting concerns shared by all modules

**Key Components**:
- `database.py` - Database session management
- `event_bus.py` - Event-driven communication
- `base_model.py` - Base SQLAlchemy model
- `embeddings.py` - Vector embedding generation
- `ai_core.py` - AI operations (summarization, entity extraction)
- `cache.py` - Redis caching service

**Rules**: Shared kernel has no dependencies on domain modules

### Backend Domain (`backend/app/domain/`)

**Purpose**: Domain objects and business rules

**Key Files**:
- `base.py` - Base domain classes
- `search.py` - Search domain objects
- `classification.py` - Classification domain
- `quality.py` - Quality domain
- `recommendation.py` - Recommendation domain

### Backend Events (`backend/app/events/`)

**Purpose**: Event-driven architecture for module communication

**Key Files**:
- `event_system.py` - Event bus implementation (in-memory, async)
- `event_types.py` - Event type definitions and schemas
- `hooks.py` - Event hook registration

**Event Categories**:
- Resource events: `resource.created`, `resource.updated`, `resource.deleted`
- Collection events: `collection.created`, `collection.resource_added`
- Annotation events: `annotation.created`, `annotation.updated`, `annotation.deleted`
- Quality events: `quality.computed`, `quality.outlier_detected`
- Classification events: `resource.classified`, `taxonomy.model_trained`
- Graph events: `citation.extracted`, `graph.updated`, `hypothesis.discovered`
- Recommendation events: `recommendation.generated`, `user.profile_updated`
- Curation events: `curation.reviewed`, `curation.approved`
- Metadata events: `metadata.extracted`, `equations.parsed`, `tables.extracted`

**Performance**: Event emission + delivery < 1ms (p95)

### Frontend Components (`frontend/src/components/`)

**Purpose**: React component library

**Structure**:
- `features/` - Feature-specific components (library, upload, resource-detail)
- `ui/` - Reusable UI components (Button, Card, Input)
- `layout/` - Layout components (Navbar, Sidebar, MainLayout)
- `common/` - Common components (CommandPalette, ErrorBoundary)

### Frontend API Client (`frontend/src/lib/api/`)

**Purpose**: Backend API integration

**Key Files**:
- `resources.ts` - Resource API calls
- `search.ts` - Search API calls
- `collections.ts` - Collection API calls
- `graph.ts` - Graph API calls
- `types.ts` - TypeScript type definitions

## Documentation Hierarchy

### Level 1: Quick Reference
- `AGENTS.md` - Agent routing rules
- `.kiro/steering/product.md` - Product overview
- `.kiro/steering/tech.md` - Tech stack
- `.kiro/steering/structure.md` - This file

### Level 2: Feature Specs
- `.kiro/specs/[feature]/requirements.md` - What to build
- `.kiro/specs/[feature]/design.md` - How to build it
- `.kiro/specs/[feature]/tasks.md` - Implementation steps

### Level 3: Technical Details
- `backend/docs/index.md` - Documentation hub and navigation
- `backend/docs/api/*.md` - API reference (10 domain files)
- `backend/docs/architecture/*.md` - Architecture documentation (5 files)
- `backend/docs/guides/*.md` - Developer guides (5 files)
- `backend/docs/POSTGRESQL_MIGRATION_GUIDE.md` - Database migration
- `backend/docs/EVENT_DRIVEN_REFACTORING.md` - Event architecture

### Level 4: Implementation
- `backend/app/modules/[module]/README.md` - Module documentation
- `backend/app/services/[service].py` - Service implementation
- `frontend/src/components/features/[feature]/README.md` - Component docs

## Finding What You Need

### "Where is the API for X?"
1. Check `backend/docs/index.md` for navigation
2. Check `backend/docs/api/[domain].md` for specific endpoint docs
3. Find router in `backend/app/modules/[module]/router.py`
4. Find service in `backend/app/modules/[module]/service.py`

### "How does feature X work?"
1. Check `.kiro/specs/[feature]/design.md` for architecture
2. Check `backend/docs/architecture/overview.md` for system context
3. Check implementation in `backend/app/modules/[module]/`

### "What are the requirements for X?"
1. Check `.kiro/specs/[feature]/requirements.md` for user stories
2. Check `backend/docs/api/[domain].md` for API contracts

### "How do I implement X?"
1. Check `.kiro/specs/[feature]/tasks.md` for implementation steps
2. Check `backend/docs/guides/workflows.md` for development workflows
3. Check existing implementations in `backend/app/modules/` for patterns

### "What tests exist for X?"
1. Check `backend/tests/modules/` for module-specific tests
2. Check `backend/tests/integration/` for integration tests
3. Check `backend/tests/conftest.py` for test fixtures

### "How do modules communicate?"
1. Check `backend/docs/architecture/event-system.md` for event bus details
2. Check `backend/docs/architecture/events.md` for event catalog
3. Check `backend/app/modules/[module]/handlers.py` for event handlers

## Migration Status

### Completed Migrations
- âœ… Event-driven architecture (Phase 12.5)
- âœ… Vertical slice refactoring (Phase 13.5 + Phase 14) - Complete
- âœ… PostgreSQL support (Phase 13)
- âœ… Test suite stabilization (Phase 14)
- âœ… Documentation modular migration (20 files migrated)
- âœ… Legacy code cleanup (Phase 14)

### Architecture Achievements
- âœ… 13 self-contained modules with event-driven communication
- âœ… Shared kernel for cross-cutting concerns
- âœ… Zero circular dependencies between modules
- âœ… 97 API routes across all modules
- âœ… Event bus with <1ms latency (p95)

### Planned
- ğŸ“‹ API versioning
- ğŸ“‹ Authentication and authorization
- ğŸ“‹ Rate limiting
- ğŸ“‹ Frontend-backend integration completion

## Related Documentation

- [Product Overview](.kiro/steering/product.md)
- [Tech Stack](.kiro/steering/tech.md)
- [Spec Organization](.kiro/specs/README.md)
- [Documentation Index](../../backend/docs/index.md)
- [API Reference](../../backend/docs/api/overview.md)
- [Architecture Overview](../../backend/docs/architecture/overview.md)
- [Developer Setup Guide](../../backend/docs/guides/setup.md)


<div style='page-break-after: always;'></div>

---



# 5. Backend Documentation Index

*Source: `backend/docs/index.md`*

---

# Backend Documentation Index

## Quick Navigation

| Need | Read |
|------|------|
| API endpoints | [API Reference](api/) |
| System architecture | [Architecture](architecture/) |
| Development setup | [Developer Guides](guides/) |
| Database info | [Architecture: Database](architecture/database.md) |
| Testing | [Guides: Testing](guides/testing.md) |

## Documentation Structure

```
backend/docs/
â”œâ”€â”€ index.md                    # This file
â”œâ”€â”€ api/                        # API Reference (split by domain/module)
â”‚   â”œâ”€â”€ overview.md             # Auth, errors, base URLs, module architecture
â”‚   â”œâ”€â”€ resources.md            # Resource management endpoints
â”‚   â”œâ”€â”€ search.md               # Search endpoints (hybrid, vector, FTS)
â”‚   â”œâ”€â”€ collections.md          # Collection management
â”‚   â”œâ”€â”€ annotations.md          # Annotation system
â”‚   â”œâ”€â”€ taxonomy.md             # Taxonomy & classification
â”‚   â”œâ”€â”€ graph.md                # Knowledge graph & citations
â”‚   â”œâ”€â”€ recommendations.md      # Recommendation engine
â”‚   â”œâ”€â”€ quality.md              # Quality assessment
â”‚   â”œâ”€â”€ scholarly.md            # Academic metadata extraction
â”‚   â”œâ”€â”€ authority.md            # Subject authority
â”‚   â”œâ”€â”€ curation.md             # Content review
â”‚   â””â”€â”€ monitoring.md           # Monitoring & health checks
â”œâ”€â”€ architecture/               # System Architecture
â”‚   â”œâ”€â”€ overview.md             # High-level system design
â”‚   â”œâ”€â”€ database.md             # Database schema & models
â”‚   â”œâ”€â”€ event-system.md         # Event-driven architecture
â”‚   â”œâ”€â”€ events.md               # Event catalog
â”‚   â”œâ”€â”€ modules.md              # Vertical slice modules
â”‚   â””â”€â”€ decisions.md            # Architectural Decision Records (ADRs)
â””â”€â”€ guides/                     # Developer Guides
    â”œâ”€â”€ setup.md                # Installation & environment
    â”œâ”€â”€ workflows.md            # Common development tasks
    â”œâ”€â”€ testing.md              # Testing strategies
    â”œâ”€â”€ deployment.md           # Docker & production
    â””â”€â”€ troubleshooting.md      # Common issues & solutions
```

## API Reference

Complete REST API documentation organized by module:

- [API Overview](api/overview.md) - Authentication, errors, pagination, module architecture
- [Resources API](api/resources.md) - Content management and ingestion
- [Search API](api/search.md) - Hybrid search, three-way fusion
- [Collections API](api/collections.md) - Collection management
- [Annotations API](api/annotations.md) - Text highlighting and notes
- [Taxonomy API](api/taxonomy.md) - Classification and ML
- [Graph API](api/graph.md) - Knowledge graph and citations
- [Recommendations API](api/recommendations.md) - Personalized content
- [Quality API](api/quality.md) - Quality assessment
- [Scholarly API](api/scholarly.md) - Academic metadata extraction
- [Authority API](api/authority.md) - Subject authority and classification
- [Curation API](api/curation.md) - Content review and batch operations
- [Monitoring API](api/monitoring.md) - Health checks and metrics

## Architecture

System design and technical decisions:

- [Architecture Overview](architecture/overview.md) - High-level system design and module structure
- [Database](architecture/database.md) - Schema, models, migrations
- [Event System](architecture/event-system.md) - Event-driven communication patterns
- [Event Catalog](architecture/events.md) - Complete event reference
- [Modules](architecture/modules.md) - Vertical slice architecture
- [Design Decisions](architecture/decisions.md) - ADRs

## Developer Guides

Getting started and development workflows:

- [Setup Guide](guides/setup.md) - Installation and configuration
- [Development Workflows](guides/workflows.md) - Common tasks
- [Testing Guide](guides/testing.md) - Running and writing tests
- [Deployment Guide](guides/deployment.md) - Docker and production
- [Troubleshooting](guides/troubleshooting.md) - Common issues

## Interactive Documentation

FastAPI provides interactive API documentation:

- **Swagger UI**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc

## Related Documentation

- [Steering Docs](../../.kiro/steering/) - High-level project context
- [Spec Organization](../../.kiro/specs/) - Feature specifications
- [Frontend Docs](../../frontend/README.md) - Frontend documentation


<div style='page-break-after: always;'></div>

---



# 6. API Overview

*Source: `backend/docs/api/overview.md`*

---

# API Overview

## Base URL

```
Development: http://127.0.0.1:8000
Production: https://your-domain.com/api
```

## Authentication

Currently, no authentication is required for development and testing.

**Future Authentication (Planned):**
- API Key in `Authorization` header: `Authorization: Bearer <api_key>`
- Rate limiting: 1000 requests/hour per API key
- Ingestion limits: 100 requests/hour per API key

## Content Types

All API endpoints accept and return JSON data:
```
Content-Type: application/json
```

## Response Format

### Success Response

```json
{
  "data": {},
  "meta": {
    "total": 100,
    "page": 1,
    "per_page": 25
  }
}
```

### Error Response

```json
{
  "detail": "Error description",
  "error_code": "VALIDATION_ERROR",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

## HTTP Status Codes

| Code | Description |
|------|-------------|
| 200 | OK - Request successful |
| 201 | Created - Resource created successfully |
| 202 | Accepted - Request accepted for processing |
| 204 | No Content - Successful deletion |
| 400 | Bad Request - Invalid request parameters |
| 403 | Forbidden - Access denied |
| 404 | Not Found - Resource not found |
| 422 | Unprocessable Entity - Validation error |
| 500 | Internal Server Error - Server error |

## Pagination

List endpoints support pagination with `limit` and `offset`:

```
GET /resources?limit=25&offset=0
```

Response includes total count:

```json
{
  "items": [...],
  "total": 100
}
```

Some endpoints use page-based pagination:

```
GET /collections?page=1&limit=50
```

## Filtering

Most list endpoints support filtering:

```
GET /resources?language=en&min_quality=0.7&classification_code=004
```

See individual endpoint documentation for available filters.

## Sorting

List endpoints support sorting:

```
GET /resources?sort_by=created_at&sort_dir=desc
```

Common sort fields: `created_at`, `updated_at`, `quality_score`, `title`, `relevance`

## Rate Limiting

**Current**: No rate limits enforced

**Planned**:
- General API: 1000 requests per hour per API key
- Ingestion: 100 requests per hour per API key
- Search: 500 requests per hour per API key
- Burst Allowance: 50 requests per minute for short-term spikes

## API Endpoints by Domain

Neo Alexandria 2.0 uses a modular architecture where each domain is implemented as a self-contained module. All modules follow consistent patterns for routing, services, and event handling.

| Module | Description | Documentation |
|--------|-------------|---------------|
| Resources | Content management and ingestion | [resources.md](resources.md) |
| Search | Hybrid search with vector and FTS | [search.md](search.md) |
| Collections | Collection management and sharing | [collections.md](collections.md) |
| Annotations | Active reading with highlights and notes | [annotations.md](annotations.md) |
| Taxonomy | ML classification and taxonomy trees | [taxonomy.md](taxonomy.md) |
| Graph | Knowledge graph, citations, and discovery | [graph.md](graph.md) |
| Recommendations | Hybrid recommendation engine | [recommendations.md](recommendations.md) |
| Quality | Multi-dimensional quality assessment | [quality.md](quality.md) |
| Scholarly | Academic metadata extraction | [scholarly.md](scholarly.md) |
| Authority | Subject authority and classification | [authority.md](authority.md) |
| Curation | Content review and batch operations | [curation.md](curation.md) |
| Monitoring | System health and metrics | [monitoring.md](monitoring.md) |

### Module Architecture

Each module is self-contained with:
- **Router**: FastAPI endpoints at `/module-name/*`
- **Service**: Business logic and data access
- **Schema**: Pydantic models for validation
- **Model**: SQLAlchemy database models
- **Handlers**: Event subscribers and emitters
- **README**: Module-specific documentation

Modules communicate through an event bus, eliminating direct dependencies.

## Complete Endpoint Reference

### Content Management
- `POST /resources` - Ingest new resource from URL
- `GET /resources` - List resources with filtering
- `GET /resources/{id}` - Get specific resource
- `PUT /resources/{id}` - Update resource metadata
- `DELETE /resources/{id}` - Delete resource
- `GET /resources/{id}/status` - Check ingestion status
- `PUT /resources/{id}/classify` - Override classification

### Search and Discovery
- `POST /search` - Advanced hybrid search
- `GET /search/three-way-hybrid` - Three-way hybrid search
- `GET /search/compare-methods` - Compare search methods
- `POST /search/evaluate` - Evaluate search quality

### Collections
- `POST /collections` - Create collection
- `GET /collections/{id}` - Get collection
- `PUT /collections/{id}` - Update collection
- `DELETE /collections/{id}` - Delete collection
- `GET /collections` - List collections
- `POST /collections/{id}/resources` - Add resources
- `DELETE /collections/{id}/resources` - Remove resources
- `GET /collections/{id}/recommendations` - Get recommendations

### Annotations
- `POST /resources/{id}/annotations` - Create annotation
- `GET /resources/{id}/annotations` - List annotations
- `GET /annotations` - List all user annotations
- `PUT /annotations/{id}` - Update annotation
- `DELETE /annotations/{id}` - Delete annotation
- `GET /annotations/search/fulltext` - Full-text search
- `GET /annotations/search/semantic` - Semantic search
- `GET /annotations/export/markdown` - Export to Markdown
- `GET /annotations/export/json` - Export to JSON

### Taxonomy
- `POST /taxonomy/nodes` - Create taxonomy node
- `PUT /taxonomy/nodes/{id}` - Update node
- `DELETE /taxonomy/nodes/{id}` - Delete node
- `POST /taxonomy/nodes/{id}/move` - Move node
- `GET /taxonomy/tree` - Get taxonomy tree
- `POST /taxonomy/classify/{id}` - Classify resource
- `POST /taxonomy/train` - Train ML model

### Quality
- `GET /resources/{id}/quality-details` - Quality breakdown
- `POST /quality/recalculate` - Recalculate quality
- `GET /quality/outliers` - Get quality outliers
- `GET /quality/degradation` - Monitor degradation
- `GET /quality/distribution` - Quality distribution
- `GET /quality/trends` - Quality trends

### Monitoring
- `GET /health` - Health check
- `GET /monitoring/status` - System status
- `GET /monitoring/metrics` - System metrics

## SDKs and Libraries

### Python

```python
import requests

# Import from modules (new structure)
from app.modules.resources.schema import ResourceCreate
from app.modules.search.schema import SearchRequest

# Ingest a resource
response = requests.post(
    "http://127.0.0.1:8000/resources",
    json={"url": "https://example.com/article"}
)

# Search resources
response = requests.post(
    "http://127.0.0.1:8000/search",
    json={
        "text": "machine learning",
        "hybrid_weight": 0.7,
        "limit": 10
    }
)

# Create a collection
response = requests.post(
    "http://127.0.0.1:8000/collections",
    json={
        "name": "ML Papers",
        "description": "Machine learning research papers"
    }
)
```

### JavaScript

```javascript
// Ingest a resource
const response = await fetch('http://127.0.0.1:8000/resources', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ url: 'https://example.com/article' })
});

// Search resources
const searchResponse = await fetch('http://127.0.0.1:8000/search', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'machine learning',
    hybrid_weight: 0.7,
    limit: 10
  })
});

// Create a collection
const collectionResponse = await fetch('http://127.0.0.1:8000/collections', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    name: 'ML Papers',
    description: 'Machine learning research papers'
  })
});
```

### Module Imports (Backend Development)

When developing backend features, import from modules:

```python
# Import from modules
from app.modules.resources import ResourceService, ResourceCreate
from app.modules.search import SearchService, SearchRequest
from app.modules.collections import CollectionService, CollectionCreate
from app.modules.annotations import AnnotationService, AnnotationCreate
from app.modules.taxonomy import TaxonomyService, ClassificationResult
from app.modules.graph import GraphService, CitationService
from app.modules.recommendations import RecommendationService
from app.modules.quality import QualityService, QualityDimensions

# Import from shared kernel
from app.shared.embeddings import EmbeddingService
from app.shared.ai_core import AICore
from app.shared.cache import CacheService
from app.shared.database import get_db
from app.shared.event_bus import event_bus
```

## Interactive API Documentation

FastAPI provides interactive API documentation:

- **Swagger UI**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc

## Related Documentation

- [Architecture Overview](../architecture/overview.md)
- [Developer Setup](../guides/setup.md)
- [Testing Guide](../guides/testing.md)


<div style='page-break-after: always;'></div>

---



# 7. Resources API

*Source: `backend/docs/api/resources.md`*

---

ï»¿# Resources API

Resource management endpoints for content ingestion, retrieval, and curation.

## Overview

The Resources API provides CRUD operations for managing knowledge resources. Resources are the core content units in Neo Alexandria, representing articles, papers, documents, and other knowledge artifacts.

## Endpoints

### POST /resources

Creates a new resource by ingesting content from a URL with AI-powered asynchronous processing.

**Request Body:**
```json
{
  "url": "string (required)",
  "title": "string (optional)",
  "description": "string (optional)",
  "language": "string (optional)",
  "type": "string (optional)",
  "source": "string (optional)"
}
```

**Response (202 Accepted):**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending"
}
```

**Background Processing:**
1. Fetch content from the provided URL
2. Extract text from HTML/PDF content
3. Generate AI-powered summary using transformers
4. Generate intelligent tags using zero-shot classification
5. Normalize metadata using authority control
6. Classify content using the classification system
7. Calculate quality score
8. Archive content locally
9. Update resource status to "completed" or "failed"

**Example:**
```bash
curl -X POST http://127.0.0.1:8000/resources \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com/article"}'
```

---

### GET /resources/{resource_id}/status

Monitor the ingestion status of a resource.

**Response:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "ingestion_status": "completed",
  "ingestion_error": null,
  "ingestion_started_at": "2024-01-01T10:00:00Z",
  "ingestion_completed_at": "2024-01-01T10:02:30Z"
}
```

**Status Values:**
- `pending` - Request received, processing not started
- `processing` - Content is being processed
- `completed` - Processing finished successfully
- `failed` - Processing failed with error

---

### GET /resources

List resources with filtering, sorting, and pagination.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `q` | string | Keyword search on title/description | - |
| `classification_code` | string | Filter by classification code | - |
| `type` | string | Filter by resource type | - |
| `language` | string | Filter by language | - |
| `read_status` | string | Filter by read status | - |
| `min_quality` | float | Minimum quality score (0.0-1.0) | - |
| `created_from` | datetime | Filter by creation date (ISO 8601) | - |
| `created_to` | datetime | Filter by creation date (ISO 8601) | - |
| `updated_from` | datetime | Filter by update date (ISO 8601) | - |
| `updated_to` | datetime | Filter by update date (ISO 8601) | - |
| `subject_any` | string[] | Filter by any of these subjects | - |
| `subject_all` | string[] | Filter by all of these subjects | - |
| `limit` | integer | Number of results (1-100) | 25 |
| `offset` | integer | Number of results to skip | 0 |
| `sort_by` | string | Sort field | updated_at |
| `sort_dir` | string | Sort direction (asc/desc) | desc |

**Response:**
```json
{
  "items": [
    {
      "id": "550e8400-e29b-41d4-a716-446655440000",
      "title": "Machine Learning Fundamentals",
      "description": "Comprehensive guide to ML concepts",
      "creator": "John Doe",
      "publisher": "Tech Publications",
      "source": "https://example.com/ml-guide",
      "language": "en",
      "type": "article",
      "subject": ["Machine Learning", "Artificial Intelligence"],
      "classification_code": "004",
      "quality_score": 0.85,
      "read_status": "unread",
      "created_at": "2024-01-01T10:00:00Z",
      "updated_at": "2024-01-01T10:02:30Z"
    }
  ],
  "total": 1
}
```

**Example:**
```bash
curl "http://127.0.0.1:8000/resources?limit=5&classification_code=004&min_quality=0.8"
```

---

### GET /resources/{resource_id}

Retrieve a specific resource by ID.

**Response:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "title": "Machine Learning Fundamentals",
  "description": "Comprehensive guide to ML concepts",
  "creator": "John Doe",
  "publisher": "Tech Publications",
  "source": "https://example.com/ml-guide",
  "language": "en",
  "type": "article",
  "subject": ["Machine Learning", "Artificial Intelligence"],
  "classification_code": "004",
  "quality_score": 0.85,
  "read_status": "unread",
  "created_at": "2024-01-01T10:00:00Z",
  "updated_at": "2024-01-01T10:02:30Z"
}
```

---

### PUT /resources/{resource_id}

Update a resource with partial data. Only provided fields are modified.

**Request Body:**
```json
{
  "title": "Updated Title",
  "description": "Updated description",
  "read_status": "in_progress",
  "subject": ["Updated", "Tags"]
}
```

**Response:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "title": "Updated Title",
  "description": "Updated description",
  "read_status": "in_progress",
  "subject": ["Updated", "Tags"],
  "updated_at": "2024-01-01T11:00:00Z"
}
```

---

### DELETE /resources/{resource_id}

Delete a resource by ID.

**Response:** `204 No Content`

---

### PUT /resources/{resource_id}/classify

Override the classification code for a specific resource.

**Request Body:**
```json
{
  "code": "004"
}
```

**Response:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "title": "Resource Title",
  "classification_code": "004",
  "updated_at": "2024-01-01T11:00:00Z"
}
```

## Data Models

### Resource Model

The core resource model follows Dublin Core metadata standards with custom extensions:

```json
{
  "id": "uuid",
  "title": "string (required)",
  "description": "string",
  "creator": "string",
  "publisher": "string",
  "contributor": "string",
  "source": "string",
  "language": "string",
  "type": "string",
  "format": "string",
  "identifier": "string",
  "subject": ["string"],
  "relation": ["string"],
  "coverage": "string",
  "rights": "string",
  "classification_code": "string",
  "read_status": "unread|in_progress|completed|archived",
  "quality_score": "float (0.0-1.0)",
  "created_at": "datetime (ISO 8601)",
  "updated_at": "datetime (ISO 8601)"
}
```

## Module Structure

The Resources module is implemented as a self-contained vertical slice:

**Module**: `app.modules.resources`  
**Router Prefix**: `/resources`  
**Version**: 1.0.0

```python
from app.modules.resources import (
    resources_router,
    ResourceService,
    ResourceCreate,
    ResourceUpdate,
    ResourceResponse
)
```

### Events

**Emitted Events:**
- `resource.created` - When a new resource is ingested
- `resource.updated` - When resource metadata is updated
- `resource.deleted` - When a resource is removed

**Subscribed Events:**
- None (Resources is a foundational module)

## Related Documentation

- [Search API](search.md) - Search and discovery
- [Collections API](collections.md) - Organize resources into collections
- [Quality API](quality.md) - Quality assessment details
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [API Overview](overview.md) - Authentication, errors, pagination


<div style='page-break-after: always;'></div>

---



# 8. Search API

*Source: `backend/docs/api/search.md`*

---

ï»¿# Search API

Advanced search endpoints with hybrid keyword/semantic capabilities, three-way fusion, and faceted results.

## Overview

The Search API provides multiple search strategies:
- **Hybrid Search** - Combines keyword (FTS5) and semantic (vector) search
- **Three-Way Hybrid** - Adds sparse vectors with RRF fusion and ColBERT reranking
- **Method Comparison** - Side-by-side comparison of search methods
- **Quality Evaluation** - IR metrics for search quality assessment

## Endpoints

### POST /search

Advanced search with hybrid keyword/semantic capabilities and faceted results.

**Request Body:**
```json
{
  "text": "machine learning algorithms",
  "hybrid_weight": 0.5,
  "filters": {
    "classification_code": ["004"],
    "language": ["en"],
    "min_quality": 0.7,
    "subject_any": ["Machine Learning"],
    "subject_all": ["Artificial Intelligence", "Machine Learning"]
  },
  "limit": 25,
  "offset": 0,
  "sort_by": "relevance",
  "sort_dir": "desc"
}
```

**Request Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `text` | string | Search query text | - |
| `hybrid_weight` | float | Weight for hybrid search (0.0-1.0) | 0.5 |
| `filters` | object | Filter criteria | - |
| `limit` | integer | Number of results (1-100) | 25 |
| `offset` | integer | Number of results to skip | 0 |
| `sort_by` | string | Sort field | relevance |
| `sort_dir` | string | Sort direction (asc/desc) | desc |

**Hybrid Search Weight:**
- `0.0` - Pure keyword search (FTS5)
- `0.5` - Balanced hybrid search (default)
- `1.0` - Pure semantic search (vector similarity)

**Response:**
```json
{
  "total": 42,
  "items": [
    {
      "id": "550e8400-e29b-41d4-a716-446655440000",
      "title": "Machine Learning Fundamentals",
      "description": "Comprehensive guide to ML concepts",
      "subject": ["Machine Learning", "Artificial Intelligence"],
      "quality_score": 0.85,
      "relevance_score": 0.92,
      "created_at": "2024-01-01T10:00:00Z",
      "updated_at": "2024-01-01T10:02:30Z"
    }
  ],
  "facets": {
    "classification_code": [{"key": "004", "count": 30}],
    "type": [{"key": "article", "count": 35}],
    "language": [{"key": "en", "count": 33}],
    "read_status": [{"key": "unread", "count": 20}],
    "subject": [{"key": "Machine Learning", "count": 18}]
  }
}
```

**Example:**
```bash
curl -X POST http://127.0.0.1:8000/search \
  -H "Content-Type: application/json" \
  -d '{
    "text": "artificial intelligence",
    "hybrid_weight": 0.7,
    "filters": {"min_quality": 0.8},
    "limit": 10
  }'
```

---

### GET /search/three-way-hybrid

Execute three-way hybrid search combining FTS5, dense vectors, and sparse vectors with RRF fusion and optional ColBERT reranking.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `query` | string | Search query text (required) | - |
| `limit` | integer | Number of results (1-100) | 20 |
| `offset` | integer | Number of results to skip | 0 |
| `enable_reranking` | boolean | Apply ColBERT reranking | true |
| `adaptive_weighting` | boolean | Use query-adaptive RRF weights | true |

**Response (200 OK):**
```json
{
  "results": [
    {
      "id": "550e8400-e29b-41d4-a716-446655440000",
      "title": "Machine Learning Fundamentals",
      "description": "Comprehensive guide to ML concepts",
      "subject": ["Machine Learning", "Artificial Intelligence"],
      "quality_score": 0.85,
      "relevance_score": 0.92,
      "created_at": "2024-01-01T10:00:00Z"
    }
  ],
  "total": 42,
  "latency_ms": 145.3,
  "method_contributions": {
    "fts5": 45,
    "dense": 38,
    "sparse": 42
  },
  "weights_used": [0.35, 0.35, 0.30],
  "facets": {
    "classification_code": [{"key": "004", "count": 30}],
    "type": [{"key": "article", "count": 35}],
    "language": [{"key": "en", "count": 33}]
  }
}
```

**Example:**
```bash
# Three-way search with reranking and adaptive weighting
curl "http://127.0.0.1:8000/search/three-way-hybrid?query=machine+learning&limit=20&enable_reranking=true"

# Fast three-way search without reranking
curl "http://127.0.0.1:8000/search/three-way-hybrid?query=neural+networks&limit=10&enable_reranking=false"
```

**Performance:**
- Target latency: <200ms at 95th percentile
- With reranking: <1 second for 100 candidates
- Parallel retrieval for optimal speed

---

### GET /search/compare-methods

Compare different search methods side-by-side for debugging and optimization.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `query` | string | Search query text (required) | - |
| `limit` | integer | Number of results per method (1-50) | 20 |

**Response (200 OK):**
```json
{
  "query": "machine learning",
  "methods": {
    "fts5_only": {
      "results": [...],
      "latency_ms": 25.3,
      "count": 20
    },
    "dense_only": {
      "results": [...],
      "latency_ms": 42.1,
      "count": 20
    },
    "sparse_only": {
      "results": [...],
      "latency_ms": 38.7,
      "count": 20
    },
    "two_way_hybrid": {
      "results": [...],
      "latency_ms": 67.4,
      "count": 20
    },
    "three_way_hybrid": {
      "results": [...],
      "latency_ms": 106.1,
      "count": 20
    },
    "three_way_reranked": {
      "results": [...],
      "latency_ms": 856.8,
      "count": 20
    }
  }
}
```

**Use Cases:**
- Debug search quality issues
- Compare method effectiveness for different query types
- Analyze latency trade-offs
- Validate search improvements

---

### POST /search/evaluate

Evaluate search quality using information retrieval metrics (nDCG, Recall, Precision, MRR).

**Request Body:**
```json
{
  "query": "machine learning",
  "relevance_judgments": {
    "resource_id_1": 3,
    "resource_id_2": 2,
    "resource_id_3": 1,
    "resource_id_4": 0
  }
}
```

**Relevance Scale:**
- `3` - Highly relevant
- `2` - Relevant
- `1` - Marginally relevant
- `0` - Not relevant

**Response (200 OK):**
```json
{
  "query": "machine learning",
  "metrics": {
    "ndcg@20": 0.847,
    "recall@20": 0.923,
    "precision@20": 0.650,
    "mrr": 0.833
  },
  "baseline_comparison": {
    "two_way_ndcg": 0.651,
    "improvement": 0.301
  }
}
```

**Metrics Explained:**
- **nDCG@20**: Normalized Discounted Cumulative Gain at position 20 (0-1, higher is better)
- **Recall@20**: Fraction of relevant documents retrieved in top 20 (0-1, higher is better)
- **Precision@20**: Fraction of top 20 results that are relevant (0-1, higher is better)
- **MRR**: Mean Reciprocal Rank of first relevant result (0-1, higher is better)

---

### POST /admin/sparse-embeddings/generate

Batch generate sparse embeddings for existing resources without them.

**Request Body:**
```json
{
  "resource_ids": ["uuid1", "uuid2"],
  "batch_size": 32
}
```

**Parameters:**
- `resource_ids` (optional): Specific resources to process. If omitted, processes all resources without sparse embeddings.
- `batch_size` (optional): Batch size for processing (default: 32 for GPU, 8 for CPU)

**Response (202 Accepted):**
```json
{
  "status": "queued",
  "job_id": "job_uuid",
  "estimated_duration_minutes": 45,
  "resources_to_process": 10000
}
```

**Background Processing:**
- Processes resources in batches for efficiency
- Commits every 100 resources
- Logs progress updates
- Resumes from last committed batch if interrupted
- Target: <1 second per resource

## Data Models

### Search Request Model

```json
{
  "text": "string",
  "hybrid_weight": "float (0.0-1.0)",
  "filters": {
    "classification_code": ["string"],
    "language": ["string"],
    "type": ["string"],
    "read_status": ["string"],
    "min_quality": "float",
    "max_quality": "float",
    "created_from": "datetime",
    "created_to": "datetime",
    "updated_from": "datetime",
    "updated_to": "datetime",
    "subject_any": ["string"],
    "subject_all": ["string"]
  },
  "limit": "integer (1-100)",
  "offset": "integer (>=0)",
  "sort_by": "relevance|updated_at|created_at|quality_score|title",
  "sort_dir": "asc|desc"
}
```

### Search Response Model

```json
{
  "total": "integer",
  "items": [
    {
      "id": "uuid",
      "title": "string",
      "description": "string",
      "subject": ["string"],
      "quality_score": "float",
      "relevance_score": "float",
      "created_at": "datetime",
      "updated_at": "datetime"
    }
  ],
  "facets": {
    "classification_code": [{"key": "string", "count": "integer"}],
    "type": [{"key": "string", "count": "integer"}],
    "language": [{"key": "string", "count": "integer"}],
    "read_status": [{"key": "string", "count": "integer"}],
    "subject": [{"key": "string", "count": "integer"}]
  }
}
```

## Module Structure

The Search module is implemented as a self-contained vertical slice:

**Module**: `app.modules.search`  
**Router Prefix**: `/search`  
**Version**: 1.0.0

```python
from app.modules.search import (
    search_router,
    SearchService,
    SearchRequest,
    SearchResponse,
    SearchStrategy
)
```

### Events

**Emitted Events:**
- `search.executed` - When a search is performed
- `search.results_returned` - When search results are returned

**Subscribed Events:**
- `resource.created` - Updates search indices
- `resource.updated` - Updates search indices
- `resource.deleted` - Removes from search indices

## Related Documentation

- [Resources API](resources.md) - Content management
- [Recommendations API](recommendations.md) - Personalized discovery
- [Graph API](graph.md) - Knowledge graph exploration
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [API Overview](overview.md) - Authentication, errors, pagination


<div style='page-break-after: always;'></div>

---



# 9. Collections API

*Source: `backend/docs/api/collections.md`*

---

ï»¿# Collections API

Collection management endpoints for organizing resources into hierarchical groups.

## Overview

Collections allow users to organize resources into named groups with:
- Hierarchical parent-child relationships
- Visibility controls (private, shared, public)
- Aggregate embeddings for similarity-based recommendations
- Batch resource membership operations

## Endpoints

### POST /collections

Create a new collection with metadata and optional hierarchical parent.

**Request Body:**
```json
{
  "name": "string (required, 1-255 characters)",
  "description": "string (optional, max 2000 characters)",
  "visibility": "private|shared|public (optional, default: private)",
  "parent_id": "string (optional, UUID of parent collection)"
}
```

**Response (201 Created):**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "name": "Machine Learning Papers",
  "description": "Curated collection of ML research",
  "owner_id": "user123",
  "visibility": "public",
  "parent_id": null,
  "resource_count": 0,
  "created_at": "2024-01-01T10:00:00Z",
  "updated_at": "2024-01-01T10:00:00Z",
  "resources": []
}
```

**Error Responses:**
- `400 Bad Request` - Invalid name length, visibility value, or circular hierarchy
- `404 Not Found` - Parent collection not found

**Example:**
```bash
curl -X POST http://127.0.0.1:8000/collections \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Machine Learning Papers",
    "description": "Curated collection of ML research",
    "visibility": "public"
  }'
```

---

### GET /collections/{id}

Retrieve a specific collection with member resource summaries.

**Response (200 OK):**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "name": "Machine Learning Papers",
  "description": "Curated collection of ML research",
  "owner_id": "user123",
  "visibility": "public",
  "parent_id": null,
  "resource_count": 2,
  "created_at": "2024-01-01T10:00:00Z",
  "updated_at": "2024-01-01T10:05:00Z",
  "resources": [
    {
      "id": "660e8400-e29b-41d4-a716-446655440001",
      "title": "Deep Learning Fundamentals",
      "creator": "John Doe",
      "quality_score": 0.92
    }
  ]
}
```

**Access Rules:**
- `private`: Only owner can access
- `shared`: Owner + explicit permissions (future)
- `public`: All authenticated users

---

### PUT /collections/{id}

Update collection metadata (name, description, visibility, parent).

**Request Body:**
```json
{
  "name": "string (optional)",
  "description": "string (optional)",
  "visibility": "private|shared|public (optional)",
  "parent_id": "string (optional, UUID or null)"
}
```

**Response (200 OK):** Returns updated collection object.

---

### DELETE /collections/{id}

Delete a collection. Cascade deletes all descendant collections.

**Response:** `204 No Content`

---

### GET /collections

List collections with filtering and pagination.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `owner_id` | string | Filter by owner | - |
| `visibility` | string | Filter by visibility | - |
| `parent_id` | string | Filter by parent (null for root) | - |
| `page` | integer | Page number | 1 |
| `limit` | integer | Results per page (1-100) | 50 |

**Response:**
```json
{
  "items": [...],
  "total": 1,
  "page": 1,
  "limit": 50
}
```

---

### POST /collections/{id}/resources

Add resources to a collection (batch operation, up to 100 resources).

**Request Body:**
```json
{
  "resource_ids": ["uuid", "uuid"]
}
```

**Response (200 OK):** Returns updated collection with new resource count.

**Behavior:**
- Validates all resource IDs exist before adding
- Handles duplicate associations gracefully (idempotent)
- Triggers aggregate embedding recomputation

---

### DELETE /collections/{id}/resources

Remove resources from a collection (batch operation).

**Request Body:**
```json
{
  "resource_ids": ["uuid", "uuid"]
}
```

**Response (200 OK):** Returns updated collection.

---

### GET /collections/{id}/recommendations

Get recommendations for similar resources and collections based on aggregate embedding.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `limit` | integer | Max results per category (1-50) | 10 |
| `include_resources` | boolean | Include resource recommendations | true |
| `include_collections` | boolean | Include collection recommendations | true |

**Response:**
```json
{
  "resources": [
    {
      "id": "880e8400-e29b-41d4-a716-446655440003",
      "title": "Advanced Neural Networks",
      "similarity": 0.92
    }
  ],
  "collections": [
    {
      "id": "aa0e8400-e29b-41d4-a716-446655440005",
      "name": "AI Research Papers",
      "similarity": 0.85
    }
  ]
}
```

---

### GET /collections/{id}/embedding

Retrieve the aggregate embedding vector for a collection.

**Response:**
```json
{
  "embedding": [0.123, -0.456, 0.789, ...],
  "dimension": 768
}
```

## Features

### Hierarchical Organization

Collections support parent-child relationships:

```bash
# Create parent
curl -X POST http://127.0.0.1:8000/collections \
  -d '{"name": "Computer Science", "visibility": "public"}'

# Create child
curl -X POST http://127.0.0.1:8000/collections \
  -d '{"name": "Machine Learning", "parent_id": "{parent_id}"}'
```

### Aggregate Embeddings

Collections automatically compute aggregate embeddings from member resources:
- Mean vector across all member resource embeddings
- Normalized to unit length (L2 norm)
- Recomputed when resources are added/removed

### Access Control

| Level | Owner | Other Users |
|-------|-------|-------------|
| `private` | Full access | None |
| `shared` | Full access | Read only (future) |
| `public` | Full access | Read only |

## Data Models

### Collection Model

```json
{
  "id": "uuid",
  "name": "string (1-255 characters)",
  "description": "string (max 2000 characters) or null",
  "owner_id": "string",
  "visibility": "private|shared|public",
  "parent_id": "uuid or null",
  "resource_count": "integer",
  "created_at": "datetime",
  "updated_at": "datetime",
  "resources": [...]
}
```

## Module Structure

The Collections module is implemented as a self-contained vertical slice:

**Module**: `app.modules.collections`  
**Router Prefix**: `/collections`  
**Version**: 1.0.0

```python
from app.modules.collections import (
    collections_router,
    CollectionService,
    CollectionCreate,
    CollectionUpdate,
    CollectionResponse
)
```

### Events

**Emitted Events:**
- `collection.created` - When a new collection is created
- `collection.updated` - When collection metadata is updated
- `collection.deleted` - When a collection is removed
- `collection.resource_added` - When a resource is added to a collection
- `collection.resource_removed` - When a resource is removed from a collection

**Subscribed Events:**
- `resource.deleted` - Removes resource from all collections

## Related Documentation

- [Resources API](resources.md) - Content management
- [Recommendations API](recommendations.md) - Personalized discovery
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [API Overview](overview.md) - Authentication, errors, pagination


<div style='page-break-after: always;'></div>

---



# 10. Annotations API

*Source: `backend/docs/api/annotations.md`*

---

ï»¿# Annotations API

Active reading system for highlighting text and adding notes to resources.

## Overview

The Annotations API enables:
- Precise text highlighting with character offsets
- Notes with semantic embeddings for search
- Tag-based organization
- Full-text and semantic search across annotations
- Export to Markdown and JSON formats

## Endpoints

### POST /resources/{resource_id}/annotations

Create a new annotation on a resource.

**Request Body:**
```json
{
  "start_offset": "integer (required, >= 0)",
  "end_offset": "integer (required, > start_offset)",
  "highlighted_text": "string (required)",
  "note": "string (optional, max 10,000 characters)",
  "tags": ["string"] (optional, max 20 tags),
  "color": "string (optional, hex color, default: #FFFF00)",
  "collection_ids": ["uuid"] (optional)
}
```

**Response (201 Created):**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "resource_id": "660e8400-e29b-41d4-a716-446655440001",
  "user_id": "user123",
  "start_offset": 150,
  "end_offset": 200,
  "highlighted_text": "This is the key finding of the paper",
  "note": "Important result - contradicts previous assumptions",
  "tags": ["key-finding", "methodology"],
  "color": "#FFD700",
  "context_before": "...previous text leading up to...",
  "context_after": "...text following the highlight...",
  "is_shared": false,
  "created_at": "2024-01-01T10:00:00Z",
  "updated_at": "2024-01-01T10:00:00Z"
}
```

**Performance:** <50ms creation time (excluding async embedding generation)

---

### GET /resources/{resource_id}/annotations

List all annotations for a specific resource in document order.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `include_shared` | boolean | Include shared annotations | false |
| `tags` | string[] | Filter by tags (comma-separated) | - |

**Response:** Array of annotations ordered by `start_offset` ascending.

---

### GET /annotations

List all annotations for the authenticated user across all resources.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `limit` | integer | Results per page (1-100) | 50 |
| `offset` | integer | Number to skip | 0 |
| `sort_by` | string | Sort order (recent/oldest) | recent |

---

### GET /annotations/{annotation_id}

Retrieve a specific annotation by ID.

---

### PUT /annotations/{annotation_id}

Update an annotation's note, tags, color, or sharing status.

**Request Body:**
```json
{
  "note": "string (optional)",
  "tags": ["string"] (optional),
  "color": "string (optional)",
  "is_shared": "boolean (optional)"
}
```

**Note:** Cannot update `start_offset`, `end_offset`, or `highlighted_text`.

---

### DELETE /annotations/{annotation_id}

Delete an annotation.

**Response:** `204 No Content`

---

## Search Endpoints

### GET /annotations/search/fulltext

Search annotations using full-text search across notes and highlighted text.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `query` | string | Search query (required) | - |
| `limit` | integer | Max results (1-100) | 25 |

**Performance:** <100ms for 10,000 annotations

---

### GET /annotations/search/semantic

Search annotations using semantic similarity for conceptual discovery.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `query` | string | Search query (required) | - |
| `limit` | integer | Max results (1-50) | 10 |

**Response includes `similarity` score (0.0-1.0).**

**Performance:** <500ms for 1,000 annotations

---

### GET /annotations/search/tags

Search annotations by tags with flexible matching.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `tags` | string[] | Tags to search (comma-separated) | - |
| `match_all` | boolean | Require all tags (true) or any (false) | false |
| `limit` | integer | Max results (1-100) | 50 |

---

## Export Endpoints

### GET /annotations/export/markdown

Export annotations to Markdown format.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `resource_id` | string | Filter by resource (optional) | - |

**Response:** `Content-Type: text/markdown`

```markdown
# Annotations Export

## Deep Learning Fundamentals

### Annotation 1
**Highlighted Text:**
> This is the key finding of the paper

**Note:** Important result

**Tags:** key-finding, methodology

**Created:** 2024-01-01 10:00:00
```

---

### GET /annotations/export/json

Export annotations to JSON format with complete metadata.

**Response:**
```json
{
  "annotations": [...],
  "total": 1,
  "exported_at": "2024-01-01T12:00:00Z"
}
```

## Features

### Text Offset Tracking

Annotations use character offsets for precise positioning:
- Zero-indexed character positions
- `start_offset`: First character (inclusive)
- `end_offset`: Last character (exclusive)
- Example: `"Hello World"[0:5]` = `"Hello"`

### Context Extraction

Automatically captures 50 characters before and after the highlight for preview.

### Semantic Embeddings

Annotations with notes get automatic semantic embeddings:
- Generated asynchronously after creation
- Uses nomic-ai/nomic-embed-text-v1 (384 dimensions)
- Enables semantic search across annotations

### Privacy Model

- `is_shared=false`: Only owner can view (default)
- `is_shared=true`: Visible to all users with resource access

## Data Models

### Annotation Model

```json
{
  "id": "uuid",
  "resource_id": "uuid",
  "user_id": "string",
  "start_offset": "integer (>= 0)",
  "end_offset": "integer (> start_offset)",
  "highlighted_text": "string",
  "note": "string or null (max 10,000 characters)",
  "tags": ["string"] (max 20 tags),
  "color": "string (hex color)",
  "embedding": [float] or null (384-dimensional),
  "context_before": "string or null",
  "context_after": "string or null",
  "is_shared": "boolean",
  "collection_ids": ["uuid"] or null,
  "created_at": "datetime",
  "updated_at": "datetime"
}
```

## Module Structure

The Annotations module is implemented as a self-contained vertical slice:

**Module**: `app.modules.annotations`  
**Router Prefix**: `/annotations`  
**Version**: 1.0.0

```python
from app.modules.annotations import (
    annotations_router,
    AnnotationService,
    AnnotationCreate,
    AnnotationUpdate,
    AnnotationResponse
)
```

### Events

**Emitted Events:**
- `annotation.created` - When a new annotation is created
- `annotation.updated` - When an annotation is modified
- `annotation.deleted` - When an annotation is removed

**Subscribed Events:**
- `resource.deleted` - Cascade deletes annotations for deleted resources

## Related Documentation

- [Resources API](resources.md) - Content management
- [Search API](search.md) - Search capabilities
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [API Overview](overview.md) - Authentication, errors


<div style='page-break-after: always;'></div>

---



# 11. Taxonomy API

*Source: `backend/docs/api/taxonomy.md`*

---

ï»¿# Taxonomy API

Hierarchical taxonomy management and ML-powered classification endpoints.

## Overview

The Taxonomy API provides:
- CRUD operations for hierarchical taxonomy trees
- Materialized paths for efficient queries
- ML-powered resource classification
- Active learning for continuous model improvement
- Authority control for subjects and classification

## Taxonomy Management Endpoints

### POST /taxonomy/nodes

Create a new taxonomy node in the hierarchical tree.

**Request Body:**
```json
{
  "name": "Machine Learning",
  "parent_id": "550e8400-e29b-41d4-a716-446655440000",
  "description": "ML and deep learning topics",
  "keywords": ["neural networks", "deep learning"],
  "allow_resources": true
}
```

**Response (200 OK):**
```json
{
  "id": "660e8400-e29b-41d4-a716-446655440001",
  "name": "Machine Learning",
  "slug": "machine-learning",
  "parent_id": "550e8400-e29b-41d4-a716-446655440000",
  "level": 1,
  "path": "/computer-science/machine-learning",
  "description": "ML and deep learning topics",
  "keywords": ["neural networks", "deep learning"],
  "resource_count": 0,
  "descendant_resource_count": 0,
  "is_leaf": true,
  "allow_resources": true,
  "created_at": "2024-01-01T10:00:00Z",
  "updated_at": "2024-01-01T10:00:00Z"
}
```

---

### PUT /taxonomy/nodes/{node_id}

Update taxonomy node metadata.

**Request Body:**
```json
{
  "name": "Deep Learning",
  "description": "Neural networks with multiple layers",
  "keywords": ["CNN", "RNN", "transformers"],
  "allow_resources": true
}
```

**Note:** To change parent, use the move endpoint instead.

---

### DELETE /taxonomy/nodes/{node_id}

Delete a taxonomy node.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `cascade` | boolean | Delete descendants vs reparent children | false |

**Behavior:**
- `cascade=false`: Child nodes reparented to deleted node's parent
- `cascade=true`: All descendant nodes deleted recursively
- Fails if node has assigned resources

---

### POST /taxonomy/nodes/{node_id}/move

Move a taxonomy node to a different parent.

**Request Body:**
```json
{
  "new_parent_id": "770e8400-e29b-41d4-a716-446655440002"
}
```

**Validation:**
- Prevents circular references
- Prevents self-parenting
- Updates level and path for node and all descendants

---

### GET /taxonomy/tree

Retrieve the hierarchical taxonomy tree as nested JSON.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `root_id` | string | Starting node UUID | null (all roots) |
| `max_depth` | integer | Maximum tree depth | null (unlimited) |

**Response:** Nested tree structure with `children` arrays.

---

### GET /taxonomy/nodes/{node_id}/ancestors

Get all ancestor nodes for breadcrumb navigation.

**Performance:** O(depth) using materialized path, typically <10ms

---

### GET /taxonomy/nodes/{node_id}/descendants

Get all descendant nodes at any depth.

**Performance:** O(1) query using path pattern matching, typically <10ms

---

## Authority Control Endpoints

### GET /authority/subjects/suggest

Get subject suggestions for autocomplete.

**Query Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `q` | string | Search query (required) |

**Response:**
```json
["Machine Learning", "Artificial Intelligence", "Data Science"]
```

---

### GET /authority/classification/tree

Retrieve the hierarchical classification tree (Dewey-style).

**Response:**
```json
{
  "tree": [
    {
      "code": "000",
      "name": "General",
      "description": "General knowledge and reference",
      "children": [
        {
          "code": "004",
          "name": "Computer Science",
          "description": "Computer science and programming",
          "children": []
        }
      ]
    }
  ]
}
```

---

### GET /classification/tree

Alternative endpoint for classification tree (same response).

---

## ML Classification Endpoints

### POST /taxonomy/classify/{resource_id}

Classify a resource using the fine-tuned ML model.

**Response (202 Accepted):**
```json
{
  "status": "accepted",
  "message": "Classification task enqueued",
  "resource_id": "550e8400-e29b-41d4-a716-446655440000"
}
```

**Background Processing:**
1. Load ML model (lazy loading)
2. Extract resource content
3. Predict taxonomy categories with confidence scores
4. Filter predictions (confidence >= 0.3)
5. Store classifications
6. Flag low-confidence predictions (< 0.7) for review

---

### GET /taxonomy/active-learning/uncertain

Get resources with uncertain classifications for human review.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `limit` | integer | Number of samples (1-1000) | 100 |

**Response:**
```json
[
  {
    "resource_id": "550e8400-e29b-41d4-a716-446655440000",
    "title": "Introduction to Neural Networks",
    "uncertainty_score": 0.87,
    "predicted_categories": [
      {
        "taxonomy_node_id": "660e8400-e29b-41d4-a716-446655440001",
        "name": "Machine Learning",
        "confidence": 0.65
      }
    ]
  }
]
```

**Uncertainty Metrics:**
- **Entropy**: Prediction uncertainty across all classes
- **Margin**: Difference between top-2 predictions
- **Confidence**: Maximum probability

---

### POST /taxonomy/active-learning/feedback

Submit human classification feedback.

**Request Body:**
```json
{
  "resource_id": "550e8400-e29b-41d4-a716-446655440000",
  "correct_taxonomy_ids": ["node_id_1", "node_id_2"]
}
```

**Response:**
```json
{
  "updated": true,
  "message": "Feedback recorded successfully",
  "manual_labels_count": 87,
  "retraining_threshold": 100,
  "retraining_recommended": false
}
```

---

### POST /taxonomy/train

Initiate ML model fine-tuning.

**Request Body:**
```json
{
  "labeled_data": [
    {
      "text": "Introduction to neural networks",
      "taxonomy_ids": ["node_id_1", "node_id_2"]
    }
  ],
  "unlabeled_texts": ["Article about CNNs..."],
  "epochs": 3,
  "batch_size": 16,
  "learning_rate": 2e-5
}
```

**Response (202 Accepted):**
```json
{
  "status": "accepted",
  "message": "Training task enqueued",
  "training_id": "990e8400-e29b-41d4-a716-446655440004",
  "labeled_examples": 150,
  "unlabeled_examples": 5000,
  "estimated_duration_minutes": 15
}
```

**Semi-Supervised Learning:**
- High-confidence predictions (>= 0.9) become pseudo-labels
- Enables effective training with <500 labeled examples

## Data Models

### Taxonomy Node Model

```json
{
  "id": "uuid",
  "name": "string",
  "slug": "string",
  "parent_id": "uuid or null",
  "level": "integer",
  "path": "string (materialized path)",
  "description": "string or null",
  "keywords": ["string"],
  "resource_count": "integer",
  "descendant_resource_count": "integer",
  "is_leaf": "boolean",
  "allow_resources": "boolean",
  "created_at": "datetime",
  "updated_at": "datetime"
}
```

## Module Structure

The Taxonomy module is implemented as a self-contained vertical slice:

**Module**: `app.modules.taxonomy`  
**Router Prefix**: `/taxonomy`  
**Version**: 1.0.0

```python
from app.modules.taxonomy import (
    taxonomy_router,
    TaxonomyService,
    MLClassificationService,
    ClassificationService,
    TaxonomyNode,
    ClassificationResult
)
```

### Events

**Emitted Events:**
- `resource.classified` - When a resource is classified
- `taxonomy.node_created` - When a taxonomy node is added
- `taxonomy.model_trained` - When the ML model is retrained

**Subscribed Events:**
- `resource.created` - Triggers automatic classification

## Related Documentation

- [Resources API](resources.md) - Content management
- [Quality API](quality.md) - Quality assessment
- [Authority API](authority.md) - Subject authority
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [API Overview](overview.md) - Authentication, errors


<div style='page-break-after: always;'></div>

---



# 12. Graph API

*Source: `backend/docs/api/graph.md`*

---

ï»¿# Graph API

Knowledge graph and citation network endpoints for relationship exploration.

## Overview

The Graph API provides:
- Knowledge graph for resource relationships
- Citation network analysis
- Mind-map visualization data
- PageRank importance scoring

## Knowledge Graph Endpoints

### GET /graph/resource/{resource_id}/neighbors

Find related resources for mind-map visualization.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `limit` | integer | Number of neighbors (1-50) | 7 |

**Response:**
```json
{
  "nodes": [
    {
      "id": "550e8400-e29b-41d4-a716-446655440000",
      "title": "Machine Learning Fundamentals",
      "type": "article",
      "classification_code": "004"
    }
  ],
  "edges": [
    {
      "source": "550e8400-e29b-41d4-a716-446655440000",
      "target": "550e8400-e29b-41d4-a716-446655440001",
      "weight": 0.76,
      "details": {
        "connection_type": "classification",
        "vector_similarity": 0.8,
        "shared_subjects": ["python", "programming"]
      }
    }
  ]
}
```

---

### GET /graph/overview

Get global relationship overview of strongest connections across the library.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `limit` | integer | Number of edges (1-200) | 50 |
| `vector_threshold` | float | Minimum vector similarity | 0.85 |

**Response:** Same structure as neighbors endpoint with `connection_type: "hybrid"`.

---

## Citation Network Endpoints

### GET /citations/resources/{resource_id}/citations

Retrieve all citations for a specific resource.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `direction` | string | `outbound`, `inbound`, or `both` | both |

**Response:**
```json
{
  "resource_id": "uuid",
  "outbound": [
    {
      "id": "uuid",
      "source_resource_id": "uuid",
      "target_url": "string",
      "target_resource_id": "uuid or null",
      "citation_type": "reference|dataset|code|general",
      "context_snippet": "string or null",
      "position": "integer or null",
      "importance_score": "float or null",
      "created_at": "datetime",
      "target_resource": {
        "id": "uuid",
        "title": "string",
        "source": "string"
      }
    }
  ],
  "inbound": [...],
  "counts": {
    "outbound": 5,
    "inbound": 3,
    "total": 8
  }
}
```

**Example:**
```bash
# Get all citations
curl "http://127.0.0.1:8000/citations/resources/{resource_id}/citations"

# Get only outbound citations
curl "http://127.0.0.1:8000/citations/resources/{resource_id}/citations?direction=outbound"
```

---

### GET /citations/graph/citations

Get citation network for visualization.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `resource_ids` | string[] | Filter to specific resources | - |
| `min_importance` | float | Minimum importance score (0.0-1.0) | 0.0 |
| `depth` | integer | Graph traversal depth (1-2) | 1 |

**Response:**
```json
{
  "nodes": [
    {
      "id": "uuid",
      "title": "string",
      "type": "source|cited|citing"
    }
  ],
  "edges": [
    {
      "source": "uuid",
      "target": "uuid",
      "type": "reference|dataset|code|general"
    }
  ]
}
```

**Performance Notes:**
- Results limited to 100 nodes maximum
- Depth capped at 2 to prevent exponential explosion

---

### POST /citations/resources/{resource_id}/citations/extract

Manually trigger citation extraction for a resource.

**Response (202 Accepted):**
```json
{
  "status": "queued",
  "resource_id": "uuid",
  "message": "Citation extraction queued for processing"
}
```

**Background Processing:**
1. Retrieve resource content from archive
2. Determine content type (HTML, PDF, Markdown)
3. Extract citations using appropriate parser
4. Classify citation types
5. Extract context snippets
6. Store citations and trigger resolution

---

### POST /citations/resolve

Trigger internal citation resolution to match URLs to existing resources.

**Response (202 Accepted):**
```json
{
  "status": "queued"
}
```

**Processing:**
- Queries citations with `target_resource_id = NULL`
- Normalizes URLs and matches to existing resources
- Processes in batches of 100

---

### POST /citations/importance/compute

Recompute PageRank importance scores for all citations.

**Response (202 Accepted):**
```json
{
  "status": "queued"
}
```

**Algorithm:**
- Damping factor: 0.85
- Max iterations: 100
- Convergence threshold: 1e-6
- Normalizes scores to [0, 1] range

**Performance:**
- Small graphs (<100 nodes): <1s
- Medium graphs (100-1000 nodes): <5s
- Large graphs (1000+ nodes): <30s

---

## Citation Type Classification

The system automatically classifies citations:

| Type | Indicators |
|------|------------|
| `dataset` | File extensions: `.csv`, `.json`, `.xml`, `.xlsx` |
| `code` | Domains: `github.com`, `gitlab.com`, `bitbucket.org` |
| `reference` | Domains: `doi.org`, `arxiv.org`, `scholar.google` |
| `general` | All other URLs |

## Data Models

### Graph Response Model

```json
{
  "nodes": [
    {
      "id": "uuid",
      "title": "string",
      "type": "string",
      "classification_code": "string"
    }
  ],
  "edges": [
    {
      "source": "uuid",
      "target": "uuid",
      "weight": "float (0.0-1.0)",
      "details": {
        "connection_type": "vector|subject|classification|hybrid",
        "vector_similarity": "float",
        "shared_subjects": ["string"],
        "classification_match": "boolean"
      }
    }
  ]
}
```

### Citation Model

```json
{
  "id": "uuid",
  "source_resource_id": "uuid",
  "target_resource_id": "uuid or null",
  "target_url": "string",
  "citation_type": "reference|dataset|code|general",
  "context_snippet": "string or null",
  "position": "integer or null",
  "importance_score": "float or null (0.0-1.0)",
  "created_at": "datetime",
  "updated_at": "datetime"
}
```

## Integration Examples

### Periodic Citation Resolution

```bash
# Cron job (daily at 2 AM)
0 2 * * * curl -X POST http://127.0.0.1:8000/citations/resolve
```

### Periodic Importance Updates

```bash
# Cron job (weekly on Sunday at 3 AM)
0 3 * * 0 curl -X POST http://127.0.0.1:8000/citations/importance/compute
```

### Citation Network Visualization

```javascript
const response = await fetch(
  `/citations/graph/citations?resource_ids=${resourceId}&depth=2`
);
const graph = await response.json();
renderGraph(graph.nodes, graph.edges);
```

## Module Structure

The Graph module is implemented as a self-contained vertical slice:

**Module**: `app.modules.graph`  
**Router Prefix**: `/graph`, `/citations`, `/discovery`  
**Version**: 1.0.0

```python
from app.modules.graph import (
    graph_router,
    citations_router,
    discovery_router,
    GraphService,
    CitationService,
    LBDService,
    GraphEdge,
    Citation,
    DiscoveryHypothesis
)
```

### Events

**Emitted Events:**
- `citation.extracted` - When citations are extracted from a resource
- `graph.updated` - When the knowledge graph is updated
- `hypothesis.discovered` - When a new discovery hypothesis is generated

**Subscribed Events:**
- `resource.created` - Extracts citations and updates graph
- `resource.deleted` - Removes resource from graph

## Related Documentation

- [Resources API](resources.md) - Content management
- [Search API](search.md) - Discovery features
- [Recommendations API](recommendations.md) - Related content
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [API Overview](overview.md) - Authentication, errors


<div style='page-break-after: always;'></div>

---



# 13. Recommendations API

*Source: `backend/docs/api/recommendations.md`*

---

ï»¿# Recommendations API

Personalized content recommendation endpoints using hybrid strategies.

## Overview

The Recommendations API provides:
- Multi-strategy recommendations (collaborative, content, graph)
- User profile learning from interactions
- Diversity optimization with MMR
- Novelty promotion for discovery
- Cold start handling for new users

## Endpoints

### GET /recommendations

Get personalized content recommendations based on library content.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `limit` | integer | Number of recommendations (1-100) | 10 |

**Response:**
```json
{
  "items": [
    {
      "url": "https://example.com/new-ml-article",
      "title": "Latest Advances in Machine Learning",
      "snippet": "Recent developments in ML algorithms",
      "relevance_score": 0.85,
      "reasoning": ["Aligned with Machine Learning, Python"]
    }
  ]
}
```

**Example:**
```bash
curl "http://127.0.0.1:8000/recommendations?limit=5"
```

---

### GET /api/recommendations

Get personalized recommendations using hybrid strategy (Phase 11).

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `limit` | integer | Number of recommendations (1-100) | 20 |
| `strategy` | string | Recommendation strategy | hybrid |
| `diversity` | float | Diversity preference (0.0-1.0) | user profile |
| `min_quality` | float | Minimum quality threshold (0.0-1.0) | 0.0 |

**Strategy Options:**
- `collaborative` - Neural Collaborative Filtering (requires â‰¥5 interactions)
- `content` - Content-based similarity only
- `graph` - Graph-based relationships only
- `hybrid` - Combines all strategies (default)

**Response:**
```json
{
  "recommendations": [
    {
      "resource_id": "550e8400-e29b-41d4-a716-446655440000",
      "title": "Advanced Machine Learning Techniques",
      "description": "Comprehensive guide to modern ML algorithms",
      "score": 0.87,
      "strategy": "hybrid",
      "scores": {
        "collaborative": 0.92,
        "content": 0.85,
        "graph": 0.78,
        "quality": 0.88,
        "recency": 0.65
      },
      "rank": 1,
      "novelty_score": 0.42,
      "source": "https://example.com/ml-guide",
      "classification_code": "004",
      "created_at": "2024-01-15T10:00:00Z"
    }
  ],
  "metadata": {
    "total": 20,
    "strategy": "hybrid",
    "diversity_applied": true,
    "gini_coefficient": 0.24,
    "user_interactions": 47,
    "cold_start": false
  }
}
```

**Hybrid Scoring Formula:**
```
hybrid_score = 
  0.35 * collaborative_score +
  0.30 * content_score +
  0.20 * graph_score +
  0.10 * quality_score +
  0.05 * recency_score
```

**Performance:**
- Target latency: <200ms for 20 recommendations
- Cache hit rate: >80% for user embeddings

**Cold Start Behavior:**
- Users with <5 interactions: Uses content + graph strategies only
- Collaborative filtering enabled after 5+ interactions

---

### POST /api/interactions

Track user-resource interactions for personalized learning.

**Request Body:**
```json
{
  "resource_id": "550e8400-e29b-41d4-a716-446655440000",
  "interaction_type": "view",
  "dwell_time": 45,
  "scroll_depth": 0.8,
  "session_id": "session_abc123"
}
```

**Interaction Types:**

| Type | Strength | Description |
|------|----------|-------------|
| `view` | 0.1-0.5 | Based on dwell time and scroll depth |
| `annotation` | 0.7 | User annotated the resource |
| `collection_add` | 0.8 | User added to collection |
| `export` | 0.9 | User exported the resource |
| `rating` | varies | Based on rating value |

**Response (201 Created):**
```json
{
  "id": "660e8400-e29b-41d4-a716-446655440001",
  "user_id": "user123",
  "resource_id": "550e8400-e29b-41d4-a716-446655440000",
  "interaction_type": "view",
  "interaction_strength": 0.42,
  "is_positive": true,
  "confidence": 0.85,
  "dwell_time": 45,
  "scroll_depth": 0.8,
  "return_visits": 1,
  "interaction_timestamp": "2024-01-15T14:30:00Z"
}
```

## Features

### Multi-Strategy Recommendations

The hybrid engine combines multiple strategies:

1. **Collaborative Filtering (NCF)**
   - Learns from user interaction patterns
   - Requires â‰¥5 interactions to activate
   - Uses neural network for user-item embeddings

2. **Content-Based Similarity**
   - Uses resource embeddings for semantic similarity
   - Works immediately for new users
   - Based on resource metadata and content

3. **Graph-Based Discovery**
   - Leverages knowledge graph relationships
   - Finds resources through citation networks
   - Discovers related topics through classification

### Diversity Optimization

Uses Maximal Marginal Relevance (MMR) to:
- Prevent filter bubbles
- Balance relevance with diversity
- Surface varied content types

### Novelty Promotion

Surfaces lesser-known but relevant resources:
- Tracks resource popularity
- Boosts underexposed quality content
- Balances popular vs. niche recommendations

## Data Models

### Recommendation Response Model

```json
{
  "items": [
    {
      "url": "string",
      "title": "string",
      "snippet": "string",
      "relevance_score": "float (0.0-1.0)",
      "reasoning": ["string"]
    }
  ]
}
```

### Interaction Model

```json
{
  "id": "uuid",
  "user_id": "string",
  "resource_id": "uuid",
  "interaction_type": "view|annotation|collection_add|export|rating",
  "interaction_strength": "float (0.0-1.0)",
  "is_positive": "boolean",
  "confidence": "float (0.0-1.0)",
  "dwell_time": "integer (seconds)",
  "scroll_depth": "float (0.0-1.0)",
  "return_visits": "integer",
  "interaction_timestamp": "datetime"
}
```

## Module Structure

The Recommendations module is implemented as a self-contained vertical slice:

**Module**: `app.modules.recommendations`  
**Router Prefix**: `/recommendations`  
**Version**: 1.0.0

```python
from app.modules.recommendations import (
    recommendations_router,
    RecommendationService,
    HybridRecommendationService,
    CollaborativeFilteringService,
    NCFService,
    UserProfileService,
    RecommendationRequest,
    RecommendationResponse
)
```

### Events

**Emitted Events:**
- `recommendation.generated` - When recommendations are generated
- `user.profile_updated` - When user profile is updated
- `interaction.recorded` - When user interaction is recorded

**Subscribed Events:**
- `annotation.created` - Updates user profile
- `collection.resource_added` - Updates user profile

## Related Documentation

- [Resources API](resources.md) - Content management
- [Search API](search.md) - Discovery features
- [Graph API](graph.md) - Knowledge graph
- [Collections API](collections.md) - Collection recommendations
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [API Overview](overview.md) - Authentication, errors


<div style='page-break-after: always;'></div>

---



# 14. Quality API

*Source: `backend/docs/api/quality.md`*

---

ï»¿# Quality API

Multi-dimensional quality assessment endpoints for resource evaluation.

## Overview

The Quality API provides:
- Multi-dimensional quality scoring (accuracy, completeness, consistency, timeliness, relevance)
- Quality outlier detection using Isolation Forest
- Quality degradation monitoring over time
- Summary quality evaluation (G-Eval, FineSurE, BERTScore)
- Quality distribution analytics and trends

## Endpoints

### GET /resources/{id}/quality-details

Retrieve full quality dimension breakdown for a resource.

**Response (200 OK):**
```json
{
  "resource_id": "550e8400-e29b-41d4-a716-446655440000",
  "quality_dimensions": {
    "accuracy": 0.75,
    "completeness": 0.82,
    "consistency": 0.88,
    "timeliness": 0.65,
    "relevance": 0.79
  },
  "quality_overall": 0.77,
  "quality_weights": {
    "accuracy": 0.30,
    "completeness": 0.25,
    "consistency": 0.20,
    "timeliness": 0.15,
    "relevance": 0.10
  },
  "quality_last_computed": "2025-11-10T12:00:00Z",
  "quality_computation_version": "v2.0",
  "is_quality_outlier": false,
  "outlier_score": null,
  "outlier_reasons": null,
  "needs_quality_review": false
}
```

**Quality Dimensions:**
- **Accuracy (0.0-1.0)**: Citation validity, source credibility, scholarly metadata
- **Completeness (0.0-1.0)**: Metadata coverage, content depth, multi-modal content
- **Consistency (0.0-1.0)**: Title-content alignment, internal coherence
- **Timeliness (0.0-1.0)**: Publication recency, content freshness
- **Relevance (0.0-1.0)**: Classification confidence, citation count

---

### POST /quality/recalculate

Trigger quality recomputation with optional custom weights.

**Request Body:**
```json
{
  "resource_id": "550e8400-e29b-41d4-a716-446655440000",
  "weights": {
    "accuracy": 0.35,
    "completeness": 0.25,
    "consistency": 0.20,
    "timeliness": 0.10,
    "relevance": 0.10
  }
}
```

**Note:** Provide either `resource_id` or `resource_ids` (array), not both. Weights must sum to 1.0.

**Response (202 Accepted):**
```json
{
  "status": "queued",
  "message": "Quality computation queued for background processing"
}
```

---

### GET /quality/outliers

Retrieve paginated list of detected quality outliers.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `page` | integer | Page number | 1 |
| `limit` | integer | Results per page (1-100) | 50 |
| `min_outlier_score` | float | Minimum anomaly score (-1.0 to 1.0) | null |
| `reason` | string | Filter by outlier reason | null |

**Outlier Reasons:**
- `low_accuracy`, `low_completeness`, `low_consistency`, `low_timeliness`, `low_relevance`
- `low_summary_coherence`, `low_summary_consistency`, `low_summary_fluency`, `low_summary_relevance`

**Response:**
```json
{
  "total": 42,
  "page": 1,
  "limit": 50,
  "outliers": [
    {
      "resource_id": "550e8400-e29b-41d4-a716-446655440000",
      "title": "Resource Title",
      "quality_overall": 0.35,
      "outlier_score": -0.82,
      "outlier_reasons": ["low_accuracy", "low_completeness"],
      "needs_quality_review": true,
      "quality_last_computed": "2025-11-10T12:00:00Z"
    }
  ]
}
```

**Outlier Score Interpretation:**
- Lower scores indicate higher anomaly likelihood
- Scores < -0.5 are typically significant outliers
- Uses Isolation Forest with contamination=0.1

---

### GET /quality/degradation

Monitor quality degradation over time.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `time_window_days` | integer | Lookback period in days | 30 |

**Response:**
```json
{
  "time_window_days": 30,
  "degraded_count": 15,
  "degraded_resources": [
    {
      "resource_id": "550e8400-e29b-41d4-a716-446655440000",
      "title": "Resource Title",
      "old_quality": 0.85,
      "new_quality": 0.62,
      "degradation_pct": 27.1,
      "quality_last_computed": "2025-10-15T12:00:00Z"
    }
  ]
}
```

**Detection:** Flags resources with >20% quality drop.

---

### POST /summaries/{id}/evaluate

Trigger summary quality evaluation using G-Eval, FineSurE, and BERTScore.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `use_g_eval` | boolean | Use GPT-4 for G-Eval metrics | false |

**Response (202 Accepted):**
```json
{
  "status": "queued",
  "message": "Summary evaluation queued for background processing"
}
```

**Evaluation Metrics:**
- **G-Eval (optional)**: Coherence, consistency, fluency, relevance (1-5 scale)
- **FineSurE**: Completeness and conciseness (0.0-1.0)
- **BERTScore**: Semantic similarity F1 score (0.0-1.0)

**Performance:**
- Without G-Eval: <2 seconds per resource
- With G-Eval: <10 seconds per resource

---

### GET /quality/distribution

Retrieve quality score distribution histogram.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `bins` | integer | Number of histogram bins (1-50) | 10 |
| `dimension` | string | Dimension or "overall" | overall |

**Response:**
```json
{
  "dimension": "overall",
  "bins": 10,
  "distribution": [
    {"range": "0.0-0.1", "count": 5},
    {"range": "0.1-0.2", "count": 12},
    ...
  ],
  "statistics": {
    "mean": 0.65,
    "median": 0.68,
    "std_dev": 0.18,
    "min": 0.12,
    "max": 0.98,
    "total_resources": 494
  }
}
```

---

### GET /quality/trends

Retrieve quality trends over time.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `granularity` | string | daily, weekly, monthly | weekly |
| `start_date` | date | Start of range (ISO 8601) | 90 days ago |
| `end_date` | date | End of range (ISO 8601) | today |
| `dimension` | string | Dimension or "overall" | overall |

**Response:**
```json
{
  "dimension": "overall",
  "granularity": "weekly",
  "data_points": [
    {
      "period": "2025-W31",
      "avg_quality": 0.72,
      "resource_count": 145,
      "date": "2025-08-03"
    }
  ]
}
```

---

### GET /quality/dimensions

Retrieve average scores per dimension across all resources.

**Response:**
```json
{
  "dimensions": {
    "accuracy": {"avg": 0.75, "min": 0.12, "max": 0.98, "std_dev": 0.15},
    "completeness": {"avg": 0.68, "min": 0.25, "max": 0.95, "std_dev": 0.18},
    ...
  },
  "overall": {"avg": 0.71, "min": 0.28, "max": 0.96, "std_dev": 0.16},
  "total_resources": 1247
}
```

---

### GET /quality/review-queue

Retrieve resources flagged for quality review.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `page` | integer | Page number | 1 |
| `limit` | integer | Results per page (1-100) | 50 |
| `sort_by` | string | outlier_score, quality_overall, updated_at | outlier_score |

---

## Curation Endpoints

### GET /curation/review-queue

Access low-quality items for review and curation.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `threshold` | float | Quality threshold | null |
| `include_unread_only` | boolean | Include only unread | false |
| `limit` | integer | Number of items (1-100) | 25 |
| `offset` | integer | Results to skip | 0 |

---

### GET /curation/low-quality

Get resources with quality scores below threshold.

**Query Parameters:**

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `threshold` | float | Quality threshold (0.0-1.0) | 0.5 |
| `limit` | integer | Number of items (1-100) | 25 |

---

### GET /curation/quality-analysis/{resource_id}

Get detailed quality analysis for a specific resource.

**Response:**
```json
{
  "resource_id": "550e8400-e29b-41d4-a716-446655440000",
  "metadata_completeness": 0.8,
  "readability": {
    "flesch_kincaid": 12.5,
    "gunning_fog": 14.2,
    "automated_readability": 11.8
  },
  "source_credibility": 0.7,
  "content_depth": 0.6,
  "overall_quality": 0.7,
  "quality_level": "good",
  "suggestions": [
    "Improve metadata completeness",
    "Add more detailed description"
  ]
}
```

---

### POST /curation/batch-update

Apply partial updates to multiple resources.

**Request Body:**
```json
{
  "resource_ids": ["uuid1", "uuid2"],
  "updates": {
    "read_status": "in_progress",
    "subject": ["Updated", "Tags"]
  }
}
```

---

### POST /curation/bulk-quality-check

Perform quality analysis on multiple resources.

**Request Body:**
```json
{
  "resource_ids": ["uuid1", "uuid2"]
}
```

## Quality Dimension Algorithms

**Accuracy:**
```
accuracy = 0.5 (baseline)
  + 0.20 * (valid_citations / total_citations)
  + 0.15 * (1 if credible_domain else 0)
  + 0.15 * (1 if has_academic_identifier else 0)
  + 0.10 * (1 if has_authors else 0)
```

**Completeness:**
```
completeness = 
  0.30 * (filled_required_fields / 3)
  + 0.30 * (filled_important_fields / 4)
  + 0.20 * (filled_scholarly_fields / 4)
  + 0.20 * (multimodal_content_score / 3)
```

**Timeliness:**
```
age_years = current_year - publication_year
recency_score = max(0.0, 1.0 - (age_years / 20))
timeliness = recency_score + (0.1 if ingested_within_30_days else 0)
```

## Module Structure

The Quality module is implemented as a self-contained vertical slice:

**Module**: `app.modules.quality`  
**Router Prefix**: `/quality`  
**Version**: 1.0.0

```python
from app.modules.quality import (
    quality_router,
    QualityService,
    SummarizationEvaluator,
    QualityDimensions,
    QualityResponse,
    OutlierReport
)
```

### Events

**Emitted Events:**
- `quality.computed` - When quality scores are calculated
- `quality.outlier_detected` - When anomalous quality is found
- `quality.degradation_detected` - When quality degrades over time

**Subscribed Events:**
- `resource.created` - Triggers initial quality computation
- `resource.updated` - Recomputes quality on changes

## Related Documentation

- [Resources API](resources.md) - Content management
- [Taxonomy API](taxonomy.md) - Classification
- [Curation API](curation.md) - Content review
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [API Overview](overview.md) - Authentication, errors


<div style='page-break-after: always;'></div>

---



# 15. Scholarly API

*Source: `backend/docs/api/scholarly.md`*

---

# Scholarly API

## Overview

The Scholarly module provides academic metadata extraction from resources, including equations, tables, citations, and scholarly metadata.

**Module**: `app.modules.scholarly`  
**Router Prefix**: `/scholarly`  
**Version**: 1.0.0

## Endpoints

### Extract Metadata

Extract scholarly metadata from a resource.

```http
POST /scholarly/extract/{resource_id}
```

**Path Parameters:**
- `resource_id` (integer, required) - Resource ID

**Response:**
```json
{
  "resource_id": 1,
  "equations": [
    {
      "id": 1,
      "latex": "E = mc^2",
      "context": "Einstein's mass-energy equivalence"
    }
  ],
  "tables": [
    {
      "id": 1,
      "caption": "Experimental Results",
      "data": {...}
    }
  ],
  "metadata": {
    "authors": ["John Doe"],
    "publication_date": "2024-01-01",
    "journal": "Nature",
    "doi": "10.1234/example"
  }
}
```

### Get Resource Metadata

Get scholarly metadata for a resource.

```http
GET /scholarly/resources/{resource_id}/metadata
```

**Path Parameters:**
- `resource_id` (integer, required) - Resource ID

**Response:**
```json
{
  "resource_id": 1,
  "authors": ["John Doe", "Jane Smith"],
  "publication_date": "2024-01-01",
  "journal": "Nature",
  "volume": "123",
  "issue": "4",
  "pages": "567-890",
  "doi": "10.1234/example",
  "abstract": "This paper presents..."
}
```

### Get Equations

Get all equations extracted from a resource.

```http
GET /scholarly/resources/{resource_id}/equations
```

**Path Parameters:**
- `resource_id` (integer, required) - Resource ID

**Response:**
```json
{
  "equations": [
    {
      "id": 1,
      "latex": "E = mc^2",
      "context": "Einstein's mass-energy equivalence",
      "position": 42
    }
  ]
}
```

### Get Tables

Get all tables extracted from a resource.

```http
GET /scholarly/resources/{resource_id}/tables
```

**Path Parameters:**
- `resource_id` (integer, required) - Resource ID

**Response:**
```json
{
  "tables": [
    {
      "id": 1,
      "caption": "Experimental Results",
      "headers": ["Condition", "Result", "P-value"],
      "rows": [
        ["Control", "0.5", "0.001"],
        ["Treatment", "0.8", "0.001"]
      ]
    }
  ]
}
```

### Health Check

Check module health status.

```http
GET /scholarly/health
```

**Response:**
```json
{
  "status": "healthy",
  "module": "scholarly",
  "version": "1.0.0"
}
```

## Events

### Emitted Events

- `metadata.extracted` - When scholarly metadata is extracted
- `equations.parsed` - When equations are parsed from content
- `tables.extracted` - When tables are extracted from content

### Subscribed Events

- `resource.created` - Triggers automatic metadata extraction

## Module Structure

```python
from app.modules.scholarly import (
    scholarly_router,
    MetadataExtractor,
    ScholarlyMetadata,
    Equation,
    Table
)
```

## Related Documentation

- [Architecture: Modules](../architecture/modules.md)
- [Architecture: Events](../architecture/events.md)
- [Resources API](resources.md)


<div style='page-break-after: always;'></div>

---



# 16. Authority API

*Source: `backend/docs/api/authority.md`*

---

# Authority API

## Overview

The Authority module manages subject authority files and classification trees, providing controlled vocabularies for resource organization.

**Module**: `app.modules.authority`  
**Router Prefix**: `/authority`  
**Version**: 1.0.0

## Endpoints

### Get Subject Suggestions

Get subject heading suggestions based on input text.

```http
GET /authority/subjects/suggest?q={query}&limit={limit}
```

**Query Parameters:**
- `q` (string, required) - Search query
- `limit` (integer, optional) - Maximum results (default: 10)

**Response:**
```json
{
  "suggestions": [
    {
      "heading": "Machine Learning",
      "code": "006.31",
      "confidence": 0.95,
      "broader_terms": ["Artificial Intelligence"],
      "narrower_terms": ["Deep Learning", "Neural Networks"]
    }
  ]
}
```

### Get Classification Tree

Get the complete classification tree or a subtree.

```http
GET /authority/classification/tree?root={code}&depth={depth}
```

**Query Parameters:**
- `root` (string, optional) - Root classification code (default: top level)
- `depth` (integer, optional) - Tree depth (default: unlimited)

**Response:**
```json
{
  "tree": {
    "code": "000",
    "label": "Computer Science",
    "children": [
      {
        "code": "006",
        "label": "Special Computer Methods",
        "children": [
          {
            "code": "006.3",
            "label": "Artificial Intelligence",
            "children": []
          }
        ]
      }
    ]
  }
}
```

### Health Check

Check module health status.

```http
GET /authority/health
```

**Response:**
```json
{
  "status": "healthy",
  "module": "authority",
  "version": "1.0.0"
}
```

## Module Structure

```python
from app.modules.authority import (
    authority_router,
    AuthorityService,
    SubjectHeading,
    ClassificationNode
)
```

## Related Documentation

- [Architecture: Modules](../architecture/modules.md)
- [Taxonomy API](taxonomy.md)
- [Resources API](resources.md)


<div style='page-break-after: always;'></div>

---



# 17. Curation API

*Source: `backend/docs/api/curation.md`*

---

# Curation API

## Overview

The Curation module provides content review workflows and batch operations for managing resource quality and organization.

**Module**: `app.modules.curation`  
**Router Prefix**: `/curation`  
**Version**: 1.0.0

## Endpoints

### Get Review Queue

Get resources pending review.

```http
GET /curation/review-queue?status={status}&limit={limit}&offset={offset}
```

**Query Parameters:**
- `status` (string, optional) - Filter by status: `pending`, `approved`, `rejected`
- `limit` (integer, optional) - Results per page (default: 25)
- `offset` (integer, optional) - Pagination offset (default: 0)

**Response:**
```json
{
  "items": [
    {
      "resource_id": 1,
      "title": "Example Resource",
      "status": "pending",
      "quality_score": 0.45,
      "flagged_reason": "Low quality score",
      "added_at": "2024-01-01T00:00:00Z"
    }
  ],
  "total": 42
}
```

### Review Resource

Submit a review decision for a resource.

```http
POST /curation/review/{resource_id}
```

**Path Parameters:**
- `resource_id` (integer, required) - Resource ID

**Request Body:**
```json
{
  "decision": "approved",
  "notes": "High quality content, well-structured",
  "tags": ["verified", "high-quality"]
}
```

**Response:**
```json
{
  "resource_id": 1,
  "decision": "approved",
  "reviewed_by": "curator@example.com",
  "reviewed_at": "2024-01-01T00:00:00Z"
}
```

### Batch Update

Perform batch operations on multiple resources.

```http
POST /curation/batch
```

**Request Body:**
```json
{
  "resource_ids": [1, 2, 3],
  "operation": "add_tags",
  "parameters": {
    "tags": ["reviewed", "approved"]
  }
}
```

**Supported Operations:**
- `add_tags` - Add tags to resources
- `remove_tags` - Remove tags from resources
- `update_classification` - Update classification
- `approve` - Approve resources
- `reject` - Reject resources

**Response:**
```json
{
  "success": 3,
  "failed": 0,
  "results": [
    {
      "resource_id": 1,
      "status": "success"
    }
  ]
}
```

### Get Curation Stats

Get curation statistics.

```http
GET /curation/stats
```

**Response:**
```json
{
  "pending": 42,
  "approved": 1234,
  "rejected": 56,
  "total_reviewed": 1290,
  "avg_review_time_hours": 2.5
}
```

### Health Check

Check module health status.

```http
GET /curation/health
```

**Response:**
```json
{
  "status": "healthy",
  "module": "curation",
  "version": "1.0.0"
}
```

## Events

### Emitted Events

- `curation.reviewed` - When a resource is reviewed
- `curation.approved` - When a resource is approved
- `curation.rejected` - When a resource is rejected

### Subscribed Events

- `quality.outlier_detected` - Adds resources to review queue

## Module Structure

```python
from app.modules.curation import (
    curation_router,
    CurationService,
    ReviewDecision,
    BatchOperation
)
```

## Related Documentation

- [Architecture: Modules](../architecture/modules.md)
- [Architecture: Events](../architecture/events.md)
- [Quality API](quality.md)
- [Resources API](resources.md)


<div style='page-break-after: always;'></div>

---



# 18. Monitoring API

*Source: `backend/docs/api/monitoring.md`*

---

ï»¿# Monitoring API

System monitoring, health checks, and metrics endpoints.

## Overview

The Monitoring API provides:
- Health check endpoints for load balancers
- System metrics and statistics
- Database connection monitoring
- Service status information

## Endpoints

### GET /health

Basic health check endpoint for load balancers and orchestration systems.

**Response (200 OK):**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T10:00:00Z"
}
```

**Response (503 Service Unavailable):**
```json
{
  "status": "unhealthy",
  "timestamp": "2024-01-01T10:00:00Z",
  "error": "Database connection failed"
}
```

**Use Cases:**
- Kubernetes liveness probes
- Load balancer health checks
- Uptime monitoring

**Example:**
```bash
curl http://127.0.0.1:8000/health
```

---

### GET /monitoring/status

Detailed system status with component health information.

**Response (200 OK):**
```json
{
  "status": "healthy",
  "version": "0.9.0",
  "uptime_seconds": 86400,
  "components": {
    "database": {
      "status": "healthy",
      "type": "postgresql",
      "connection_pool": {
        "size": 10,
        "available": 8,
        "in_use": 2
      }
    },
    "cache": {
      "status": "healthy",
      "type": "redis",
      "connected": true
    },
    "ml_models": {
      "status": "healthy",
      "embedding_model": "loaded",
      "classification_model": "loaded"
    }
  },
  "timestamp": "2024-01-01T10:00:00Z"
}
```

**Example:**
```bash
curl http://127.0.0.1:8000/monitoring/status
```

---

### GET /monitoring/metrics

System metrics and statistics.

**Response (200 OK):**
```json
{
  "resources": {
    "total": 10000,
    "by_status": {
      "completed": 9500,
      "pending": 300,
      "failed": 200
    },
    "by_type": {
      "article": 6000,
      "paper": 3000,
      "book": 1000
    }
  },
  "collections": {
    "total": 500,
    "by_visibility": {
      "private": 300,
      "public": 150,
      "shared": 50
    }
  },
  "annotations": {
    "total": 25000,
    "by_user_count": 150
  },
  "search": {
    "queries_last_hour": 1500,
    "avg_latency_ms": 145
  },
  "quality": {
    "avg_score": 0.72,
    "outliers_count": 42,
    "review_queue_size": 87
  },
  "timestamp": "2024-01-01T10:00:00Z"
}
```

**Example:**
```bash
curl http://127.0.0.1:8000/monitoring/metrics
```

---

### GET /monitoring/database

Database-specific monitoring information.

**Response (200 OK):**
```json
{
  "type": "postgresql",
  "version": "15.2",
  "connection": {
    "status": "connected",
    "pool_size": 10,
    "active_connections": 3,
    "idle_connections": 7
  },
  "tables": {
    "resources": {
      "row_count": 10000,
      "size_mb": 256
    },
    "annotations": {
      "row_count": 25000,
      "size_mb": 64
    },
    "collections": {
      "row_count": 500,
      "size_mb": 8
    }
  },
  "indexes": {
    "total": 45,
    "size_mb": 128
  },
  "timestamp": "2024-01-01T10:00:00Z"
}
```

---

## Integration Examples

### Kubernetes Liveness Probe

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
```

### Kubernetes Readiness Probe

```yaml
readinessProbe:
  httpGet:
    path: /monitoring/status
    port: 8000
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3
```

### Prometheus Metrics (Planned)

Future releases will expose Prometheus-compatible metrics at `/metrics`:

```
# HELP neo_alexandria_resources_total Total number of resources
# TYPE neo_alexandria_resources_total gauge
neo_alexandria_resources_total 10000

# HELP neo_alexandria_search_latency_seconds Search latency histogram
# TYPE neo_alexandria_search_latency_seconds histogram
neo_alexandria_search_latency_seconds_bucket{le="0.1"} 500
neo_alexandria_search_latency_seconds_bucket{le="0.2"} 1200
```

### Alerting Rules (Example)

```yaml
groups:
  - name: neo-alexandria
    rules:
      - alert: HighSearchLatency
        expr: neo_alexandria_search_latency_seconds > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High search latency detected"
          
      - alert: DatabaseConnectionPoolExhausted
        expr: neo_alexandria_db_pool_available == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database connection pool exhausted"
```

## Health Check Best Practices

1. **Use `/health` for simple checks** - Fast, lightweight, suitable for frequent polling
2. **Use `/monitoring/status` for detailed checks** - More comprehensive, use for debugging
3. **Set appropriate timeouts** - Health checks should respond within 5 seconds
4. **Monitor trends** - Track metrics over time to identify degradation

## Module Structure

The Monitoring module is implemented as a self-contained vertical slice:

**Module**: `app.modules.monitoring`  
**Router Prefix**: `/monitoring`, `/health`  
**Version**: 1.0.0

```python
from app.modules.monitoring import (
    monitoring_router,
    MonitoringService,
    HealthStatus,
    SystemMetrics
)
```

### Events

**Emitted Events:**
- None (Monitoring is a read-only aggregation module)

**Subscribed Events:**
- All events (for metrics aggregation)

## Related Documentation

- [API Overview](overview.md) - Authentication, errors
- [Architecture Overview](../architecture/overview.md) - System design
- [Architecture: Modules](../architecture/modules.md) - Module architecture
- [Architecture: Events](../architecture/events.md) - Event system
- [Deployment Guide](../guides/deployment.md) - Production setup


<div style='page-break-after: always;'></div>

---



# 19. Architecture Overview

*Source: `backend/docs/architecture/overview.md`*

---

# Architecture Overview

High-level system architecture for Neo Alexandria 2.0.

> **Last Updated**: Phase 14 - Complete Vertical Slice Refactor

## Table of Contents

1. [Modular Architecture Overview](#modular-architecture-overview)
2. [Core Components](#core-components)
3. [Technology Stack](#technology-stack)
4. [Vertical Slice Module Pattern](#vertical-slice-module-pattern)
5. [Complete System Architecture](#complete-system-architecture)
6. [Data Flow](#data-flow)
7. [Design Patterns](#design-patterns)
8. [Key Architectural Principles](#key-architectural-principles)

---

## Modular Architecture Overview

### High-Level Modular Structure (Phase 14 - Complete)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NEO ALEXANDRIA 2.0 - COMPLETE MODULAR ARCHITECTURE                   â”‚
â”‚                              (13 Vertical Slice Modules)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         FastAPI Application (main.py)                            â”‚   â”‚
â”‚  â”‚                    Registers all module routers & event handlers                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                                 â”‚
â”‚                                       â”‚ Module Registration                             â”‚
â”‚                                       â”‚                                                 â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚       â”‚                               â”‚                                   â”‚             â”‚
â”‚       â–¼                               â–¼                                   â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚Resources â”‚  â”‚Collectionsâ”‚ â”‚  Search  â”‚  â”‚Annotationsâ”‚ â”‚ Scholarlyâ”‚  â”‚ Authorityâ”‚     â”‚
â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚
â”‚       â”‚             â”‚             â”‚             â”‚             â”‚             â”‚           â”‚
â”‚       â”‚             â”‚             â”‚             â”‚             â”‚             â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Curation â”‚  â”‚  Quality â”‚  â”‚ Taxonomy â”‚  â”‚  Graph   â”‚  â”‚Recommend-â”‚  â”‚Monitoringâ”‚     â”‚
â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚ ations   â”‚  â”‚  Module  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚
â”‚       â”‚             â”‚             â”‚             â”‚             â”‚             â”‚           â”‚
â”‚       â”‚             â”‚             â”‚             â”‚             â”‚             â”‚           â”‚
â”‚       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚       â”‚    â”‚                                                                            â”‚
â”‚       â”‚    â–¼                                                                            â”‚
â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚       â”‚  â”‚                      Shared Kernel                              â”‚            â”‚
â”‚       â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚            â”‚
â”‚       â””â”€â–ºâ”‚  â”‚ Database â”‚  â”‚  Event Bus   â”‚  â”‚  Base Model  â”‚               â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜|
â”‚          â”‚  â”‚ (Session)â”‚  â”‚  (Pub/Sub)   â”‚  â”‚   (GUID)     â”‚               â”‚            â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚            â”‚
â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚            â”‚
â”‚          â”‚  â”‚  Cross-Cutting Services:                                 â”‚   â”‚            â”‚
â”‚          â”‚  â”‚  â€¢ EmbeddingService (dense & sparse embeddings)          â”‚   â”‚            â”‚
â”‚          â”‚  â”‚  â€¢ AICore (summarization, entity extraction)             â”‚   â”‚            â”‚
â”‚          â”‚  â”‚  â€¢ CacheService (Redis caching with TTL)                 â”‚   â”‚            â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚            â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                                         â”‚
â”‚  Event-Driven Communication (All Modules):                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Resources â”€â”€[resource.created]â”€â”€â–º Scholarly, Quality, Taxonomy, Graph           â”‚   â”‚
â”‚  â”‚  Resources â”€â”€[resource.updated]â”€â”€â–º Collections, Quality, Search                  â”‚   â”‚
â”‚  â”‚  Resources â”€â”€[resource.deleted]â”€â”€â–º Collections, Annotations, Graph               â”‚   â”‚
â”‚  â”‚  Quality â”€â”€â”€â”€[quality.outlier_detected]â”€â”€â–º Curation                              â”‚   â”‚
â”‚  â”‚  Annotations â”€[annotation.created]â”€â”€â–º Recommendations                            â”‚   â”‚
â”‚  â”‚  Collections â”€[collection.resource_added]â”€â”€â–º Recommendations                     â”‚   â”‚
â”‚  â”‚  Taxonomy â”€â”€â”€[resource.classified]â”€â”€â–º Monitoring                                 â”‚   â”‚
â”‚  â”‚  Graph â”€â”€â”€â”€â”€â”€[citation.extracted]â”€â”€â–º Monitoring                                  â”‚   â”‚
â”‚  â”‚  All Modules â”€â”€[*.events]â”€â”€â–º Monitoring (metrics aggregation)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Module Summary (13 Modules)

| Module | Purpose | Key Events Emitted | Key Events Consumed |
|--------|---------|-------------------|---------------------|
| **Resources** | Resource CRUD operations | resource.created, resource.updated, resource.deleted | - |
| **Collections** | Collection management | collection.created, collection.updated, collection.resource_added | resource.created, resource.updated, resource.deleted |
| **Search** | Hybrid search (keyword + semantic + sparse) | search.executed | resource.created, resource.updated |
| **Annotations** | Text highlights and notes | annotation.created, annotation.updated, annotation.deleted | resource.deleted |
| **Scholarly** | Academic metadata extraction | metadata.extracted, equations.parsed, tables.extracted | resource.created |
| **Authority** | Subject authority and classification trees | - | - |
| **Curation** | Content review and batch operations | curation.reviewed, curation.approved, curation.rejected | quality.outlier_detected |
| **Quality** | Multi-dimensional quality assessment | quality.computed, quality.outlier_detected, quality.degradation_detected | resource.created, resource.updated |
| **Taxonomy** | ML classification and taxonomy management | resource.classified, taxonomy.node_created, taxonomy.model_trained | resource.created |
| **Graph** | Knowledge graph, citations, discovery | citation.extracted, graph.updated, hypothesis.discovered | resource.created, resource.deleted |
| **Recommendations** | Hybrid recommendation engine | recommendation.generated, user.profile_updated, interaction.recorded | annotation.created, collection.resource_added |
| **Monitoring** | System health and metrics aggregation | - | All events (for metrics) |

### Phase 14: Complete Vertical Slice Refactor

Phase 14 completes the modular architecture transformation by migrating all remaining domains from the traditional layered structure to self-contained vertical slice modules.

**Migration Summary:**
- **Phase 13.5**: Extracted 3 modules (Resources, Collections, Search) - 20% of codebase
- **Phase 14**: Extracted 10 additional modules - 80% of codebase
- **Result**: 13 total modules with complete event-driven communication

**New Modules Added in Phase 14:**

1. **Annotations Module** - Text highlights and notes with semantic search
   - Migrated from: `routers/annotations.py`, `services/annotation_service.py`
   - Event handlers: Cascade delete on `resource.deleted`
   - Public interface: `AnnotationService`, annotation schemas

2. **Scholarly Module** - Academic metadata extraction (equations, tables, citations)
   - Migrated from: `routers/scholarly.py`, `services/metadata_extractor.py`
   - Event handlers: Extract metadata on `resource.created`
   - Public interface: `MetadataExtractor`, scholarly schemas

3. **Authority Module** - Subject authority and classification trees
   - Migrated from: `routers/authority.py`, `services/authority_service.py`
   - No event handlers (read-only service)
   - Public interface: `AuthorityService`, authority schemas

4. **Curation Module** - Content review and batch operations
   - Migrated from: `routers/curation.py`, `services/curation_service.py`
   - Event handlers: Add to review queue on `quality.outlier_detected`
   - Public interface: `CurationService`, curation schemas

5. **Quality Module** - Multi-dimensional quality assessment
   - Migrated from: `routers/quality.py`, `services/quality_service.py`, `services/summarization_evaluator.py`
   - Event handlers: Compute quality on `resource.created` and `resource.updated`
   - Public interface: `QualityService`, `SummarizationEvaluator`, quality schemas

6. **Taxonomy Module** - ML classification and taxonomy management
   - Migrated from: `routers/taxonomy.py`, `routers/classification.py`, `services/taxonomy_service.py`, `services/ml_classification_service.py`, `services/classification_service.py`
   - Event handlers: Auto-classify on `resource.created`
   - Public interface: `TaxonomyService`, `MLClassificationService`, taxonomy schemas

7. **Graph Module** - Knowledge graph, citations, and discovery
   - Migrated from: `routers/graph.py`, `routers/citations.py`, `routers/discovery.py`, 5 graph services
   - Event handlers: Extract citations on `resource.created`, remove from graph on `resource.deleted`
   - Public interface: `GraphService`, `CitationService`, `LBDService`, graph schemas

8. **Recommendations Module** - Hybrid recommendation engine (collaborative + content-based + graph-based)
   - Migrated from: `routers/recommendation.py`, `routers/recommendations.py`, 6 recommendation services
   - Event handlers: Update user profile on `annotation.created` and `collection.resource_added`
   - Public interface: `RecommendationService`, strategy classes, `UserProfileService`, recommendation schemas

9. **Monitoring Module** - System health and metrics aggregation
   - Migrated from: `routers/monitoring.py`, monitoring services
   - Event handlers: Aggregate metrics from all event types
   - Public interface: `MonitoringService`, monitoring schemas

10. **Shared Kernel Enhancements** - Cross-cutting services moved to shared kernel
    - `EmbeddingService` - Dense and sparse embedding generation
    - `AICore` - Summarization, entity extraction, classification
    - `CacheService` - Redis caching with TTL and pattern-based invalidation

**Architecture Benefits:**

- **High Cohesion**: Related code stays together within each module
- **Low Coupling**: Modules communicate only via events, no direct imports
- **Independent Testing**: Each module can be tested in isolation
- **Clear Boundaries**: Explicit public interfaces via `__init__.py`
- **Event-Driven**: Asynchronous, decoupled communication
- **Scalability**: Modules can be extracted to microservices if needed
- **Maintainability**: Changes to one module don't affect others

**Legacy Cleanup:**

Phase 14 also removed all legacy layered structure directories:
- âŒ Deleted `app/routers/` (all routers moved to modules)
- âŒ Deleted `app/services/` (all services moved to modules or shared kernel)
- âŒ Deleted `app/schemas/` (all schemas moved to modules)
- âœ… Cleaned `app/database/models.py` (only shared models remain: Resource, User, ResourceStatus)

---

## Core Components

1. **API Layer** - FastAPI-based RESTful API with automatic OpenAPI documentation
2. **Module Layer** - Vertical slice modules (Resources, Collections, Search)
3. **Service Layer** - Business logic and processing services
4. **Domain Layer** - Rich domain objects with business rules (Phase 11 DDD)
5. **Data Layer** - SQLAlchemy ORM with database abstraction
6. **Event Layer** - Event-driven communication between modules
7. **Task Layer** - Celery distributed task queue
8. **Cache Layer** - Redis multi-layer caching
9. **AI Processing** - Asynchronous AI-powered content analysis
10. **Search Engine** - Three-way hybrid search with RRF fusion
11. **Knowledge Graph** - Relationship detection and graph-based exploration
12. **Recommendation Engine** - Strategy-based personalized recommendations

---

## Technology Stack

| Layer | Technology |
|-------|------------|
| Web Framework | FastAPI 0.104.1 |
| ORM | SQLAlchemy 2.0.23 |
| Validation | Pydantic 2.5.2 |
| AI/ML | Hugging Face Transformers, PyTorch |
| Embeddings | sentence-transformers |
| Database | SQLite (dev), PostgreSQL (prod) |
| Search | FTS5, Vector Similarity, SPLADE |
| Task Queue | Celery + Redis |
| Caching | Redis |
| Migrations | Alembic 1.13.1 |

---

## Vertical Slice Module Pattern

Each module follows a consistent structure:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VERTICAL SLICE MODULE PATTERN                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Each module (Resources, Collections, Search) follows this structure:   â”‚
â”‚                                                                         â”‚
â”‚  app/modules/{module_name}/                                             â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ __init__.py          # Public interface & exports                  â”‚
â”‚  â”‚   â€¢ router                                                           â”‚
â”‚  â”‚   â€¢ service functions                                                â”‚
â”‚  â”‚   â€¢ schemas                                                          â”‚
â”‚  â”‚   â€¢ models                                                           â”‚
â”‚  â”‚   â€¢ module metadata (__version__, __domain__)                        â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ router.py            # FastAPI endpoints                           â”‚
â”‚  â”‚   â€¢ HTTP request/response handling                                   â”‚
â”‚  â”‚   â€¢ Input validation                                                 â”‚
â”‚  â”‚   â€¢ Calls service layer                                              â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ service.py           # Business logic                              â”‚
â”‚  â”‚   â€¢ Core domain operations                                           â”‚
â”‚  â”‚   â€¢ Orchestration                                                    â”‚
â”‚  â”‚   â€¢ Event emission                                                   â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ schema.py            # Pydantic models                             â”‚
â”‚  â”‚   â€¢ Request/response validation                                      â”‚
â”‚  â”‚   â€¢ Data serialization                                               â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ model.py             # SQLAlchemy models                           â”‚
â”‚  â”‚   â€¢ Database entities                                                â”‚
â”‚  â”‚   â€¢ String-based relationships (avoid circular imports)              â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ handlers.py          # Event handlers                              â”‚
â”‚  â”‚   â€¢ Subscribe to events from other modules                           â”‚
â”‚  â”‚   â€¢ React to system events                                           â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ README.md            # Module documentation                        â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â””â”€â”€ tests/               # Module-specific tests                       â”‚
â”‚      â””â”€â”€ __init__.py                                                    â”‚
â”‚                                                                         â”‚
â”‚  Benefits:                                                              â”‚
â”‚  â€¢ High cohesion - related code stays together                          â”‚
â”‚  â€¢ Low coupling - modules communicate via events                        â”‚
â”‚  â€¢ Independent deployment - modules can be extracted to microservices   â”‚
â”‚  â€¢ Clear boundaries - explicit public interfaces                        â”‚
â”‚  â€¢ Easy testing - isolated module tests                                 â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Complete System Architecture - Layered View

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          LAYER 1: PRESENTATION                              â•‘
â•‘                  (FastAPI Routers)                                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  /api/resources      /api/search         /api/collections                   â•‘
â•‘  /api/taxonomy       /api/annotations    /api/recommendations               â•‘
â•‘  /api/quality        /api/classification /api/monitoring                    â•‘
â•‘  /api/scholarly      /api/graph          /api/citations                     â•‘
â•‘                                                                             â•‘
â•‘  â€¢ Request validation (Pydantic)                                            â•‘
â•‘  â€¢ Authentication & authorization                                           â•‘
â•‘  â€¢ Response serialization                                                   â•‘
â•‘  â€¢ OpenAPI documentation                                                    â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ HTTP Requests
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          LAYER 2: DOMAIN LAYER                              â•‘
â•‘                      (Phase 11: Domain-Driven Design)                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  Rich Domain Objects with Business Logic:                                   â•‘
â•‘                                                                             â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â•‘
â•‘  â”‚ClassificationRe-â”‚  â”‚  SearchQuery    â”‚  â”‚  QualityScore   â”‚              â•‘
â•‘  â”‚sult (ValueObj)  â”‚  â”‚  (ValueObject)  â”‚  â”‚  (ValueObject)  â”‚              â•‘
â•‘  â”‚ â€¢ validate()    â”‚  â”‚  â€¢ execute()    â”‚  â”‚  â€¢ compute()    â”‚              â•‘
â•‘  â”‚ â€¢ to_dict()     â”‚  â”‚  â€¢ to_dict()    â”‚  â”‚  â€¢ to_dict()    â”‚              â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â•‘
â•‘                                                                             â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â•‘
â•‘  â”‚ Recommendation  â”‚  â”‚Classification   â”‚  â”‚  SearchResult   â”‚              â•‘
â•‘  â”‚ (ValueObject)   â”‚  â”‚Prediction       â”‚  â”‚  (ValueObject)  â”‚              â•‘
â•‘  â”‚ â€¢ get_score()   â”‚  â”‚  â€¢ validate()   â”‚  â”‚  â€¢ to_dict()    â”‚              â•‘
â•‘  â”‚ â€¢ to_dict()     â”‚  â”‚  â€¢ to_dict()    â”‚  â”‚                 â”‚              â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â•‘
â•‘                                                                             â•‘
â•‘  â€¢ Encapsulates business rules                                              â•‘
â•‘  â€¢ Independent of persistence                                               â•‘
â•‘  â€¢ Ubiquitous language                                                      â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Business Logic
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          LAYER 3: SERVICE LAYER                             â•‘
â•‘                         (Core Business Services)                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  Core Services:                                                             â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â•‘
â•‘  â”‚ ResourceService  â”‚  â”‚  SearchService   â”‚  â”‚ QualityService   â”‚           â•‘
â•‘  â”‚ â€¢ create()       â”‚  â”‚  â€¢ hybrid()      â”‚  â”‚  â€¢ compute()     â”‚           â•‘
â•‘  â”‚ â€¢ update()       â”‚  â”‚  â€¢ three_way()   â”‚  â”‚  â€¢ dimensions()  â”‚           â•‘
â•‘  â”‚ â€¢ delete()       â”‚  â”‚  â€¢ rerank()      â”‚  â”‚  â€¢ outliers()    â”‚           â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â•‘
â•‘                                                                             â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â•‘
â•‘  â”‚RecommendService  â”‚  â”‚MLClassifyService â”‚  â”‚ EmbeddingService â”‚           â•‘
â•‘  â”‚ â€¢ get_similar()  â”‚  â”‚  â€¢ predict()     â”‚  â”‚  â€¢ generate()    â”‚           â•‘
â•‘  â”‚ â€¢ graph_based()  â”‚  â”‚  â€¢ fine_tune()   â”‚  â”‚  â€¢ batch()       â”‚           â•‘
â•‘  â”‚ â€¢ collaborative()â”‚  â”‚  â€¢ active_learn()â”‚  â”‚  â€¢ similarity()  â”‚           â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â•‘
â•‘                                                                             â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â•‘
â•‘  â”‚ CitationService  â”‚  â”‚ TaxonomyService  â”‚  â”‚AnnotationService â”‚           â•‘
â•‘  â”‚ â€¢ extract()      â”‚  â”‚  â€¢ classify()    â”‚  â”‚  â€¢ create()      â”‚           â•‘
â•‘  â”‚ â€¢ parse()        â”‚  â”‚  â€¢ get_tree()    â”‚  â”‚  â€¢ update()      â”‚           â•‘
â•‘  â”‚ â€¢ graph_update() â”‚  â”‚  â€¢ suggest()     â”‚  â”‚  â€¢ by_resource() â”‚           â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â•‘
â•‘                                                                             â•‘
â•‘  â€¢ Orchestrates business operations                                         â•‘
â•‘  â€¢ Emits domain events                                                      â•‘
â•‘  â€¢ Transaction management                                                   â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Event Emission
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       LAYER 4: EVENT-DRIVEN LAYER                           â•‘
â•‘                      (Phase 12.5: Event System)                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Event System Architecture](event-system.md)                          â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Task Queue
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      LAYER 5: TASK PROCESSING LAYER                         â•‘
â•‘                          (Celery + Redis)                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Event System Architecture](event-system.md)                          â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Cache Access
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         LAYER 6: CACHING LAYER                              â•‘
â•‘                            (Redis Cache)                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Event System Architecture](event-system.md)                          â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Data Access
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       LAYER 7: DATA ACCESS LAYER                            â•‘
â•‘                         (SQLAlchemy ORM)                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Database Architecture](database.md)                                  â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Data Flow

### URL Ingestion Pipeline

```
URL Input â†’ API Validation â†’ Asynchronous Processing Pipeline
    â†“
Content Fetching â†’ Multi-Format Extraction â†’ AI Analysis
    â†“
Vector Embedding â†’ Authority Control â†’ Classification
    â†“
Quality Scoring â†’ Archiving â†’ Database Persistence
    â†“
Search Indexing â†’ Graph Relationship Detection â†’ Recommendation Learning
```

### Resource Update Event Cascade

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RESOURCE UPDATE EVENT CASCADE (Phase 12.5)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. API Request: PUT /resources/{id}                                        â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â–¼                                                                       â”‚
â”‚  2. ResourceService.update(id, data)                                        â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â–º Update database                                                     â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â–º Detect changes: content_changed = True, metadata_changed = False    â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â–º Emit: resource.updated                                              â”‚
â”‚     â”‚   â””â”€â–º Hook: on_resource_updated_sync_search_index                     â”‚
â”‚     â”‚       â””â”€â–º Queue: update_search_index_task (priority=9, countdown=1s)  â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â–º Emit: resource.updated                                              â”‚
â”‚     â”‚   â””â”€â–º Hook: on_resource_updated_invalidate_caches                     â”‚
â”‚     â”‚       â””â”€â–º Queue: invalidate_cache_task (priority=9, countdown=0s)     â”‚
â”‚     â”‚           â””â”€â–º Invalidate: resource:{id}:*, search_query:*             â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â””â”€â–º Emit: resource.content_changed                                      â”‚
â”‚         â””â”€â–º Hook: on_content_changed_regenerate_embedding                   â”‚
â”‚             â””â”€â–º Queue: regenerate_embedding_task (priority=7, countdown=5s) â”‚
â”‚                 â””â”€â–º Generate embedding â†’ Store in cache                     â”‚
â”‚                                                                             â”‚
â”‚  3. Celery Workers Process Tasks (in parallel)                              â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â–º Worker 1: update_search_index_task (1s delay)                       â”‚
â”‚     â”‚   â””â”€â–º Update FTS5 index â†’ Resource searchable                         â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â”œâ”€â–º Worker 2: invalidate_cache_task (immediate)                         â”‚
â”‚     â”‚   â””â”€â–º Delete cache keys â†’ Fresh data on next request                  â”‚
â”‚     â”‚                                                                       â”‚
â”‚     â””â”€â–º Worker 3: regenerate_embedding_task (5s delay)                      â”‚
â”‚         â””â”€â–º Generate embedding â†’ Cache â†’ Enable semantic search             â”‚
â”‚                                                                             â”‚
â”‚  4. All tasks complete within 10 seconds                                    â”‚
â”‚     â””â”€â–º Resource fully updated and consistent across all systems            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Design Patterns Used

### Domain-Driven Design (DDD)
- **Value Objects**: ClassificationPrediction, QualityScore, RecommendationScore, SearchQuery
- **Entities**: Resource, TaxonomyNode, User (via entity_id)
- **Domain Services**: Classification, Quality, Recommendation, Search domains
- **Validation**: Encapsulated in domain objects with validate() methods

### Strategy Pattern
- **Context**: RecommendationService
- **Strategy Interface**: RecommendationStrategy (ABC)
- **Concrete Strategies**: CollaborativeFilteringStrategy, ContentBasedStrategy, GraphBasedStrategy, HybridStrategy
- **Factory**: RecommendationStrategyFactory

### Factory Pattern
- **RecommendationStrategyFactory**: Creates strategy instances based on type
- **SessionLocal**: Creates database session instances

### Repository Pattern
- **Database Models**: Act as repositories for domain entities
- **Service Layer**: Abstracts database operations from business logic

### Dependency Injection
- **FastAPI Dependencies**: get_db() provides database sessions
- **Service Constructors**: Accept db: Session parameter

### Observer Pattern
- **PredictionMonitor**: Observes and logs ML predictions
- **AlertManager**: Observes metrics and triggers alerts
- **Event Bus**: Pub/sub for inter-module communication

### Command Query Separation (CQS)
- **Query Methods**: get_*, compute_*, analyze_* (no side effects)
- **Command Methods**: create_*, update_*, delete_* (modify state)

### Builder Pattern
- **SearchQuery**: Builds complex search queries with optional parameters
- **ClassificationResult**: Builds results with predictions and metadata

---

## Key Architectural Principles

### 1. Separation of Concerns
- **Domain Layer**: Pure business logic, no infrastructure dependencies
- **Service Layer**: Orchestrates domain objects and infrastructure
- **Router Layer**: HTTP concerns only, delegates to services
- **Database Layer**: Data persistence only

### 2. Dependency Inversion
- High-level modules (services) don't depend on low-level modules (database)
- Both depend on abstractions (domain objects, interfaces)
- Database sessions injected via dependency injection

### 3. Single Responsibility
- Each class has one reason to change
- Domain objects: Represent business concepts
- Services: Implement business operations
- Validators: Check specific code quality aspects
- Routers: Handle HTTP requests/responses

### 4. Open/Closed Principle
- Open for extension: New strategies can be added without modifying existing code
- Closed for modification: Core abstractions remain stable
- Example: Adding new RecommendationStrategy doesn't change RecommendationService

### 5. Liskov Substitution
- All RecommendationStrategy implementations are interchangeable
- All ValueObject subclasses can be used polymorphically
- Domain objects can be substituted without breaking contracts

### 6. Interface Segregation
- Small, focused interfaces (RecommendationStrategy has one method)
- Clients depend only on methods they use
- No fat interfaces with unused methods

### 7. Don't Repeat Yourself (DRY)
- Common validation logic in base classes (BaseDomainObject)
- Shared utilities in utility layer
- Reusable validators in refactoring framework

### 8. Composition Over Inheritance
- HybridStrategy composes multiple strategies
- Services compose domain objects
- Minimal inheritance hierarchies

---

## Complete 9-Layer System Architecture

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          LAYER 1: PRESENTATION                              â•‘
â•‘                  (FastAPI Routers)                                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  /api/resources      /api/search         /api/collections                   â•‘
â•‘  /api/taxonomy       /api/annotations    /api/recommendations               â•‘
â•‘  /api/quality        /api/classification /api/monitoring                    â•‘
â•‘  /api/scholarly      /api/graph          /api/citations                     â•‘
â•‘                                                                             â•‘
â•‘  â€¢ Request validation (Pydantic)                                            â•‘
â•‘  â€¢ Authentication & authorization                                           â•‘
â•‘  â€¢ Response serialization                                                   â•‘
â•‘  â€¢ OpenAPI documentation                                                    â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ HTTP Requests
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          LAYER 2: DOMAIN LAYER                              â•‘
â•‘                      (Phase 11: Domain-Driven Design)                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  Rich Domain Objects with Business Logic:                                   â•‘
â•‘                                                                             â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â•‘
â•‘  â”‚ClassificationRe-â”‚  â”‚  SearchQuery    â”‚  â”‚  QualityScore   â”‚              â•‘
â•‘  â”‚sult (ValueObj)  â”‚  â”‚  (ValueObject)  â”‚  â”‚  (ValueObject)  â”‚              â•‘
â•‘  â”‚ â€¢ validate()    â”‚  â”‚  â€¢ execute()    â”‚  â”‚  â€¢ compute()    â”‚              â•‘
â•‘  â”‚ â€¢ to_dict()     â”‚  â”‚  â€¢ to_dict()    â”‚  â”‚  â€¢ to_dict()    â”‚              â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â•‘
â•‘                                                                             â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â•‘
â•‘  â”‚ Recommendation  â”‚  â”‚Classification   â”‚  â”‚  SearchResult   â”‚              â•‘
â•‘  â”‚ (ValueObject)   â”‚  â”‚Prediction       â”‚  â”‚  (ValueObject)  â”‚              â•‘
â•‘  â”‚ â€¢ get_score()   â”‚  â”‚  â€¢ validate()   â”‚  â”‚  â€¢ to_dict()    â”‚              â•‘
â•‘  â”‚ â€¢ to_dict()     â”‚  â”‚  â€¢ to_dict()    â”‚  â”‚                 â”‚              â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â•‘
â•‘                                                                             â•‘
â•‘  â€¢ Encapsulates business rules                                              â•‘
â•‘  â€¢ Independent of persistence                                               â•‘
â•‘  â€¢ Ubiquitous language                                                      â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Business Logic
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          LAYER 3: SERVICE LAYER                             â•‘
â•‘                         (Core Business Services)                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Modules Architecture](modules.md)                                    â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Event Emission
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       LAYER 4: EVENT-DRIVEN LAYER                           â•‘
â•‘                      (Phase 12.5: Event System)                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Event System Architecture](event-system.md)                          â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Task Queue
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      LAYER 5: TASK PROCESSING LAYER                         â•‘
â•‘                          (Celery + Redis)                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Event System Architecture](event-system.md)                          â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Cache Access
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         LAYER 6: CACHING LAYER                              â•‘
â•‘                            (Redis Cache)                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Event System Architecture](event-system.md)                          â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ Data Access
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       LAYER 7: DATA ACCESS LAYER                            â•‘
â•‘                         (SQLAlchemy ORM)                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Database Architecture](database.md)                                  â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ SQL Queries
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         LAYER 8: DATABASE LAYER                             â•‘
â•‘                       (SQLite / PostgreSQL)                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  See: [Database Architecture](database.md)                                  â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                    â”‚
                                    â”‚ ML Processing
                                    â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      LAYER 9: MACHINE LEARNING LAYER                        â•‘
â•‘                    (PyTorch + Transformers)                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  Classification Models (Phase 5-7):                                         â•‘
â•‘  â€¢ DistilBERT / BERT Transformer                                            â•‘
â•‘  â€¢ Multi-label classification                                               â•‘
â•‘  â€¢ Fine-tuned on academic taxonomy                                          â•‘
â•‘  â€¢ Active learning with uncertainty sampling                                â•‘
â•‘                                                                             â•‘
â•‘  Embedding Models (Phase 4, 8):                                             â•‘
â•‘  â€¢ Dense Embeddings (BERT/Sentence-BERT) - 768-dimensional vectors          â•‘
â•‘  â€¢ Sparse Embeddings (SPLADE/TF-IDF) - Term importance weighting            â•‘
â•‘                                                                             â•‘
â•‘  Reranking Models (Phase 8):                                                â•‘
â•‘  â€¢ ColBERT Cross-Encoder                                                    â•‘
â•‘  â€¢ Query-document interaction modeling                                      â•‘
â•‘                                                                             â•‘
â•‘  Quality Assessment Models (Phase 9):                                       â•‘
â•‘  â€¢ Isolation Forest (Outlier Detection)                                     â•‘
â•‘  â€¢ 9-dimensional feature space                                              â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Cross-Cutting Concerns

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         CROSS-CUTTING CONCERNS                              â•‘
â•‘                    (Applied Across All Layers)                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                             â•‘
â•‘  Monitoring & Observability:                                                â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â•‘
â•‘  â”‚ â€¢ PredictionMonitor - ML model performance tracking             â”‚        â•‘
â•‘  â”‚ â€¢ Flower Dashboard - Celery task monitoring                     â”‚        â•‘
â•‘  â”‚ â€¢ Event history logging                                         â”‚        â•‘
â•‘  â”‚ â€¢ Cache statistics tracking                                     â”‚        â•‘
â•‘  â”‚ â€¢ API endpoints: /api/monitoring/health, /metrics, /cache-stats â”‚        â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â•‘
â•‘                                                                             â•‘
â•‘  Error Handling & Resilience:                                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â•‘
â•‘  â”‚ â€¢ Automatic task retries with exponential backoff               â”‚        â•‘
â•‘  â”‚ â€¢ Circuit breakers for external services                        â”‚        â•‘
â•‘  â”‚ â€¢ Graceful degradation (fallback to cached data)                â”‚        â•‘
â•‘  â”‚ â€¢ Dead letter queues for failed tasks                           â”‚        â•‘
â•‘  â”‚ â€¢ Comprehensive error logging                                   â”‚        â•‘
â•‘  â”‚ â€¢ Health checks for all services                                â”‚        â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â•‘
â•‘                                                                             â•‘
â•‘  Security & Authentication:                                                 â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â•‘
â•‘  â”‚ â€¢ API key authentication                                        â”‚        â•‘
â•‘  â”‚ â€¢ Role-based access control (RBAC)                              â”‚        â•‘
â•‘  â”‚ â€¢ Input validation and sanitization                             â”‚        â•‘
â•‘  â”‚ â€¢ SQL injection prevention (ORM)                                â”‚        â•‘
â•‘  â”‚ â€¢ Rate limiting                                                 â”‚        â•‘
â•‘  â”‚ â€¢ CORS configuration                                            â”‚        â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â•‘
â•‘                                                                             â•‘
â•‘  Configuration Management:                                                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â•‘
â•‘  â”‚ â€¢ Environment-based configuration (.env files)                  â”‚        â•‘
â•‘  â”‚ â€¢ Centralized settings (settings.py)                            â”‚        â•‘
â•‘  â”‚ â€¢ Feature flags                                                 â”‚        â•‘
â•‘  â”‚ â€¢ Dynamic configuration updates                                 â”‚        â•‘
â•‘  â”‚ â€¢ Secrets management                                            â”‚        â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â•‘
â•‘                                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Testing Architecture

### Unit Tests
```
test_domain_*.py
â”œâ”€â”€ Test domain object validation
â”œâ”€â”€ Test domain object methods
â”œâ”€â”€ Test value object immutability
â””â”€â”€ No database or external dependencies

test_*_service.py
â”œâ”€â”€ Test service methods with mocked database
â”œâ”€â”€ Test business logic
â”œâ”€â”€ Test error handling
â””â”€â”€ Use pytest fixtures for setup

test_refactoring_*.py
â”œâ”€â”€ Test code smell detection
â”œâ”€â”€ Test validators
â”œâ”€â”€ Test AST parsing
â””â”€â”€ Use sample code files
```

### Integration Tests
```
test_*_integration.py
â”œâ”€â”€ Test service + database interactions
â”œâ”€â”€ Test API endpoints
â”œâ”€â”€ Use test database
â””â”€â”€ Test complete workflows
```

### Test Fixtures
```
conftest.py
â”œâ”€â”€ @pytest.fixture: db_session
â”œâ”€â”€ @pytest.fixture: test_client
â”œâ”€â”€ @pytest.fixture: sample_resources
â””â”€â”€ @pytest.fixture: mock_ml_model
```

---

## Performance Considerations

### Lazy Loading
- ML models loaded on first use (MLClassificationService._load_model)
- Reduces startup time and memory usage

### Caching
- Model checkpoints cached on disk
- Embeddings cached in database and Redis
- Query results cached with TTL

### Batch Processing
- predict_batch() for multiple classifications
- Batch quality outlier detection
- Vectorized operations in numpy

### Database Optimization
- Indexes on frequently queried fields (id, resource_id, user_id)
- JSON fields for flexible metadata
- Pagination for large result sets
- Connection pooling (20 base + 40 overflow)

### Async Operations
- FastAPI async endpoints
- Background tasks for long-running operations
- Celery for distributed task processing

---

## Security Considerations

### Input Validation
- Pydantic schemas validate all API inputs
- Domain objects validate business rules
- SQL injection prevented by SQLAlchemy ORM

### Authentication & Authorization
- JWT tokens for API authentication (planned)
- Role-based access control (planned)
- Resource ownership validation

### Data Privacy
- User data anonymization options
- GDPR compliance considerations
- Audit logging for sensitive operations

---

## Deployment Architecture

```
Production Environment
â”œâ”€â”€ Load Balancer
â”‚   â””â”€â”€ Distributes traffic across instances
â”œâ”€â”€ Application Servers (multiple instances)
â”‚   â”œâ”€â”€ FastAPI application
â”‚   â”œâ”€â”€ Gunicorn workers
â”‚   â””â”€â”€ ML models loaded in memory
â”œâ”€â”€ Database Server
â”‚   â”œâ”€â”€ PostgreSQL (production)
â”‚   â””â”€â”€ SQLite (development)
â”œâ”€â”€ Cache Layer
â”‚   â””â”€â”€ Redis
â”œâ”€â”€ Task Queue
â”‚   â”œâ”€â”€ Celery Workers (4 replicas)
â”‚   â”œâ”€â”€ Celery Beat (scheduler)
â”‚   â””â”€â”€ Flower (monitoring)
â””â”€â”€ Monitoring
    â”œâ”€â”€ Prometheus metrics
    â”œâ”€â”€ Grafana dashboards
    â””â”€â”€ Alert notifications
```

---

## Future Enhancements

### Planned Features
1. **Async Operations**: Convert services to async for better concurrency
2. **GraphQL API**: Alternative to REST for flexible queries
3. **Real-time Updates**: WebSocket support for live notifications
4. **Advanced ML**: Add more sophisticated models (BERT, GPT)
5. **Distributed Training**: Multi-GPU and distributed model training
6. **A/B Testing**: Framework for testing recommendation strategies
7. **Explainability**: Add SHAP/LIME for model interpretability

### Technical Debt
1. Complete async conversion of database operations
2. Add comprehensive API documentation (OpenAPI/Swagger)
3. Implement rate limiting and throttling
4. Add request/response compression
5. Implement circuit breakers for external services
6. Add distributed tracing (OpenTelemetry)

---

## Related Documentation

- [Database Architecture](database.md) - Schema, models, migrations
- [Event System](event-system.md) - Event-driven communication, Celery, Redis
- [Modules](modules.md) - Vertical slice details, service architecture
- [Design Decisions](decisions.md) - ADRs


<div style='page-break-after: always;'></div>

---



# 20. Database Architecture

*Source: `backend/docs/architecture/database.md`*

---

# Database Architecture

Database schema, models, and migration strategies for Neo Alexandria 2.0.

## Database Support

Neo Alexandria supports both SQLite and PostgreSQL with automatic detection.

### SQLite (Development)

```bash
DATABASE_URL=sqlite:///./backend.db
```

**Use Cases:**
- Local development and prototyping
- Single-user deployments
- Testing and CI/CD pipelines
- Small datasets (<10,000 resources)

**Advantages:**
- Zero configuration
- File-based (portable)
- No separate server needed

**Limitations:**
- Single writer (limited concurrency)
- No advanced indexing (GIN, JSONB)

### PostgreSQL (Production)

```bash
DATABASE_URL=postgresql://user:password@host:5432/database
```

**Use Cases:**
- Production deployments
- Multi-user environments
- High concurrency (100+ users)
- Large datasets (>10,000 resources)

**Advantages:**
- Excellent concurrent write performance
- Advanced indexing (GIN for JSONB)
- Native JSONB support
- Connection pooling

---

## Database Model Hierarchy

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   SQLAlchemy Base   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                â”‚                â”‚                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Resource      â”‚  â”‚ TaxonomyNode â”‚  â”‚ Collection â”‚  â”‚ Annotation â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ id: UUID       â”‚  â”‚ â€¢ id: UUID   â”‚  â”‚ â€¢ id: UUID â”‚  â”‚ â€¢ id: UUID â”‚
    â”‚ â€¢ title: str     â”‚  â”‚ â€¢ code: str  â”‚  â”‚ â€¢ name     â”‚  â”‚ â€¢ content  â”‚
    â”‚ â€¢ description    â”‚  â”‚ â€¢ name: str  â”‚  â”‚ â€¢ owner_id â”‚  â”‚ â€¢ user_id  â”‚
    â”‚ â€¢ creator        â”‚  â”‚ â€¢ parent_id  â”‚  â”‚ â€¢ public   â”‚  â”‚ â€¢ type     â”‚
    â”‚ â€¢ subject: JSON  â”‚  â”‚ â€¢ level: int â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ â€¢ type           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ â€¢ language       â”‚         â”‚
    â”‚ â€¢ identifier     â”‚         â”‚ self-referential
    â”‚ â€¢ doi            â”‚         â–¼
    â”‚ â€¢ embedding      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â€¢ created_at     â”‚  â”‚   children   â”‚
    â”‚ â€¢ updated_at     â”‚  â”‚  (List[Node])â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ one-to-many
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ResourceTaxonomy â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ resource_id    â”‚
    â”‚ â€¢ taxonomy_id    â”‚
    â”‚ â€¢ confidence     â”‚
    â”‚ â€¢ method         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Core Schema

### Resource Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Resource                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)                                                    â”‚
â”‚ title: String (required)                                         â”‚
â”‚ description: Text                                                â”‚
â”‚ creator: String                                                  â”‚
â”‚ publisher: String                                                â”‚
â”‚ source: String (URL)                                             â”‚
â”‚ language: String                                                 â”‚
â”‚ type: String                                                     â”‚
â”‚ subject: JSON (array of strings)                                 â”‚
â”‚ classification_code: String                                      â”‚
â”‚ quality_score: Float (0.0-1.0)                                   â”‚
â”‚ read_status: Enum (unread, in_progress, completed, archived)     â”‚
â”‚ embedding: JSON (vector array)                                   â”‚
â”‚ created_at: DateTime                                             â”‚
â”‚ updated_at: DateTime                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Collection Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Collection                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)                                                    â”‚
â”‚ name: String (1-255 chars)                                       â”‚
â”‚ description: Text (max 2000 chars)                               â”‚
â”‚ owner_id: String (indexed)                                       â”‚
â”‚ visibility: Enum (private, shared, public)                       â”‚
â”‚ parent_id: UUID (FK â†’ Collection, nullable)                      â”‚
â”‚ embedding: JSON (aggregate vector)                               â”‚
â”‚ created_at: DateTime                                             â”‚
â”‚ updated_at: DateTime                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Annotation Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Annotation                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)                                                    â”‚
â”‚ resource_id: UUID (FK â†’ Resource)                                â”‚
â”‚ user_id: String                                                  â”‚
â”‚ start_offset: Integer                                            â”‚
â”‚ end_offset: Integer                                              â”‚
â”‚ highlighted_text: Text                                           â”‚
â”‚ note: Text (max 10,000 chars)                                    â”‚
â”‚ tags: JSON (array, max 20)                                       â”‚
â”‚ color: String (hex)                                              â”‚
â”‚ embedding: JSON (384-dim vector)                                 â”‚
â”‚ is_shared: Boolean                                               â”‚
â”‚ created_at: DateTime                                             â”‚
â”‚ updated_at: DateTime                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Taxonomy Node Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       TaxonomyNode                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)                                                    â”‚
â”‚ name: String                                                     â”‚
â”‚ slug: String (unique)                                            â”‚
â”‚ parent_id: UUID (FK â†’ TaxonomyNode, nullable)                    â”‚
â”‚ level: Integer                                                   â”‚
â”‚ path: String (materialized path)                                 â”‚
â”‚ description: Text                                                â”‚
â”‚ keywords: JSON (array)                                           â”‚
â”‚ resource_count: Integer                                          â”‚
â”‚ descendant_resource_count: Integer                               â”‚
â”‚ is_leaf: Boolean                                                 â”‚
â”‚ allow_resources: Boolean                                         â”‚
â”‚ created_at: DateTime                                             â”‚
â”‚ updated_at: DateTime                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Citation Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Citation                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)                                                    â”‚
â”‚ source_resource_id: UUID (FK â†’ Resource)                         â”‚
â”‚ target_resource_id: UUID (FK â†’ Resource)                         â”‚
â”‚ citation_type: String (cites, cited_by, related)                 â”‚
â”‚ context: Text (surrounding text)                                 â”‚
â”‚ confidence: Float (0.0-1.0)                                      â”‚
â”‚ created_at: DateTime                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### User Interaction Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      UserInteraction                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)                                                    â”‚
â”‚ user_id: String (indexed)                                        â”‚
â”‚ resource_id: UUID (FK â†’ Resource)                                â”‚
â”‚ interaction_type: String (view, bookmark, rate, download)        â”‚
â”‚ rating: Integer (1-5, nullable)                                  â”‚
â”‚ duration_seconds: Integer (nullable)                             â”‚
â”‚ metadata: JSON                                                   â”‚
â”‚ created_at: DateTime                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Association Tables

### Collection-Resource Association

```sql
CREATE TABLE collection_resources (
    collection_id UUID REFERENCES collections(id) ON DELETE CASCADE,
    resource_id UUID REFERENCES resources(id) ON DELETE CASCADE,
    added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (collection_id, resource_id)
);

CREATE INDEX idx_collection_resources_collection ON collection_resources(collection_id);
CREATE INDEX idx_collection_resources_resource ON collection_resources(resource_id);
```

### Resource-Taxonomy Association

```sql
CREATE TABLE resource_taxonomy (
    resource_id UUID REFERENCES resources(id) ON DELETE CASCADE,
    taxonomy_id UUID REFERENCES taxonomy_nodes(id) ON DELETE CASCADE,
    confidence FLOAT,
    is_predicted BOOLEAN DEFAULT TRUE,
    PRIMARY KEY (resource_id, taxonomy_id)
);
```

---

## Connection Pool Configuration

### PostgreSQL

```python
postgresql_params = {
    'pool_size': 20,              # Base connections
    'max_overflow': 40,           # Burst connections
    'pool_recycle': 3600,         # Recycle after 1 hour
    'pool_pre_ping': True,        # Validate before use
}
```

### SQLite

```python
sqlite_params = {
    'pool_size': 5,
    'max_overflow': 10,
    'connect_args': {
        'check_same_thread': False,
        'timeout': 30
    }
}
```

---

## Database Layer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DATABASE LAYER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Shared Kernel (app/shared/)                   â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚   database.py   â”‚  â”‚  base_model.py  â”‚  â”‚   event_bus.py  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ get_db()      â”‚  â”‚ â€¢ BaseModel     â”‚  â”‚ â€¢ publish()     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ SessionLocal  â”‚  â”‚   - id (GUID)   â”‚  â”‚ â€¢ subscribe()   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ engine        â”‚  â”‚   - created_at  â”‚  â”‚ â€¢ Event class   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Base          â”‚  â”‚   - updated_at  â”‚  â”‚                 â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                    â”‚
â”‚                                    â”‚ used by                            â”‚
â”‚                                    â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Module Models                                 â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ resources/      â”‚  â”‚ collections/    â”‚  â”‚ search/         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚   model.py      â”‚  â”‚   model.py      â”‚  â”‚   (uses shared) â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Resource      â”‚  â”‚ â€¢ Collection    â”‚  â”‚ â€¢ FTS5 tables   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Annotation    â”‚  â”‚ â€¢ CollectionRes â”‚  â”‚ â€¢ Vector index  â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Migration Commands

```bash
# Create new migration
alembic revision --autogenerate -m "Description"

# Apply migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# Check current version
alembic current
```

## Database Migration (SQLite â†” PostgreSQL)

### SQLite â†’ PostgreSQL

```bash
python backend/scripts/migrate_sqlite_to_postgresql.py \
  --source sqlite:///./backend.db \
  --target postgresql://user:pass@host:5432/db \
  --validate
```

### PostgreSQL â†’ SQLite

```bash
python backend/scripts/migrate_postgresql_to_sqlite.py \
  --source postgresql://user:pass@host:5432/db \
  --target sqlite:///./backend.db \
  --validate
```

---

## Backup Strategies

### PostgreSQL

```bash
# Full backup
pg_dump -h localhost -U postgres -d neo_alexandria > backup.sql

# Compressed backup
pg_dump -h localhost -U postgres -d neo_alexandria | gzip > backup.sql.gz
```

### SQLite

```bash
# Simple copy
cp backend.db backend.db.backup

# SQLite backup command
sqlite3 backend.db ".backup 'backup.db'"
```

---

## Related Documentation

- [Architecture Overview](overview.md) - System design
- [PostgreSQL Migration Guide](../POSTGRESQL_MIGRATION_GUIDE.md) - Detailed migration
- [PostgreSQL Backup Guide](../POSTGRESQL_BACKUP_GUIDE.md) - Backup procedures


<div style='page-break-after: always;'></div>

---



# 21. Event System

*Source: `backend/docs/architecture/event-system.md`*

---

# Event System Architecture

Event-driven communication, Celery task queue, and Redis caching for Neo Alexandria 2.0.

> **Last Updated**: Phase 14 - Complete Vertical Slice Refactor

## Table of Contents

1. [Overview](#overview)
2. [Event System Core](#event-system-core)
3. [Celery Distributed Task Queue](#celery-distributed-task-queue)
4. [Redis Caching Architecture](#redis-caching-architecture)
5. [Event Hooks](#event-hooks)
6. [Service Integration](#service-integration)
7. [Docker Compose Orchestration](#docker-compose-orchestration)
8. [Performance Characteristics](#performance-characteristics)

---

## Overview

The event system enables loose coupling between modules through publish-subscribe messaging. Modules emit events when significant actions occur, and other modules can subscribe to react to these events.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EVENT-DRIVEN ARCHITECTURE (Phase 12.5)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         Event System Core                           â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚                     EventEmitter (Singleton)                 â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ on(event_type, handler) - Register listener               â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ off(event_type, handler) - Unregister listener            â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ emit(event_type, data, priority) - Dispatch event         â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ get_event_history(limit) - Retrieve event log             â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚                    SystemEvent Enum                          â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  Resource: created, updated, deleted, content_changed        â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  Processing: ingestion, embedding, quality, classification   â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  User: interaction_tracked, profile_updated                  â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  System: cache_invalidated, search_index_updated             â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Event System Core

### Event Bus Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         EVENT BUS (Pub/Sub)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Publishers                    Event Bus                  Subscribers   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚Resources â”‚â”€â”€publishâ”€â”€â”€â”€â”€â”€â–ºâ”‚           â”‚â”€â”€notifyâ”€â”€â”€â”€â”€â–ºâ”‚Collectionsâ”‚   â”‚
â”‚  â”‚ Module   â”‚                â”‚           â”‚              â”‚  Module   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚           â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚  Event    â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   Bus     â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚Collectionsâ”‚â”€â”€publishâ”€â”€â”€â”€â”€â–ºâ”‚           â”‚â”€â”€notifyâ”€â”€â”€â”€â”€â–ºâ”‚ Search   â”‚    â”‚
â”‚  â”‚  Module  â”‚                â”‚           â”‚              â”‚  Module  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚           â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚           â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚           â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Search   â”‚â”€â”€publishâ”€â”€â”€â”€â”€â”€â–ºâ”‚           â”‚â”€â”€notifyâ”€â”€â”€â”€â”€â–ºâ”‚Analytics â”‚    â”‚
â”‚  â”‚  Module  â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ (future) â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Event Types

#### Resource Events

| Event | Payload | Triggered When |
|-------|---------|----------------|
| `resource.created` | `{resource_id, title, ...}` | New resource ingested |
| `resource.updated` | `{resource_id, changes}` | Resource metadata updated |
| `resource.deleted` | `{resource_id}` | Resource deleted |
| `resource.content_changed` | `{resource_id}` | Content modified |
| `resource.metadata_changed` | `{resource_id}` | Metadata modified |
| `resource.classified` | `{resource_id, taxonomy_ids}` | Classification assigned |
| `resource.quality_computed` | `{resource_id, score}` | Quality score calculated |

#### Collection Events

| Event | Payload | Triggered When |
|-------|---------|----------------|
| `collection.created` | `{collection_id, name}` | New collection created |
| `collection.updated` | `{collection_id, changes}` | Collection metadata updated |
| `collection.deleted` | `{collection_id}` | Collection deleted |
| `collection.resource_added` | `{collection_id, resource_ids}` | Resources added |
| `collection.resource_removed` | `{collection_id, resource_ids}` | Resources removed |

#### Search Events

| Event | Payload | Triggered When |
|-------|---------|----------------|
| `search.executed` | `{query, results_count, latency}` | Search performed |
| `search.facets_computed` | `{query, facets}` | Facets calculated |

#### Processing Events

| Event | Payload | Triggered When |
|-------|---------|----------------|
| `ingestion.started` | `{url, resource_id}` | Ingestion begins |
| `ingestion.completed` | `{resource_id, status}` | Ingestion finishes |
| `citations.extracted` | `{resource_id, citation_ids}` | Citations parsed |
| `authors.extracted` | `{resource_id, author_names}` | Authors identified |

### Event Bus Implementation

```python
# app/shared/event_bus.py
from typing import Callable, Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class Event:
    type: str
    payload: Dict[str, Any]
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.utcnow()

class EventBus:
    def __init__(self):
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable) -> None:
        """Subscribe a handler to an event type."""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    def publish(self, event: Event) -> None:
        """Publish an event to all subscribers."""
        handlers = self._subscribers.get(event.type, [])
        for handler in handlers:
            try:
                handler(event)
            except Exception as e:
                logger.error(f"Event handler error: {e}")
    
    def unsubscribe(self, event_type: str, handler: Callable) -> None:
        """Remove a handler from an event type."""
        if event_type in self._subscribers:
            self._subscribers[event_type].remove(handler)

# Global event bus instance
event_bus = EventBus()
```

---

## Celery Distributed Task Queue

### Task Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CELERY TASK HIERARCHY                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚                        â”‚  DatabaseTask    â”‚                                 â”‚
â”‚                        â”‚  (Base Class)    â”‚                                 â”‚
â”‚                        â”‚  â€¢ __call__()    â”‚                                 â”‚
â”‚                        â”‚  â€¢ Session mgmt  â”‚                                 â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                                 â”‚                                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚         â”‚                       â”‚                       â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ regenerate_     â”‚   â”‚ recompute_       â”‚   â”‚ update_search_   â”‚          â”‚
â”‚  â”‚ embedding_task  â”‚   â”‚ quality_task     â”‚   â”‚ index_task       â”‚          â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”‚
â”‚  â”‚ â€¢ max_retries=3 â”‚   â”‚ â€¢ max_retries=2  â”‚   â”‚ â€¢ priority=9     â”‚          â”‚
â”‚  â”‚ â€¢ retry_delay=60â”‚   â”‚ â€¢ priority=5     â”‚   â”‚ â€¢ max_retries=3  â”‚          â”‚
â”‚  â”‚ â€¢ priority=7    â”‚   â”‚ â€¢ countdown=10   â”‚   â”‚ â€¢ countdown=1    â”‚          â”‚
â”‚  â”‚ â€¢ countdown=5   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ update_graph_    â”‚   â”‚ classify_        â”‚   â”‚ invalidate_      â”‚         â”‚
â”‚  â”‚ edges_task       â”‚   â”‚ resource_task    â”‚   â”‚ cache_task       â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ â€¢ priority=5     â”‚   â”‚ â€¢ max_retries=2  â”‚   â”‚ â€¢ priority=9     â”‚         â”‚
â”‚  â”‚ â€¢ countdown=30   â”‚   â”‚ â€¢ priority=5     â”‚   â”‚ â€¢ countdown=0    â”‚         â”‚
â”‚  â”‚ â€¢ batch_delay    â”‚   â”‚ â€¢ countdown=20   â”‚   â”‚ â€¢ pattern supportâ”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ refresh_         â”‚   â”‚ batch_process_resources_task             â”‚        â”‚
â”‚  â”‚ recommendation_  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚  â”‚ profile_task     â”‚   â”‚ â€¢ Progress tracking with update_state()  â”‚        â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚ â€¢ Operations: regenerate_embeddings,     â”‚        â”‚
â”‚  â”‚ â€¢ priority=3     â”‚   â”‚   recompute_quality                      â”‚        â”‚
â”‚  â”‚ â€¢ countdown=300  â”‚   â”‚ â€¢ Returns: processed_count, status       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Task Routing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Task Routing                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ urgent queue (priority 9) - Search index, cache invalidation         â”‚
â”‚  â€¢ high_priority queue (priority 7) - Embeddings                        â”‚
â”‚  â€¢ ml_tasks queue (priority 5) - Classification, quality                â”‚
â”‚  â€¢ batch queue (priority 3) - Batch processing                          â”‚
â”‚  â€¢ default queue (priority 5) - General tasks                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Redis Caching Architecture

### Multi-Layer Caching

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MULTI-LAYER REDIS CACHING                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         RedisCache Class                            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚  Methods:                                                    â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ get(key) â†’ value | None                                   â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ set(key, value, ttl) â†’ None                               â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ delete(key) â†’ None                                        â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ delete_pattern(pattern) â†’ int (count)                     â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ get_default_ttl(key) â†’ int (seconds)                      â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚                    CacheStats Tracking                       â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ hits: int                                                 â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ misses: int                                               â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ invalidations: int                                        â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ hit_rate() â†’ float (0.0-1.0)                              â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                        Cache Key Strategy                           â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  embedding:{resource_id}           TTL: 3600s (1 hour)              â”‚    â”‚
â”‚  â”‚  quality:{resource_id}             TTL: 1800s (30 minutes)          â”‚    â”‚
â”‚  â”‚  search_query:{hash}               TTL: 300s (5 minutes)            â”‚    â”‚
â”‚  â”‚  resource:{resource_id}            TTL: 600s (10 minutes)           â”‚    â”‚
â”‚  â”‚  graph:{resource_id}:neighbors     TTL: 1800s (30 minutes)          â”‚    â”‚
â”‚  â”‚  user:{user_id}:profile            TTL: 600s (10 minutes)           â”‚    â”‚
â”‚  â”‚  classification:{resource_id}      TTL: 3600s (1 hour)              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    Cache Invalidation Patterns                      â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  resource:{resource_id}:*          â†’ All resource-related caches    â”‚    â”‚
â”‚  â”‚  search_query:*                    â†’ All search result caches       â”‚    â”‚
â”‚  â”‚  graph:*                           â†’ All graph caches               â”‚    â”‚
â”‚  â”‚  user:{user_id}:*                  â†’ All user-related caches        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Event Hooks

### Auto-Consistency Hooks

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Event Hooks (Auto-Consistency)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  resource.content_changed â”€â”€â–º regenerate_embedding_task (5s delay)      â”‚
â”‚  resource.metadata_changed â”€â–º recompute_quality_task (10s delay)        â”‚
â”‚  resource.updated â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º update_search_index_task (1s delay)       â”‚
â”‚  citations.extracted â”€â”€â”€â”€â”€â”€â”€â”€â–º update_graph_edges_task (30s delay)      â”‚
â”‚  resource.updated â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º invalidate_cache_task (immediate)         â”‚
â”‚  user.interaction_tracked â”€â”€â”€â–º refresh_profile_task (every 10)          â”‚
â”‚  resource.created â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º classify_resource_task (20s delay)       â”‚
â”‚  authors.extracted â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º normalize_names_task (60s delay)         â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Service Integration

### ResourceService Event Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ResourceService                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  create(data) â†’ Resource                                                â”‚
â”‚    1. Create resource in database                                       â”‚
â”‚    2. Emit: resource.created                                            â”‚
â”‚    3. Hooks trigger: classify_resource_task                             â”‚
â”‚                                                                         â”‚
â”‚  update(id, data) â†’ Resource                                            â”‚
â”‚    1. Update resource in database                                       â”‚
â”‚    2. Detect changes (content vs metadata)                              â”‚
â”‚    3. Emit: resource.updated                                            â”‚
â”‚    4. Emit: resource.content_changed (if content changed)               â”‚
â”‚    5. Emit: resource.metadata_changed (if metadata changed)             â”‚
â”‚    6. Hooks trigger:                                                    â”‚
â”‚       - regenerate_embedding_task (if content)                          â”‚
â”‚       - recompute_quality_task (if metadata)                            â”‚
â”‚       - update_search_index_task (always)                               â”‚
â”‚       - invalidate_cache_task (always)                                  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### IngestionService Event Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      IngestionService                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  process(url) â†’ Resource                                                â”‚
â”‚    1. Emit: ingestion.started                                           â”‚
â”‚    2. Fetch and extract content                                         â”‚
â”‚    3. Generate embeddings                                               â”‚
â”‚    4. Extract citations â†’ Emit: citations.extracted                     â”‚
â”‚    5. Extract authors â†’ Emit: authors.extracted                         â”‚
â”‚    6. Compute quality                                                   â”‚
â”‚    7. Create resource â†’ Emit: resource.created                          â”‚
â”‚    8. Emit: ingestion.completed                                         â”‚
â”‚    9. Hooks trigger all downstream tasks                                â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### UserInteractionTracking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   UserInteractionTracking                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  track_interaction(user_id, resource_id, type) â†’ None                   â”‚
â”‚    1. Record interaction in database                                    â”‚
â”‚    2. Get total interaction count for user                              â”‚
â”‚    3. Emit: user.interaction_tracked                                    â”‚
â”‚    4. Hook checks: if count % 10 == 0                                   â”‚
â”‚       â†’ refresh_recommendation_profile_task                             â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Docker Compose Orchestration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DOCKER COMPOSE ORCHESTRATION                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                            Redis                                    â”‚    â”‚
â”‚  â”‚  â€¢ Image: redis:7-alpine                                            â”‚    â”‚
â”‚  â”‚  â€¢ Memory: 2GB with allkeys-lru eviction                            â”‚    â”‚
â”‚  â”‚  â€¢ Persistence: appendonly yes                                      â”‚    â”‚
â”‚  â”‚  â€¢ Port: 6379                                                       â”‚    â”‚
â”‚  â”‚  â€¢ Health check: redis-cli ping                                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                   â”‚                                         â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚              â”‚              â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Celery Workers    â”‚  â”‚  Celery Beat    â”‚  â”‚     Flower          â”‚       â”‚
â”‚  â”‚  (4 replicas)      â”‚  â”‚  (Scheduler)    â”‚  â”‚   (Monitoring)      â”‚       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚
â”‚  â”‚ â€¢ Concurrency: 4   â”‚  â”‚ â€¢ Schedules:    â”‚  â”‚ â€¢ Port: 5555        â”‚       â”‚
â”‚  â”‚ â€¢ CPU: 2 cores     â”‚  â”‚   - Daily 2 AM  â”‚  â”‚ â€¢ Web dashboard     â”‚       â”‚
â”‚  â”‚ â€¢ Memory: 2GB      â”‚  â”‚   - Weekly Sun  â”‚  â”‚ â€¢ Task monitoring   â”‚       â”‚
â”‚  â”‚ â€¢ Queues: all      â”‚  â”‚   - Monthly 1st â”‚  â”‚ â€¢ Worker stats      â”‚       â”‚
â”‚  â”‚ â€¢ Auto-restart     â”‚  â”‚   - Daily 4 AM  â”‚  â”‚ â€¢ Real-time graphs  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         FastAPI Application                         â”‚    â”‚
â”‚  â”‚  â€¢ Depends on: Redis                                                â”‚    â”‚
â”‚  â”‚  â€¢ Environment: CELERY_BROKER_URL, CELERY_RESULT_BACKEND            â”‚    â”‚
â”‚  â”‚  â€¢ Startup: register_all_hooks(), initialize Redis cache            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Performance Characteristics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 12.5 PERFORMANCE METRICS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Scalability:                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  â€¢ 100+ concurrent ingestions without degradation                   â”‚    â”‚
â”‚  â”‚  â€¢ Linear throughput scaling with worker count                      â”‚    â”‚
â”‚  â”‚  â€¢ Horizontal scaling across multiple machines                      â”‚    â”‚
â”‚  â”‚  â€¢ 4 workers â†’ 400 tasks/minute                                     â”‚    â”‚
â”‚  â”‚  â€¢ 8 workers â†’ 800 tasks/minute (linear)                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  Cache Performance:                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  â€¢ 60-70% cache hit rate for repeated operations                    â”‚    â”‚
â”‚  â”‚  â€¢ 50-70% computation reduction through caching                     â”‚    â”‚
â”‚  â”‚  â€¢ Sub-millisecond cache lookups                                    â”‚    â”‚
â”‚  â”‚  â€¢ Pattern-based invalidation in <10ms                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  Task Reliability:                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  â€¢ <1% task failure rate with automatic retries                     â”‚    â”‚
â”‚  â”‚  â€¢ Exponential backoff for transient errors                         â”‚    â”‚
â”‚  â”‚  â€¢ Dead letter queue for permanent failures                         â”‚    â”‚
â”‚  â”‚  â€¢ Task acknowledgment after completion                             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  Search Index Updates:                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  â€¢ Complete within 5 seconds of resource updates                    â”‚    â”‚
â”‚  â”‚  â€¢ URGENT priority ensures immediate searchability                  â”‚    â”‚
â”‚  â”‚  â€¢ Automatic retry on failure                                       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  Database Connection Pooling:                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  â€¢ 20 base connections + 40 overflow = 60 total                     â”‚    â”‚
â”‚  â”‚  â€¢ Connection recycling after 1 hour                                â”‚    â”‚
â”‚  â”‚  â€¢ Pre-ping health checks                                           â”‚    â”‚
â”‚  â”‚  â€¢ Handles 100+ concurrent requests                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Best Practices

### Event Design

- Keep payloads minimal (IDs, not full objects)
- Include timestamp for ordering
- Use past tense for event names (`created`, not `create`)
- Make events idempotent when possible

### Handler Design

- Handlers should be fast (<100ms)
- Use background tasks for slow operations
- Handle errors gracefully (don't crash on failure)
- Log all event processing

### Testing Events

```python
def test_resource_deletion_updates_collections(db, event_bus):
    # Create resource and collection
    resource = create_resource(db, {...})
    collection = create_collection(db, {...})
    add_resource_to_collection(db, collection.id, resource.id)
    
    # Delete resource (triggers event)
    delete_resource(db, resource.id)
    
    # Verify collection updated
    updated = get_collection(db, collection.id)
    assert resource.id not in [r.id for r in updated.resources]
```

---

## Related Documentation

- [Architecture Overview](overview.md) - System design
- [Modules](modules.md) - Vertical slice architecture
- [Database](database.md) - Schema and models
- [Event-Driven Refactoring](../EVENT_DRIVEN_REFACTORING.md) - Migration details


<div style='page-break-after: always;'></div>

---



# 22. Event Catalog

*Source: `backend/docs/architecture/events.md`*

---

# Event Catalog

Complete reference for all events in Neo Alexandria 2.0's event-driven architecture.

> **Phase 14 Complete**: This catalog documents all 25+ events used for inter-module communication in the fully modular vertical slice architecture.

---

## Table of Contents

1. [Overview](#overview)
2. [Event Naming Conventions](#event-naming-conventions)
3. [Event Categories](#event-categories)
4. [Complete Event Reference](#complete-event-reference)
5. [Event Flow Diagrams](#event-flow-diagrams)
6. [Best Practices](#best-practices)
7. [Monitoring Events](#monitoring-events)

---

## Overview

### What Are Events?

Events are the primary mechanism for communication between modules in Neo Alexandria 2.0. Instead of modules directly calling each other (which creates tight coupling), modules emit events when something significant happens, and other modules subscribe to events they care about.

### Benefits of Event-Driven Architecture

1. **Loose Coupling**: Modules don't need to know about each other
2. **Scalability**: Easy to add new subscribers without modifying emitters
3. **Testability**: Modules can be tested in isolation
4. **Flexibility**: Event handlers can be added/removed dynamically
5. **Auditability**: All inter-module communication is logged

### Event Bus

The event bus is implemented in `app/shared/event_bus.py` and provides:
- **Synchronous delivery**: Events are delivered immediately in the same process
- **Error isolation**: Handler failures don't affect other handlers
- **Metrics tracking**: Events emitted, delivered, and errors are tracked
- **Type safety**: Events have defined types and payloads

---

## Event Naming Conventions

### Pattern

All events follow the pattern: `{domain}.{action}`

- **domain**: The module or entity that owns the event (lowercase, singular)
- **action**: The action that occurred (past tense, snake_case)

### Examples

```
resource.created          # Resource module created a resource
resource.updated          # Resource module updated a resource
resource.deleted          # Resource module deleted a resource
collection.updated        # Collection module updated a collection
quality.computed          # Quality module computed quality scores
quality.outlier_detected  # Quality module detected an outlier
annotation.created        # Annotation module created an annotation
```

### Guidelines

1. **Use past tense**: Events describe what happened, not what will happen
2. **Be specific**: `resource.created` not `resource.changed`
3. **Use snake_case**: `outlier_detected` not `outlierDetected`
4. **Keep it short**: Prefer concise names that are still clear
5. **Avoid abbreviations**: `metadata.extracted` not `meta.ext`

---

## Event Categories

### Resource Lifecycle Events

Events related to resource creation, modification, and deletion.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `resource.created` | Resources | New resource added to system |
| `resource.updated` | Resources | Resource metadata or content changed |
| `resource.deleted` | Resources | Resource removed from system |

### Collection Events

Events related to collection management.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `collection.updated` | Collections | Collection metadata changed |
| `collection.deleted` | Collections | Collection removed |
| `collection.resource_added` | Collections | Resource added to collection |
| `collection.resource_removed` | Collections | Resource removed from collection |

### Annotation Events

Events related to user annotations.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `annotation.created` | Annotations | User created annotation |
| `annotation.updated` | Annotations | User modified annotation |
| `annotation.deleted` | Annotations | User deleted annotation |

### Quality Events

Events related to quality assessment.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `quality.computed` | Quality | Quality scores calculated |
| `quality.outlier_detected` | Quality | Anomalous quality detected |
| `quality.degradation_detected` | Quality | Quality decreased over time |

### Taxonomy Events

Events related to classification and taxonomy.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `resource.classified` | Taxonomy | Resource auto-classified |
| `taxonomy.node_created` | Taxonomy | New taxonomy node added |
| `taxonomy.model_trained` | Taxonomy | ML model retrained |

### Graph Events

Events related to knowledge graph and citations.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `citation.extracted` | Graph | Citations parsed from resource |
| `graph.updated` | Graph | Graph structure changed |
| `hypothesis.discovered` | Graph | LBD found new connection |

### Recommendation Events

Events related to recommendations and user profiles.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `recommendation.generated` | Recommendations | Recommendations produced |
| `user.profile_updated` | Recommendations | User preferences changed |
| `interaction.recorded` | Recommendations | User interaction logged |

### Scholarly Events

Events related to academic metadata.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `metadata.extracted` | Scholarly | Academic metadata parsed |
| `equations.parsed` | Scholarly | Mathematical equations found |
| `tables.extracted` | Scholarly | Tables extracted from content |

### Curation Events

Events related to content review.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `curation.reviewed` | Curation | Content reviewed by curator |
| `curation.approved` | Curation | Content approved |
| `curation.rejected` | Curation | Content rejected |

### Search Events

Events related to search operations.

| Event | Emitter | Purpose |
|-------|---------|---------|
| `search.completed` | Search | Search query executed |

---

## Complete Event Reference

### resource.created

**Emitter**: Resources Module  
**Subscribers**: Annotations, Quality, Taxonomy, Graph, Scholarly  
**Purpose**: Trigger processing for newly created resources

**Payload**:
```python
{
    "resource_id": str,        # UUID of created resource
    "title": str,              # Resource title
    "content": str,            # Resource content (may be truncated)
    "content_type": str,       # MIME type (e.g., "text/html")
    "url": str | None,         # Source URL if applicable
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("resource.created", {
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "title": "Introduction to Machine Learning",
    "content": "Machine learning is...",
    "content_type": "text/html",
    "url": "https://example.com/ml-intro",
    "timestamp": "2024-01-15T10:30:00Z"
})
```

**Subscribers React By**:
- **Quality**: Computing initial quality scores
- **Taxonomy**: Auto-classifying the resource
- **Graph**: Extracting citations
- **Scholarly**: Extracting academic metadata
- **Annotations**: (No immediate action, but enables annotation creation)

---

### resource.updated

**Emitter**: Resources Module  
**Subscribers**: Quality, Search  
**Purpose**: Update dependent data when resource changes

**Payload**:
```python
{
    "resource_id": str,        # UUID of updated resource
    "changed_fields": list,    # List of field names that changed
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("resource.updated", {
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "changed_fields": ["title", "content", "tags"],
    "timestamp": "2024-01-15T11:00:00Z"
})
```

**Subscribers React By**:
- **Quality**: Recomputing quality scores
- **Search**: Reindexing the resource

---

### resource.deleted

**Emitter**: Resources Module  
**Subscribers**: Collections, Annotations, Graph  
**Purpose**: Cascade cleanup when resource is removed

**Payload**:
```python
{
    "resource_id": str,        # UUID of deleted resource
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("resource.deleted", {
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "timestamp": "2024-01-15T12:00:00Z"
})
```

**Subscribers React By**:
- **Collections**: Removing resource from all collections
- **Annotations**: Deleting all annotations on the resource
- **Graph**: Removing resource from knowledge graph

---

### collection.updated

**Emitter**: Collections Module  
**Subscribers**: Search  
**Purpose**: Reindex collection when metadata changes

**Payload**:
```python
{
    "collection_id": str,      # UUID of updated collection
    "resource_count": int,     # Number of resources in collection
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("collection.updated", {
    "collection_id": "456e7890-e89b-12d3-a456-426614174000",
    "resource_count": 42,
    "timestamp": "2024-01-15T13:00:00Z"
})
```

**Subscribers React By**:
- **Search**: Reindexing the collection

---

### collection.resource_added

**Emitter**: Collections Module  
**Subscribers**: Recommendations  
**Purpose**: Update user preferences based on collection additions

**Payload**:
```python
{
    "collection_id": str,      # UUID of collection
    "resource_id": str,        # UUID of added resource
    "user_id": str,            # UUID of user who added it
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("collection.resource_added", {
    "collection_id": "456e7890-e89b-12d3-a456-426614174000",
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "user_id": "789e0123-e89b-12d3-a456-426614174000",
    "timestamp": "2024-01-15T14:00:00Z"
})
```

**Subscribers React By**:
- **Recommendations**: Updating user profile with new preferences

---

### annotation.created

**Emitter**: Annotations Module  
**Subscribers**: Recommendations  
**Purpose**: Update user profile based on annotation activity

**Payload**:
```python
{
    "annotation_id": str,      # UUID of created annotation
    "resource_id": str,        # UUID of annotated resource
    "user_id": str,            # UUID of user who created it
    "text": str,               # Annotation text
    "tags": list,              # List of tags
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("annotation.created", {
    "annotation_id": "abc12345-e89b-12d3-a456-426614174000",
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "user_id": "789e0123-e89b-12d3-a456-426614174000",
    "text": "Important concept for my research",
    "tags": ["machine-learning", "research"],
    "timestamp": "2024-01-15T15:00:00Z"
})
```

**Subscribers React By**:
- **Recommendations**: Updating user profile with annotation topics

---

### quality.computed

**Emitter**: Quality Module  
**Subscribers**: Monitoring  
**Purpose**: Track quality metrics across the system

**Payload**:
```python
{
    "resource_id": str,        # UUID of assessed resource
    "overall_score": float,    # Overall quality score (0-1)
    "dimensions": dict,        # Scores by dimension
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("quality.computed", {
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "overall_score": 0.85,
    "dimensions": {
        "completeness": 0.9,
        "accuracy": 0.8,
        "readability": 0.85
    },
    "timestamp": "2024-01-15T16:00:00Z"
})
```

**Subscribers React By**:
- **Monitoring**: Aggregating quality statistics

---

### quality.outlier_detected

**Emitter**: Quality Module  
**Subscribers**: Curation  
**Purpose**: Flag resources with anomalous quality for review

**Payload**:
```python
{
    "resource_id": str,        # UUID of outlier resource
    "outlier_score": float,    # How anomalous (higher = more anomalous)
    "reasons": list,           # List of reasons for outlier status
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("quality.outlier_detected", {
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "outlier_score": 0.95,
    "reasons": [
        "Completeness score 3 std devs below mean",
        "Readability score in bottom 5%"
    ],
    "timestamp": "2024-01-15T17:00:00Z"
})
```

**Subscribers React By**:
- **Curation**: Adding resource to review queue with high priority

---

### resource.classified

**Emitter**: Taxonomy Module  
**Subscribers**: Search  
**Purpose**: Update search index with classification results

**Payload**:
```python
{
    "resource_id": str,        # UUID of classified resource
    "classifications": list,   # List of classification results
    "model_version": str,      # ML model version used
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("resource.classified", {
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "classifications": [
        {"category": "cs.AI", "confidence": 0.92},
        {"category": "cs.LG", "confidence": 0.85}
    ],
    "model_version": "v2.0",
    "timestamp": "2024-01-15T18:00:00Z"
})
```

**Subscribers React By**:
- **Search**: Updating search index with classification tags

---

### citation.extracted

**Emitter**: Graph Module  
**Subscribers**: Monitoring  
**Purpose**: Track citation network growth

**Payload**:
```python
{
    "resource_id": str,        # UUID of resource with citations
    "citation_count": int,     # Number of citations found
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("citation.extracted", {
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "citation_count": 15,
    "timestamp": "2024-01-15T19:00:00Z"
})
```

**Subscribers React By**:
- **Monitoring**: Tracking citation network statistics

---

### recommendation.generated

**Emitter**: Recommendations Module  
**Subscribers**: Monitoring  
**Purpose**: Track recommendation quality and usage

**Payload**:
```python
{
    "user_id": str,            # UUID of user receiving recommendations
    "count": int,              # Number of recommendations generated
    "strategy": str,           # Strategy used (e.g., "hybrid")
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("recommendation.generated", {
    "user_id": "789e0123-e89b-12d3-a456-426614174000",
    "count": 10,
    "strategy": "hybrid",
    "timestamp": "2024-01-15T20:00:00Z"
})
```

**Subscribers React By**:
- **Monitoring**: Aggregating recommendation metrics

---

### metadata.extracted

**Emitter**: Scholarly Module  
**Subscribers**: Monitoring  
**Purpose**: Track metadata extraction completeness

**Payload**:
```python
{
    "resource_id": str,        # UUID of resource
    "metadata_fields": list,   # List of extracted field names
    "timestamp": str           # ISO 8601 timestamp
}
```

**Example**:
```python
event_bus.emit("metadata.extracted", {
    "resource_id": "123e4567-e89b-12d3-a456-426614174000",
    "metadata_fields": ["authors", "abstract", "doi", "publication_date"],
    "timestamp": "2024-01-15T21:00:00Z"
})
```

**Subscribers React By**:
- **Monitoring**: Tracking metadata completeness statistics

---

## Event Flow Diagrams

### Resource Creation Flow

```
User creates resource via API
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Resources Module  â”‚
â”‚ â”œâ”€ Save to DB     â”‚
â”‚ â”œâ”€ Emit event     â”‚
â”‚ â””â”€ Return responseâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ resource.created
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Event Bus Distribution                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“          â†“          â†“          â†“          â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Quality â”‚ â”‚Taxonomyâ”‚ â”‚ Graph  â”‚ â”‚Scholarlyâ”‚ â”‚Annot.  â”‚
   â”‚        â”‚ â”‚        â”‚ â”‚        â”‚ â”‚        â”‚ â”‚        â”‚
   â”‚Compute â”‚ â”‚Auto-   â”‚ â”‚Extract â”‚ â”‚Extract â”‚ â”‚(Ready) â”‚
   â”‚quality â”‚ â”‚classifyâ”‚ â”‚citationsâ”‚ â”‚metadataâ”‚ â”‚        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚          â”‚          â”‚          â”‚
        â†“          â†“          â†“          â†“
   quality.   resource.  citation.  metadata.
   computed   classified extracted  extracted
```

### Quality Outlier Detection Flow

```
Quality Module computes scores
        â†“
Detects outlier (score > threshold)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Quality Module   â”‚
â”‚ Emit event        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ quality.outlier_detected
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Curation Module   â”‚
â”‚ â”œâ”€ Add to queue   â”‚
â”‚ â”œâ”€ Set priority   â”‚
â”‚ â””â”€ Notify curator â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ curation.reviewed (when reviewed)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monitoring Module â”‚
â”‚ Track metrics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### User Interaction Flow

```
User adds annotation
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Annotations Module â”‚
â”‚ â”œâ”€ Save annotationâ”‚
â”‚ â”œâ”€ Emit event     â”‚
â”‚ â””â”€ Return responseâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ annotation.created
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Recommendations Moduleâ”‚
â”‚ â”œâ”€ Update profile     â”‚
â”‚ â”œâ”€ Adjust preferences â”‚
â”‚ â”œâ”€ Emit event         â”‚
â”‚ â””â”€ Refresh recs       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ user.profile_updated
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monitoring Module â”‚
â”‚ Track engagement  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Resource Deletion Cascade

```
User deletes resource
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Resources Module  â”‚
â”‚ â”œâ”€ Delete from DB â”‚
â”‚ â”œâ”€ Emit event     â”‚
â”‚ â””â”€ Return 204     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ resource.deleted
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Event Bus Distribution          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“          â†“          â†“          â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Collect.â”‚ â”‚Annot.  â”‚ â”‚ Graph  â”‚ â”‚Monitor.â”‚
   â”‚        â”‚ â”‚        â”‚ â”‚        â”‚ â”‚        â”‚
   â”‚Remove  â”‚ â”‚Delete  â”‚ â”‚Remove  â”‚ â”‚Track   â”‚
   â”‚from    â”‚ â”‚all     â”‚ â”‚from    â”‚ â”‚deletionâ”‚
   â”‚colls   â”‚ â”‚annots  â”‚ â”‚graph   â”‚ â”‚        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Best Practices

### For Event Emitters

1. **Emit after commit**: Always emit events AFTER database commits succeed
   ```python
   # Good
   db.commit()
   event_bus.emit("resource.created", payload)
   
   # Bad - event emitted before commit
   event_bus.emit("resource.created", payload)
   db.commit()  # Could fail!
   ```

2. **Include sufficient context**: Provide enough information for subscribers
   ```python
   # Good - includes all relevant data
   event_bus.emit("resource.created", {
       "resource_id": str(resource.id),
       "title": resource.title,
       "content_type": resource.content_type,
       "timestamp": datetime.now(timezone.utc).isoformat()
   })
   
   # Bad - insufficient context
   event_bus.emit("resource.created", {
       "resource_id": str(resource.id)
   })
   ```

3. **Use ISO 8601 timestamps**: Always include timestamps in ISO 8601 format
   ```python
   from datetime import datetime, timezone
   
   "timestamp": datetime.now(timezone.utc).isoformat()
   ```

4. **Don't emit on failures**: Only emit events for successful operations
   ```python
   try:
       resource = create_resource(data)
       db.commit()
       event_bus.emit("resource.created", payload)
   except Exception as e:
       db.rollback()
       # Don't emit event on failure
       raise
   ```

### For Event Subscribers

1. **Create fresh database sessions**: Always create new sessions in handlers
   ```python
   def handle_resource_created(payload: dict):
       from app.shared.database import SessionLocal
       
       db = SessionLocal()  # Fresh session
       try:
           # Process event
           pass
       finally:
           db.close()  # Always close
   ```

2. **Catch all exceptions**: Don't let handler failures affect other handlers
   ```python
   def handle_event(payload: dict):
       try:
           # Process event
           pass
       except Exception as e:
           logger.error(f"Handler error: {e}", exc_info=True)
           # Don't re-raise - let other handlers continue
       finally:
           db.close()
   ```

3. **Keep handlers fast**: Aim for <100ms execution time
   ```python
   # Good - quick processing
   def handle_event(payload: dict):
       resource_id = payload["resource_id"]
       update_cache(resource_id)  # Fast operation
   
   # Bad - slow processing
   def handle_event(payload: dict):
       resource_id = payload["resource_id"]
       recompute_all_embeddings()  # Slow! Use Celery instead
   ```

4. **Make handlers idempotent**: Safe to run multiple times
   ```python
   def handle_resource_created(payload: dict):
       resource_id = payload["resource_id"]
       
       # Check if already processed
       if already_processed(resource_id):
           return
       
       # Process event
       process_resource(resource_id)
       mark_as_processed(resource_id)
   ```

5. **Log all processing**: Include event type and payload in logs
   ```python
   def handle_event(payload: dict):
       logger.info(f"Processing event: {payload}")
       try:
           # Process
           logger.info(f"Successfully processed: {payload}")
       except Exception as e:
           logger.error(f"Failed to process: {payload}", exc_info=True)
   ```

### Event Payload Guidelines

1. **Use UUIDs as strings**: Always convert UUIDs to strings
   ```python
   "resource_id": str(resource.id)  # Good
   "resource_id": resource.id       # Bad - not JSON serializable
   ```

2. **Keep payloads small**: Don't include large content
   ```python
   # Good - reference only
   "resource_id": "123e4567-e89b-12d3-a456-426614174000"
   
   # Bad - includes full content
   "content": "..." # 10MB of text
   ```

3. **Use consistent field names**: Follow naming conventions
   ```python
   # Good - snake_case
   "resource_id", "user_id", "created_at"
   
   # Bad - mixed case
   "resourceId", "userId", "createdAt"
   ```

4. **Include metadata**: Add context for debugging
   ```python
   {
       "resource_id": "...",
       "timestamp": "2024-01-15T10:00:00Z",
       "source": "api",  # Where did this come from?
       "user_id": "..."  # Who triggered it?
   }
   ```

---

## Monitoring Events

### Event Bus Metrics

Check event bus health and metrics:

```bash
curl http://localhost:8000/monitoring/events
```

Response:
```json
{
  "events_emitted": 1523,
  "events_delivered": 4569,
  "handler_errors": 3,
  "event_types": {
    "resource.created": 234,
    "resource.updated": 1289,
    "quality.computed": 234,
    "resource.classified": 234
  },
  "latency_ms": {
    "p50": 0.8,
    "p95": 2.3,
    "p99": 5.1
  }
}
```

### Event History

View recent events:

```bash
curl http://localhost:8000/monitoring/events/history?limit=10
```

Response:
```json
{
  "events": [
    {
      "type": "resource.created",
      "timestamp": "2024-01-15T10:00:00Z",
      "payload": {"resource_id": "..."},
      "handlers_called": 5,
      "latency_ms": 1.2
    }
  ]
}
```

### Debugging Event Issues

1. **Check if event is being emitted**:
   ```python
   # Add logging in emitter
   logger.info(f"Emitting event: {event_type}")
   event_bus.emit(event_type, payload)
   ```

2. **Check if handlers are registered**:
   ```bash
   curl http://localhost:8000/monitoring/events
   # Look at handler_count per event type
   ```

3. **Check handler errors**:
   ```bash
   curl http://localhost:8000/monitoring/events/history
   # Look for events with errors
   ```

4. **Enable debug logging**:
   ```python
   # In app/shared/event_bus.py
   logger.setLevel(logging.DEBUG)
   ```

---

## Related Documentation

- [Architecture Overview](overview.md) - System architecture
- [Event System](event-system.md) - Event bus implementation details
- [Module Documentation](modules.md) - Module-specific event usage
- [Migration Guide](../MIGRATION_GUIDE.md) - Event-driven migration patterns
- [Development Workflows](../guides/workflows.md) - Working with events

---

*Last Updated: Phase 14 Complete - December 2024*


<div style='page-break-after: always;'></div>

---



# 23. Module Architecture

*Source: `backend/docs/architecture/modules.md`*

---

# Vertical Slice Modules & Service Architecture

Module architecture, service layer, and class hierarchies for Neo Alexandria 2.0.

> **Last Updated**: Phase 14 - Complete Vertical Slice Refactor

## Modular Architecture Overview (Phase 14 - Complete)

Phase 14 completes the vertical slice architecture transformation with 13 self-contained modules.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NEO ALEXANDRIA 2.0 - COMPLETE MODULAR ARCHITECTURE                   â”‚
â”‚                              (13 Vertical Slice Modules)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         FastAPI Application (main.py)                            â”‚   â”‚
â”‚  â”‚                    Registers all module routers & event handlers                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                                 â”‚
â”‚                                       â”‚ Module Registration                             â”‚
â”‚                                       â”‚                                                 â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚       â”‚                               â”‚                                   â”‚             â”‚
â”‚       â–¼                               â–¼                                   â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Resources â”‚  â”‚Collectionsâ”‚ â”‚  Search  â”‚  â”‚Annotationsâ”‚ â”‚ Scholarlyâ”‚  â”‚ Authorityâ”‚   â”‚
â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚             â”‚             â”‚             â”‚             â”‚             â”‚          â”‚
â”‚       â”‚             â”‚             â”‚             â”‚             â”‚             â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Curation â”‚  â”‚  Quality â”‚  â”‚ Taxonomy â”‚  â”‚  Graph   â”‚  â”‚Recommend-â”‚  â”‚Monitoringâ”‚   â”‚
â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚ ations   â”‚  â”‚  Module  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚             â”‚             â”‚             â”‚             â”‚             â”‚          â”‚
â”‚       â”‚             â”‚             â”‚             â”‚             â”‚             â”‚          â”‚
â”‚       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚       â”‚    â”‚                                                                           â”‚
â”‚       â”‚    â–¼                                                                           â”‚
â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚       â”‚  â”‚                      Shared Kernel                              â”‚           â”‚
â”‚       â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚           â”‚
â”‚       â””â”€â–ºâ”‚  â”‚ Database â”‚  â”‚  Event Bus   â”‚  â”‚  Base Model  â”‚              â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚          â”‚  â”‚ (Session)â”‚  â”‚  (Pub/Sub)   â”‚  â”‚   (GUID)     â”‚              â”‚           â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚           â”‚
â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚           â”‚
â”‚          â”‚  â”‚  Cross-Cutting Services:                                 â”‚   â”‚           â”‚
â”‚          â”‚  â”‚  â€¢ EmbeddingService (dense & sparse embeddings)          â”‚   â”‚           â”‚
â”‚          â”‚  â”‚  â€¢ AICore (summarization, entity extraction)             â”‚   â”‚           â”‚
â”‚          â”‚  â”‚  â€¢ CacheService (Redis caching with TTL)                 â”‚   â”‚           â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚           â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### All 13 Modules

| # | Module | Domain | Events Emitted | Events Consumed |
|---|--------|--------|----------------|-----------------|
| 1 | **Resources** | Content management | resource.created, resource.updated, resource.deleted | - |
| 2 | **Collections** | Organization | collection.created, collection.updated, collection.resource_added | resource.deleted |
| 3 | **Search** | Discovery | search.executed | resource.created, resource.updated |
| 4 | **Annotations** | Highlights & notes | annotation.created, annotation.updated, annotation.deleted | resource.deleted |
| 5 | **Scholarly** | Academic metadata | metadata.extracted, equations.parsed, tables.extracted | resource.created |
| 6 | **Authority** | Subject authority | - | - |
| 7 | **Curation** | Content review | curation.reviewed, curation.approved, curation.rejected | quality.outlier_detected |
| 8 | **Quality** | Quality assessment | quality.computed, quality.outlier_detected | resource.created, resource.updated |
| 9 | **Taxonomy** | ML classification | resource.classified, taxonomy.node_created | resource.created |
| 10 | **Graph** | Knowledge graph | citation.extracted, graph.updated, hypothesis.discovered | resource.created, resource.deleted |
| 11 | **Recommendations** | Personalization | recommendation.generated, user.profile_updated | annotation.created, collection.resource_added |
| 12 | **Monitoring** | System health | - | All events (metrics) |

---

## Vertical Slice Module Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VERTICAL SLICE MODULE PATTERN                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Each module (Resources, Collections, Search) follows this structure:   â”‚
â”‚                                                                         â”‚
â”‚  app/modules/{module_name}/                                             â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ __init__.py          # Public interface & exports                  â”‚
â”‚  â”‚   â€¢ router                                                          â”‚
â”‚  â”‚   â€¢ service functions                                               â”‚
â”‚  â”‚   â€¢ schemas                                                         â”‚
â”‚  â”‚   â€¢ models                                                          â”‚
â”‚  â”‚   â€¢ module metadata (__version__, __domain__)                       â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ router.py            # FastAPI endpoints                          â”‚
â”‚  â”‚   â€¢ HTTP request/response handling                                  â”‚
â”‚  â”‚   â€¢ Input validation                                                â”‚
â”‚  â”‚   â€¢ Calls service layer                                             â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ service.py           # Business logic                             â”‚
â”‚  â”‚   â€¢ Core domain operations                                          â”‚
â”‚  â”‚   â€¢ Orchestration                                                   â”‚
â”‚  â”‚   â€¢ Event emission                                                  â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ schema.py            # Pydantic models                            â”‚
â”‚  â”‚   â€¢ Request/response validation                                     â”‚
â”‚  â”‚   â€¢ Data serialization                                              â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ model.py             # SQLAlchemy models                          â”‚
â”‚  â”‚   â€¢ Database entities                                               â”‚
â”‚  â”‚   â€¢ String-based relationships (avoid circular imports)             â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ handlers.py          # Event handlers                             â”‚
â”‚  â”‚   â€¢ Subscribe to events from other modules                          â”‚
â”‚  â”‚   â€¢ React to system events                                          â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ README.md            # Module documentation                       â”‚
â”‚  â”‚                                                                      â”‚
â”‚  â””â”€â”€ tests/               # Module-specific tests                      â”‚
â”‚      â””â”€â”€ __init__.py                                                   â”‚
â”‚                                                                         â”‚
â”‚  Benefits:                                                              â”‚
â”‚  â€¢ High cohesion - related code stays together                         â”‚
â”‚  â€¢ Low coupling - modules communicate via events                       â”‚
â”‚  â€¢ Independent deployment - modules can be extracted to microservices  â”‚
â”‚  â€¢ Clear boundaries - explicit public interfaces                       â”‚
â”‚  â€¢ Easy testing - isolated module tests                                â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Current Modules

### Resources Module

**Domain:** Content management and ingestion

**Responsibilities:**
- Resource CRUD operations
- URL ingestion and content extraction
- AI-powered summarization and tagging
- Quality score computation
- Classification assignment

**Events Published:**
- `resource.created`
- `resource.updated`
- `resource.deleted`
- `resource.classified`

**Location:** `app/modules/resources/`

### Collections Module

**Domain:** Resource organization and curation

**Responsibilities:**
- Collection CRUD operations
- Hierarchical organization (parent-child)
- Resource membership management
- Aggregate embedding computation
- Collection-based recommendations

**Events Published:**
- `collection.created`
- `collection.updated`
- `collection.deleted`
- `collection.resource_added`
- `collection.resource_removed`

**Events Subscribed:**
- `resource.deleted` â†’ Remove from collections

**Location:** `app/modules/collections/`

### Search Module

**Domain:** Discovery and retrieval

**Responsibilities:**
- Hybrid search (keyword + semantic)
- Three-way search with RRF fusion
- Faceted search results
- Search quality evaluation

**Events Published:**
- `search.executed`

**Events Subscribed:**
- `resource.created` â†’ Update search index
- `resource.updated` â†’ Update search index
- `resource.deleted` â†’ Remove from index

**Location:** `app/modules/search/`

---

## Module Communication

Modules communicate through the event bus, not direct imports:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODULE COMMUNICATION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  âŒ WRONG: Direct Import                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  from app.modules.resources.service import get_resource              â”‚
â”‚                                                                      â”‚
â”‚  âœ… CORRECT: Event-Based Communication                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚  event_bus.publish(Event(type="resource.deleted", payload={...}))    â”‚
â”‚                                                                      â”‚
â”‚  âœ… CORRECT: Shared Kernel                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  from app.shared.database import get_db                              â”‚
â”‚  from app.shared.event_bus import event_bus                          â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Shared Kernel

Common infrastructure shared by all modules:

```
app/shared/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ database.py      # Database session, engine
â”œâ”€â”€ event_bus.py     # Event publishing/subscribing
â””â”€â”€ base_model.py    # Base SQLAlchemy model with GUID
```

### Database Access

```python
from app.shared.database import get_db, SessionLocal

# In router
@router.get("/resources")
def list_resources(db: Session = Depends(get_db)):
    return service.list_resources(db)
```

### Event Bus

```python
from app.shared.event_bus import event_bus, Event

# Publishing
event_bus.publish(Event(
    type="resource.created",
    payload={"resource_id": str(resource.id)}
))

# Subscribing
event_bus.subscribe("resource.deleted", handle_resource_deleted)
```

### Base Model

```python
from app.shared.base_model import BaseModel

class Resource(BaseModel):
    __tablename__ = "resources"
    # Inherits: id (UUID), created_at, updated_at
    title = Column(String, nullable=False)
```

---

## Service Layer Architecture

The service layer implements business logic and orchestrates domain objects, database operations, and external services.

### ML Classification Service

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MLClassificationService                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                        â”‚
â”‚  â€¢ db: Session                                                     â”‚
â”‚  â€¢ model_name: str = "distilbert-base-uncased"                     â”‚
â”‚  â€¢ model: Optional[AutoModelForSequenceClassification]             â”‚
â”‚  â€¢ tokenizer: Optional[AutoTokenizer]                              â”‚
â”‚  â€¢ id_to_label: Dict[int, str]                                     â”‚
â”‚  â€¢ label_to_id: Dict[str, int]                                     â”‚
â”‚  â€¢ monitor: PredictionMonitor                                      â”‚
â”‚  â€¢ checkpoint_dir: Path                                            â”‚
â”‚  â€¢ device: torch.device                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Constants:                                                         â”‚
â”‚  â€¢ DEFAULT_MODEL_NAME = "distilbert-base-uncased"                  â”‚
â”‚  â€¢ MAX_TOKEN_LENGTH = 512                                          â”‚
â”‚  â€¢ DEFAULT_EPOCHS = 3                                              â”‚
â”‚  â€¢ DEFAULT_BATCH_SIZE = 16                                         â”‚
â”‚  â€¢ DEFAULT_LEARNING_RATE = 2e-5                                    â”‚
â”‚  â€¢ BINARY_PREDICTION_THRESHOLD = 0.5                               â”‚
â”‚  â€¢ HIGH_CONFIDENCE_THRESHOLD = 0.8                                 â”‚
â”‚  â€¢ DEFAULT_TOP_K = 5                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Public Methods:                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Training & Fine-tuning                                       â”‚  â”‚ 
â”‚  â”‚  â€¢ fine_tune(labeled_data, ...) â†’ Dict[str, float]           â”‚  â”‚
â”‚  â”‚  â€¢ semi_supervised_learning(...) â†’ Dict[str, float]          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ 
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Inference                                                    â”‚  â”‚
â”‚  â”‚  â€¢ predict(text, top_k) â†’ ClassificationResult               â”‚  â”‚
â”‚  â”‚  â€¢ predict_batch(texts, top_k) â†’ List[ClassificationResult]  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Active Learning                                              â”‚  â”‚
â”‚  â”‚  â€¢ active_learning_uncertainty_sampling(...)                 â”‚  â”‚
â”‚  â”‚  â€¢ get_model_metrics(window_minutes) â†’ Dict                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Private Methods (20+ helper methods):                              â”‚
â”‚  â€¢ _load_model(), _import_ml_libraries()                           â”‚
â”‚  â€¢ _tokenize_texts(), _create_datasets()                           â”‚
â”‚  â€¢ _compute_metrics(), _calculate_classification_metrics()         â”‚
â”‚  â€¢ _build_label_mapping(), _convert_to_multihot_encoding()         â”‚
â”‚  â€¢ _split_train_validation(), _initialize_model_for_training()     â”‚
â”‚  â€¢ _configure_trainer(), _train_model()                            â”‚
â”‚  â€¢ _perform_semi_supervised_learning()                             â”‚
â”‚  â€¢ _save_model_and_artifacts(), _extract_metrics()                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quality Service

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ContentQualityAnalyzer                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                    â”‚
â”‚  â€¢ REQUIRED_KEYS: List[str] = ["title", "description",         â”‚
â”‚    "subject", "creator", "language", "type", "identifier"]     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Constants:                                                     â”‚
â”‚  â€¢ METADATA_WEIGHT = 0.6                                       â”‚
â”‚  â€¢ READABILITY_WEIGHT = 0.4                                    â”‚
â”‚  â€¢ READING_EASE_MIN = 0.0                                      â”‚
â”‚  â€¢ READING_EASE_MAX = 100.0                                    â”‚
â”‚  â€¢ CREDIBILITY_HIGH = 0.9                                      â”‚
â”‚  â€¢ CREDIBILITY_MEDIUM = 0.7                                    â”‚
â”‚  â€¢ CREDIBILITY_DEFAULT = 0.6                                   â”‚
â”‚  â€¢ DEPTH_THRESHOLD_MINIMAL = 100                               â”‚
â”‚  â€¢ DEPTH_THRESHOLD_SHORT = 500                                 â”‚
â”‚  â€¢ DEPTH_THRESHOLD_MEDIUM = 2000                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                       â”‚
â”‚  â€¢ metadata_completeness(resource) â†’ float                     â”‚
â”‚  â€¢ text_readability(text) â†’ Dict[str, float]                   â”‚
â”‚  â€¢ overall_quality(resource, text) â†’ float                     â”‚
â”‚  â€¢ quality_level(score) â†’ str                                  â”‚
â”‚  â€¢ source_credibility(source) â†’ float                          â”‚
â”‚  â€¢ content_depth(text) â†’ float                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ used by
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      QualityService                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                    â”‚
â”‚  â€¢ db: Session                                                 â”‚
â”‚  â€¢ quality_version: str = "v2.0"                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Constants:                                                     â”‚
â”‚  â€¢ HIGH_QUALITY_THRESHOLD = 0.8                                â”‚
â”‚  â€¢ MEDIUM_QUALITY_THRESHOLD = 0.5                              â”‚
â”‚  â€¢ DEFAULT_QUALITY_WEIGHTS = {...}                             â”‚
â”‚  â€¢ COMPLETENESS_FIELD_WEIGHT = 0.2                             â”‚
â”‚  â€¢ DEGRADATION_THRESHOLD = 0.2                                 â”‚
â”‚  â€¢ OUTLIER_MIN_RESOURCES = 10                                  â”‚
â”‚  â€¢ OUTLIER_CONTAMINATION = 0.1                                 â”‚
â”‚  â€¢ OUTLIER_THRESHOLD_LOW = 0.3                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Public Methods:                                                â”‚
â”‚  â€¢ compute_quality(resource_id, weights) â†’ QualityScore        â”‚
â”‚  â€¢ monitor_quality_degradation(days) â†’ List[Dict]              â”‚
â”‚  â€¢ detect_quality_outliers(batch_size) â†’ int                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Private Methods:                                               â”‚
â”‚  â€¢ _compute_accuracy_dimension(resource) â†’ float               â”‚
â”‚  â€¢ _compute_completeness_dimension(resource) â†’ float           â”‚
â”‚  â€¢ _compute_consistency_dimension(resource) â†’ float            â”‚
â”‚  â€¢ _compute_timeliness_dimension(resource) â†’ float             â”‚
â”‚  â€¢ _compute_relevance_dimension(resource) â†’ float              â”‚
â”‚  â€¢ _update_resource_quality_fields(resource, ...) â†’ None       â”‚
â”‚  â€¢ _identify_outlier_reasons(resource) â†’ List[str]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Recommendation Service (Strategy Pattern)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  RecommendationStrategy      â”‚
                    â”‚  (Abstract Base Class)       â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ + generate(user_id, limit)   â”‚
                    â”‚   â†’ List[Recommendation]     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â”‚ implements
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                    â”‚                    â”‚                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Collaborative      â”‚  â”‚  Content      â”‚    â”‚   Graph       â”‚   â”‚  Hybrid  â”‚
    â”‚ FilteringStrategy  â”‚  â”‚  BasedStrategyâ”‚    â”‚BasedStrategy  â”‚   â”‚ Strategy â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚â€¢ db: Session       â”‚  â”‚â€¢ db: Session  â”‚    â”‚â€¢ db: Session  â”‚   â”‚â€¢ strats  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚â€¢ weights â”‚
    â”‚+ generate()        â”‚  â”‚+ generate()   â”‚    â”‚+ generate()   â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚- _build_matrix()   â”‚  â”‚- _build_prof()â”‚    â”‚- _traverse()  â”‚   â”‚+ generateâ”‚
    â”‚- _find_similar()   â”‚  â”‚- _compute_sim â”‚    â”‚- _score_path()â”‚   â”‚- _merge()â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
RecommendationService
â”œâ”€â”€ Public Functions:
â”‚   â”œâ”€â”€ get_graph_based_recommendations(db, resource_id, limit=10)
â”‚   â”œâ”€â”€ generate_recommendations_with_graph_fusion(db, resource_id, ...)
â”‚   â”œâ”€â”€ generate_recommendations(db, resource_id, limit, strategy, user_id)
â”‚   â”œâ”€â”€ generate_user_profile_vector(db, user_id) â†’ List[float]
â”‚   â”œâ”€â”€ recommend_based_on_annotations(db, user_id, limit) â†’ List[Dict]
â”‚   â””â”€â”€ get_top_subjects(db, limit=10) â†’ List[str]
â”œâ”€â”€ Private Functions:
â”‚   â”œâ”€â”€ _cosine_similarity(vec1, vec2) â†’ float
â”‚   â”œâ”€â”€ _convert_subjects_to_vector(subjects) â†’ List[float]
â”‚   â””â”€â”€ _to_numpy_vector(data) â†’ List[float]

RecommendationStrategyFactory
â”œâ”€â”€ Methods:
â”‚   â””â”€â”€ create(strategy_type: str, db: Session) â†’ RecommendationStrategy
```

### Search Service

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AdvancedSearchService                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Public Methods:                                                â”‚
â”‚  â€¢ hybrid_search(db, query, weight) â†’ (resources, total, ...)  â”‚
â”‚  â€¢ fts_search(db, query, filters, ...) â†’ (resources, ...)      â”‚
â”‚  â€¢ vector_search(db, query_text, ...) â†’ (resources, ...)       â”‚
â”‚  â€¢ parse_search_query(query: str) â†’ str                        â”‚
â”‚  â€¢ generate_snippets(text, query, max_len) â†’ str               â”‚
â”‚                                                                â”‚
â”‚ Private Methods:                                               â”‚
â”‚  â€¢ _analyze_query(query) â†’ Dict[str, Any]                      â”‚
â”‚  â€¢ _search_sparse(db, query_text, limit) â†’ List[Tuple]         â”‚
â”‚  â€¢ _fetch_resources_ordered(db, ids, filters) â†’ List[Res]      â”‚
â”‚  â€¢ _compute_facets(db, query) â†’ Facets                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ uses
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     HybridSearchQuery                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                    â”‚
â”‚  â€¢ db: Session                                                 â”‚
â”‚  â€¢ query: DomainSearchQuery                                    â”‚
â”‚  â€¢ enable_reranking: bool                                      â”‚
â”‚  â€¢ adaptive_weighting: bool                                    â”‚
â”‚  â€¢ _diagnostics: Dict[str, Any]                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Public Methods:                                                â”‚
â”‚  â€¢ execute() â†’ Tuple[List[Resource], int, Facets, ...]         â”‚
â”‚  â€¢ get_diagnostic_info() â†’ Dict[str, Any]                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Private Methods:                                               â”‚
â”‚  â€¢ _convert_to_schema_filters() â†’ SearchFilters | None         â”‚
â”‚  â€¢ _ensure_tables_exist() â†’ None                               â”‚
â”‚  â€¢ _check_services_available() â†’ bool                          â”‚
â”‚  â€¢ _fallback_to_two_way_hybrid(start_time) â†’ Tuple[...]        â”‚
â”‚  â€¢ _analyze_query() â†’ Dict[str, Any]                           â”‚
â”‚  â€¢ _execute_retrieval_phase() â†’ RetrievalCandidates            â”‚
â”‚  â€¢ _execute_fusion_phase(candidates) â†’ FusedCandidates         â”‚
â”‚  â€¢ _execute_reranking_phase(fused) â†’ List[Tuple[str, float]]   â”‚
â”‚  â€¢ _search_fts5() â†’ List[Tuple[str, float]]                    â”‚
â”‚  â€¢ _search_dense() â†’ List[Tuple[str, float]]                   â”‚
â”‚  â€¢ _search_sparse() â†’ List[Tuple[str, float]]                  â”‚
â”‚  â€¢ _compute_weights() â†’ List[float]                            â”‚
â”‚  â€¢ _compute_method_contributions(...) â†’ Dict[str, int]         â”‚
â”‚  â€¢ _fetch_paginated_resources(fused) â†’ List[Resource]          â”‚
â”‚  â€¢ _compute_facets(fused) â†’ Facets                             â”‚
â”‚  â€¢ _generate_snippets(resources) â†’ Dict[str, str]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Search Pipeline Data Structures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RetrievalCandidates                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                    â”‚
â”‚  â€¢ fts5_results: List[Tuple[str, float]]                       â”‚
â”‚  â€¢ dense_results: List[Tuple[str, float]]                      â”‚
â”‚  â€¢ sparse_results: List[Tuple[str, float]]                     â”‚
â”‚  â€¢ retrieval_time_ms: float                                    â”‚
â”‚  â€¢ method_times_ms: Dict[str, float]                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                       â”‚
â”‚  â€¢ get_all_candidate_ids() â†’ set[str]                          â”‚
â”‚  â€¢ get_method_counts() â†’ Dict[str, int]                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ feeds into
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FusedCandidates                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                    â”‚
â”‚  â€¢ fused_results: List[Tuple[str, float]]                      â”‚
â”‚  â€¢ weights_used: List[float]                                   â”‚
â”‚  â€¢ fusion_time_ms: float                                       â”‚
â”‚  â€¢ method_contributions: Dict[str, int]                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                       â”‚
â”‚  â€¢ get_top_k(k: int) â†’ List[Tuple[str, float]]                 â”‚
â”‚  â€¢ get_candidate_ids() â†’ List[str]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Domain Layer Architecture (Phase 11)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DOMAIN-DRIVEN DESIGN (DDD) REFACTORING                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                   â”‚  BaseDomainObject (ABC)  â”‚                          â”‚
â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                          â”‚
â”‚                   â”‚ + to_dict()              â”‚                          â”‚
â”‚                   â”‚ + from_dict()            â”‚                          â”‚
â”‚                   â”‚ + to_json()              â”‚                          â”‚
â”‚                   â”‚ + from_json()            â”‚                          â”‚
â”‚                   â”‚ + validate() [abstract]  â”‚                          â”‚
â”‚                   â”‚ + __eq__()               â”‚                          â”‚
â”‚                   â”‚ + __repr__()             â”‚                          â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                            â”‚                                            â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚              â”‚                            â”‚                             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚   ValueObject      â”‚      â”‚   DomainEntity      â”‚                  â”‚
â”‚    â”‚   (dataclass)      â”‚      â”‚                     â”‚                  â”‚
â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
â”‚    â”‚ Immutable          â”‚      â”‚ â€¢ entity_id: str    â”‚                  â”‚
â”‚    â”‚ Defined by values  â”‚      â”‚ Identity-based      â”‚                  â”‚
â”‚    â”‚ No identity        â”‚      â”‚ Mutable             â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚              â”‚                                                          â”‚
â”‚              â”‚ subclasses                                               â”‚
â”‚              â”‚                                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚    â”‚         â”‚         â”‚             â”‚             â”‚             â”‚      â”‚
â”‚    â–¼         â–¼         â–¼             â–¼             â–¼             â–¼      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚Class-â”‚ â”‚Class-â”‚ â”‚ Quality  â”‚ â”‚Recommend-â”‚ â”‚ Search   â”‚ â”‚ Search   â”‚   â”‚
â”‚ â”‚ifica-â”‚ â”‚ifica-â”‚ â”‚  Score   â”‚ â”‚  ation   â”‚ â”‚  Query   â”‚ â”‚ Result   â”‚   â”‚
â”‚ â”‚tion  â”‚ â”‚tion  â”‚ â”‚          â”‚ â”‚  Score   â”‚ â”‚          â”‚ â”‚          â”‚   â”‚
â”‚ â”‚Predicâ”‚ â”‚Resultâ”‚ â”‚          â”‚ â”‚          â”‚ â”‚          â”‚ â”‚          â”‚   â”‚
â”‚ â”‚tion  â”‚ â”‚      â”‚ â”‚          â”‚ â”‚          â”‚ â”‚          â”‚ â”‚          â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Domain Objects


#### Classification Domain

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ClassificationPrediction (ValueObject)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                  â”‚
â”‚  â€¢ taxonomy_id: str                                          â”‚
â”‚  â€¢ confidence: float (0.0-1.0)                               â”‚
â”‚  â€¢ rank: int (1-based)                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                     â”‚
â”‚  â€¢ validate()                                                â”‚
â”‚  â€¢ is_high_confidence(threshold=0.8) â†’ bool                  â”‚
â”‚  â€¢ is_low_confidence(threshold=0.5) â†’ bool                   â”‚
â”‚  â€¢ is_medium_confidence(low, high) â†’ bool                    â”‚ 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ contains multiple
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ClassificationResult (ValueObject)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                  â”‚
â”‚  â€¢ predictions: List[ClassificationPrediction]               â”‚
â”‚  â€¢ model_version: str                                        â”‚
â”‚  â€¢ inference_time_ms: float                                  â”‚
â”‚  â€¢ resource_id: Optional[str]                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                     â”‚
â”‚  â€¢ validate()                                                â”‚
â”‚  â€¢ get_high_confidence(threshold) â†’ List[Prediction]         â”‚
â”‚  â€¢ get_top_k(k) â†’ List[Prediction]                           â”‚
â”‚  â€¢ get_best_prediction() â†’ Prediction                        â”‚
â”‚  â€¢ count_by_confidence_level() â†’ Dict[str, int]              â”‚
â”‚  â€¢ to_dict() â†’ Dict[str, Any]                                â”‚
â”‚  â€¢ from_dict(data) â†’ ClassificationResult                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Quality Domain

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              QualityScore (ValueObject)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes (5 Dimensions):                                   â”‚
â”‚  â€¢ accuracy: float (0.0-1.0)        Weight: 0.30             â”‚
â”‚  â€¢ completeness: float (0.0-1.0)    Weight: 0.25             â”‚
â”‚  â€¢ consistency: float (0.0-1.0)     Weight: 0.20             â”‚
â”‚  â€¢ timeliness: float (0.0-1.0)      Weight: 0.15             â”‚
â”‚  â€¢ relevance: float (0.0-1.0)       Weight: 0.15             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                     â”‚
â”‚  â€¢ validate()                                                â”‚
â”‚  â€¢ overall_score() â†’ float                                   â”‚
â”‚  â€¢ is_high_quality(threshold=0.7) â†’ bool                     â”‚
â”‚  â€¢ is_low_quality(threshold=0.5) â†’ bool                      â”‚
â”‚  â€¢ get_quality_level() â†’ str ("high"/"medium"/"low")         â”‚
â”‚  â€¢ get_weakest_dimension() â†’ str                             â”‚
â”‚  â€¢ get_strongest_dimension() â†’ str                           â”‚
â”‚  â€¢ get_dimension_scores() â†’ Dict[str, float]                 â”‚
â”‚  â€¢ has_dimension_below_threshold(t) â†’ bool                   â”‚
â”‚  â€¢ count_dimensions_below_threshold(t) â†’ int                 â”‚
â”‚  â€¢ to_dict() â†’ Dict[str, Any]                                â”‚
â”‚  â€¢ from_dict(data) â†’ QualityScore                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Recommendation Domain

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RecommendationScore (ValueObject)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                  â”‚
â”‚  â€¢ score: float (0.0-1.0)                                    â”‚
â”‚  â€¢ confidence: float (0.0-1.0)                               â”‚
â”‚  â€¢ rank: int (1-based)                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                     â”‚
â”‚  â€¢ validate()                                                â”‚
â”‚  â€¢ is_high_confidence(threshold=0.8) â†’ bool                  â”‚
â”‚  â€¢ is_high_score(threshold=0.7) â†’ bool                       â”‚
â”‚  â€¢ is_top_ranked(top_k=5) â†’ bool                             â”‚
â”‚  â€¢ combined_quality() â†’ float                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ embedded in
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Recommendation (ValueObject)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                  â”‚
â”‚  â€¢ resource_id: str                                          â”‚
â”‚  â€¢ user_id: str                                              â”‚
â”‚  â€¢ recommendation_score: RecommendationScore                 â”‚
â”‚  â€¢ strategy: str = "unknown"                                 â”‚
â”‚  â€¢ reason: Optional[str]                                     â”‚
â”‚  â€¢ metadata: Optional[Dict[str, Any]]                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                     â”‚
â”‚  â€¢ validate()                                                â”‚
â”‚  â€¢ get_score() â†’ float                                       â”‚
â”‚  â€¢ get_confidence() â†’ float                                  â”‚
â”‚  â€¢ get_rank() â†’ int                                          â”‚
â”‚  â€¢ is_high_quality(score_t, conf_t) â†’ bool                   â”‚
â”‚  â€¢ is_top_recommendation(top_k=5) â†’ bool                     â”‚
â”‚  â€¢ get_metadata_value(key, default) â†’ Any                    â”‚
â”‚  â€¢ __lt__, __le__, __gt__, __ge__ (for sorting)              â”‚
â”‚  â€¢ to_dict() â†’ Dict[str, Any]                                â”‚
â”‚  â€¢ from_dict(data) â†’ Recommendation                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Search Domain

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SearchQuery (ValueObject)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                  â”‚
â”‚  â€¢ query_text: str                                           â”‚
â”‚  â€¢ limit: int = 20                                           â”‚
â”‚  â€¢ enable_reranking: bool = True                             â”‚
â”‚  â€¢ adaptive_weights: bool = True                             â”‚
â”‚  â€¢ search_method: str = "hybrid"                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                     â”‚
â”‚  â€¢ validate()                                                â”‚
â”‚  â€¢ is_short_query(threshold=3) â†’ bool                        â”‚
â”‚  â€¢ is_long_query(threshold=10) â†’ bool                        â”‚
â”‚  â€¢ is_medium_query(short, long) â†’ bool                       â”‚
â”‚  â€¢ get_word_count() â†’ int                                    â”‚
â”‚  â€¢ is_single_word() â†’ bool                                   â”‚
â”‚  â€¢ get_query_length() â†’ int                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ produces
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SearchResults (ValueObject)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                  â”‚
â”‚  â€¢ results: List[SearchResult]                               â”‚
â”‚  â€¢ query: SearchQuery                                        â”‚
â”‚  â€¢ total_results: int                                        â”‚
â”‚  â€¢ search_time_ms: float                                     â”‚
â”‚  â€¢ reranked: bool = False                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Methods:                                                     â”‚
â”‚  â€¢ validate()                                                â”‚
â”‚  â€¢ get_top_k(k) â†’ List[SearchResult]                         â”‚
â”‚  â€¢ get_by_score_threshold(t) â†’ List[SearchResult]            â”‚
â”‚  â€¢ is_empty() â†’ bool                                         â”‚
â”‚  â€¢ has_results() â†’ bool                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Refactoring Framework Architecture (Phase 12)

The refactoring framework implements Fowler's refactoring patterns with automated code smell detection and validation.

### Refactoring Models

```
SmellType (Enum)
â”œâ”€â”€ Values:
â”‚   â”œâ”€â”€ DUPLICATED_CODE
â”‚   â”œâ”€â”€ LONG_FUNCTION
â”‚   â”œâ”€â”€ LARGE_CLASS
â”‚   â”œâ”€â”€ GLOBAL_DATA
â”‚   â”œâ”€â”€ FEATURE_ENVY
â”‚   â”œâ”€â”€ DATA_CLUMPS
â”‚   â”œâ”€â”€ PRIMITIVE_OBSESSION
â”‚   â”œâ”€â”€ REPEATED_SWITCHES
â”‚   â”œâ”€â”€ DATA_CLASS
â”‚   â””â”€â”€ LONG_PARAMETER_LIST

Severity (Enum)
â”œâ”€â”€ Values:
â”‚   â”œâ”€â”€ HIGH (blocks production)
â”‚   â”œâ”€â”€ MEDIUM (technical debt)
â”‚   â””â”€â”€ LOW (minor improvement)

RefactoringTechnique (Enum)
â”œâ”€â”€ Values:
â”‚   â”œâ”€â”€ EXTRACT_FUNCTION
â”‚   â”œâ”€â”€ EXTRACT_CLASS
â”‚   â”œâ”€â”€ REPLACE_PRIMITIVE_WITH_OBJECT
â”‚   â”œâ”€â”€ COMBINE_FUNCTIONS_INTO_CLASS
â”‚   â”œâ”€â”€ SEPARATE_QUERY_FROM_MODIFIER
â”‚   â”œâ”€â”€ ENCAPSULATE_COLLECTION
â”‚   â”œâ”€â”€ SPLIT_PHASE
â”‚   â”œâ”€â”€ REPLACE_CONDITIONAL_WITH_POLYMORPHISM
â”‚   â”œâ”€â”€ MOVE_FUNCTION
â”‚   â””â”€â”€ INLINE_FUNCTION
```

### Refactoring Data Classes

```
Location (dataclass)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ file_path: Path
â”‚   â”œâ”€â”€ start_line: int
â”‚   â”œâ”€â”€ end_line: int
â”‚   â”œâ”€â”€ function_name: Optional[str]
â”‚   â””â”€â”€ class_name: Optional[str]

CodeSmell (dataclass)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ smell_type: SmellType
â”‚   â”œâ”€â”€ severity: Severity
â”‚   â”œâ”€â”€ location: Location
â”‚   â”œâ”€â”€ description: str
â”‚   â”œâ”€â”€ suggested_technique: RefactoringTechnique
â”‚   â””â”€â”€ metrics: Dict[str, Any]

SmellReport (dataclass)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ file_path: Path
â”‚   â”œâ”€â”€ smells: List[CodeSmell]
â”‚   â”œâ”€â”€ total_lines: int
â”‚   â”œâ”€â”€ complexity_score: float
â”‚   â””â”€â”€ timestamp: str
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ high_priority_smells() â†’ List[CodeSmell]
â”‚   â”œâ”€â”€ smells_by_type(smell_type) â†’ List[CodeSmell]
â”‚   â””â”€â”€ summary() â†’ str

RefactoringResult (dataclass)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ success: bool
â”‚   â”œâ”€â”€ original_code: str
â”‚   â”œâ”€â”€ refactored_code: str
â”‚   â”œâ”€â”€ technique_applied: RefactoringTechnique
â”‚   â”œâ”€â”€ changes_made: List[str]
â”‚   â””â”€â”€ test_results: Optional[TestResults]

TestResults (dataclass)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ total_tests: int
â”‚   â”œâ”€â”€ passed: int
â”‚   â”œâ”€â”€ failed: int
â”‚   â”œâ”€â”€ errors: List[str]
â”‚   â”œâ”€â”€ coverage_percentage: float
â”‚   â””â”€â”€ execution_time_seconds: float
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ all_passed() â†’ bool
â”‚   â”œâ”€â”€ coverage_acceptable(threshold=0.85) â†’ bool
â”‚   â””â”€â”€ summary() â†’ str
```

### Refactoring Detector

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CodeSmellDetector                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attributes:                                                    â”‚
â”‚  â€¢ function_checker: FunctionLengthChecker                     â”‚
â”‚  â€¢ class_checker: ClassSizeChecker                             â”‚
â”‚  â€¢ type_hint_checker: TypeHintCoverageChecker                  â”‚
â”‚  â€¢ duplication_detector: CodeDuplicationDetector               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Public Methods:                                                â”‚
â”‚  â€¢ analyze_file(file_path: Path) â†’ SmellReport                 â”‚
â”‚  â€¢ analyze_directory(dir_path: Path) â†’ List[SmellReport]       â”‚
â”‚  â€¢ prioritize_smells(reports) â†’ PrioritizedSmells              â”‚
â”‚  â€¢ generate_summary_report(reports) â†’ str                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Private Methods:                                               â”‚
â”‚  â€¢ _detect_feature_envy(file_path) â†’ List[CodeSmell]           â”‚
â”‚  â€¢ _detect_long_parameter_lists(file_path) â†’ List[CodeSmell]   â”‚
â”‚  â€¢ _count_lines(file_path) â†’ int                               â”‚
â”‚  â€¢ _calculate_complexity(file_path) â†’ float                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Refactoring Validators

```
FunctionLengthChecker
â”œâ”€â”€ Constants: MAX_FUNCTION_LINES = 50
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ check_file(file_path: Path) â†’ List[CodeSmell]
â”‚   â”œâ”€â”€ _extract_functions(tree, source) â†’ List[FunctionInfo]
â”‚   â””â”€â”€ _create_smell(file_path, func) â†’ CodeSmell

ClassSizeChecker
â”œâ”€â”€ Constants: MAX_CLASS_LINES = 200, MAX_METHODS = 10
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ check_file(file_path: Path) â†’ List[CodeSmell]
â”‚   â”œâ”€â”€ _extract_classes(tree, source) â†’ List[ClassInfo]
â”‚   â””â”€â”€ _create_smell(file_path, cls) â†’ CodeSmell

TypeHintCoverageChecker
â”œâ”€â”€ Constants: MIN_TYPE_HINT_COVERAGE = 1.0
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ check_file(file_path: Path) â†’ Tuple[float, List[CodeSmell]]
â”‚   â””â”€â”€ _has_complete_type_hints(node) â†’ bool

CodeDuplicationDetector
â”œâ”€â”€ Constants: DUPLICATION_SIMILARITY_THRESHOLD = 0.8
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ check_files(file_paths: List[Path]) â†’ List[CodeSmell]
â”‚   â”œâ”€â”€ _extract_function_bodies(tree, source) â†’ List[Tuple]
â”‚   â””â”€â”€ _calculate_similarity(body1, body2) â†’ float
```

---

## Router Layer Architecture

The router layer provides FastAPI endpoints for all services, implementing REST API patterns.

### Main Routers

```
Classification Router (/api/classification)
â”œâ”€â”€ Endpoints:
â”‚   â”œâ”€â”€ POST /classify
â”‚   â”‚   â”œâ”€â”€ Input: ClassifyRequest (text, top_k)
â”‚   â”‚   â””â”€â”€ Output: ClassificationResult
â”‚   â”œâ”€â”€ POST /fine-tune
â”‚   â”‚   â”œâ”€â”€ Input: FineTuneRequest (labeled_data, epochs, batch_size)
â”‚   â”‚   â””â”€â”€ Output: TrainingMetrics
â”‚   â””â”€â”€ GET /metrics
â”‚       â””â”€â”€ Output: ModelMetrics

Quality Router (/api/quality)
â”œâ”€â”€ Endpoints:
â”‚   â”œâ”€â”€ POST /compute/{resource_id}
â”‚   â”‚   â”œâ”€â”€ Input: Optional[QualityWeights]
â”‚   â”‚   â””â”€â”€ Output: QualityScore
â”‚   â”œâ”€â”€ GET /monitor/degradation
â”‚   â”‚   â”œâ”€â”€ Query: time_window_days
â”‚   â”‚   â””â”€â”€ Output: List[DegradationReport]
â”‚   â””â”€â”€ POST /detect/outliers
â”‚       â”œâ”€â”€ Query: batch_size
â”‚       â””â”€â”€ Output: OutlierDetectionResult

Recommendation Router (/api/recommendations)
â”œâ”€â”€ Endpoints:
â”‚   â”œâ”€â”€ GET /user/{user_id}
â”‚   â”‚   â”œâ”€â”€ Query: limit, strategy
â”‚   â”‚   â””â”€â”€ Output: List[Recommendation]
â”‚   â”œâ”€â”€ GET /resource/{resource_id}
â”‚   â”‚   â”œâ”€â”€ Query: limit
â”‚   â”‚   â””â”€â”€ Output: List[Recommendation]
â”‚   â””â”€â”€ GET /graph/{resource_id}
â”‚       â”œâ”€â”€ Query: limit, graph_weight
â”‚       â””â”€â”€ Output: List[Recommendation]

Search Router (/api/search)
â”œâ”€â”€ Endpoints:
â”‚   â”œâ”€â”€ POST /hybrid
â”‚   â”‚   â”œâ”€â”€ Input: HybridSearchRequest
â”‚   â”‚   â””â”€â”€ Output: SearchResults with facets
â”‚   â”œâ”€â”€ GET /fts
â”‚   â”‚   â”œâ”€â”€ Query: q, filters, limit, offset
â”‚   â”‚   â””â”€â”€ Output: SearchResults
â”‚   â””â”€â”€ GET /vector
â”‚       â”œâ”€â”€ Query: q, limit, offset
â”‚       â””â”€â”€ Output: SearchResults
```

---

## Creating a New Module

1. Create module directory:
```bash
mkdir -p app/modules/new_module
```

2. Create module files:
```python
# __init__.py
from .router import router
from .service import create_item, get_item
from .schema import ItemCreate, ItemResponse
from .model import Item

__version__ = "1.0.0"
__domain__ = "new_module"
```

3. Register router in main.py:
```python
from app.modules.new_module import router as new_module_router
app.include_router(new_module_router, prefix="/new-module", tags=["new-module"])
```

4. Register event handlers:
```python
# In handlers.py
from app.shared.event_bus import event_bus

def register_handlers():
    event_bus.subscribe("some.event", handle_some_event)

# Call in __init__.py or main.py
register_handlers()
```

---

## Module Isolation Rules

1. **No cross-module imports** - Use events or shared kernel
2. **String-based relationships** - Avoid circular imports in models
3. **Independent testing** - Each module has its own tests
4. **Clear public interface** - Export only what's needed in `__init__.py`
5. **Self-contained migrations** - Module-specific schema changes

---

## Legacy Services Migration Status

Services being migrated to modules:

| Service | Target Module | Status |
|---------|---------------|--------|
| `resource_service.py` | Resources | âœ… Complete |
| `collection_service.py` | Collections | âœ… Complete |
| `search_service.py` | Search | âœ… Complete |
| `taxonomy_service.py` | Taxonomy | ğŸ”„ Planned |
| `annotation_service.py` | Annotations | ğŸ”„ Planned |
| `quality_service.py` | Quality | ğŸ”„ Planned |
| `graph_service.py` | Graph | ğŸ”„ Planned |
| `recommendation_service.py` | Recommendations | ğŸ”„ Planned |

---

## Schema Layer Architecture

The schema layer defines Pydantic models for API request/response validation.

```
SearchQuery (Pydantic)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ text: str
â”‚   â”œâ”€â”€ limit: int = 20
â”‚   â”œâ”€â”€ offset: int = 0
â”‚   â”œâ”€â”€ hybrid_weight: float = 0.5
â”‚   â”œâ”€â”€ filters: Optional[SearchFilters]
â”‚   â””â”€â”€ sort_by: Optional[str]

SearchFilters (Pydantic)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ classification_code: Optional[List[str]]
â”‚   â”œâ”€â”€ type: Optional[List[str]]
â”‚   â”œâ”€â”€ language: Optional[List[str]]
â”‚   â”œâ”€â”€ year_min: Optional[int]
â”‚   â””â”€â”€ year_max: Optional[int]

ResourceCreate (Pydantic)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ title: str
â”‚   â”œâ”€â”€ description: Optional[str]
â”‚   â”œâ”€â”€ creator: Optional[str]
â”‚   â”œâ”€â”€ subject: Optional[List[str]]
â”‚   â”œâ”€â”€ type: str
â”‚   â”œâ”€â”€ language: str
â”‚   â””â”€â”€ identifier: str

ResourceUpdate (Pydantic)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ title: Optional[str]
â”‚   â”œâ”€â”€ description: Optional[str]
â”‚   â”œâ”€â”€ creator: Optional[str]
â”‚   â”œâ”€â”€ subject: Optional[List[str]]
â”‚   â””â”€â”€ classification_code: Optional[str]

ClassifyRequest (Pydantic)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ text: str
â”‚   â””â”€â”€ top_k: int = 5

AnnotationCreate (Pydantic)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ resource_id: UUID
â”‚   â”œâ”€â”€ content: str
â”‚   â”œâ”€â”€ annotation_type: str
â”‚   â”œâ”€â”€ start_position: Optional[int]
â”‚   â”œâ”€â”€ end_position: Optional[int]
â”‚   â””â”€â”€ tags: Optional[List[str]]

RecommendationRequest (Pydantic)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ user_id: str
â”‚   â”œâ”€â”€ limit: int = 10
â”‚   â””â”€â”€ strategy: str = "hybrid"
```

---

## Configuration Layer Architecture

The configuration layer manages application settings and environment variables.

```
Settings (Pydantic BaseSettings)
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ DATABASE_URL: str
â”‚   â”œâ”€â”€ SECRET_KEY: str
â”‚   â”œâ”€â”€ API_VERSION: str = "v2.0"
â”‚   â”œâ”€â”€ DEBUG: bool = False
â”‚   â”œâ”€â”€ LOG_LEVEL: str = "INFO"
â”‚   â”œâ”€â”€ CORS_ORIGINS: List[str]
â”‚   â”œâ”€â”€ MAX_UPLOAD_SIZE: int
â”‚   â”œâ”€â”€ EMBEDDING_MODEL: str = "sentence-transformers/all-MiniLM-L6-v2"
â”‚   â”œâ”€â”€ CLASSIFICATION_MODEL: str = "distilbert-base-uncased"
â”‚   â”œâ”€â”€ ENABLE_GPU: bool = True
â”‚   â”œâ”€â”€ CACHE_TTL: int = 3600
â”‚   â””â”€â”€ RATE_LIMIT: int = 100
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ get_database_url() â†’ str
â”‚   â”œâ”€â”€ is_production() â†’ bool
â”‚   â””â”€â”€ validate_settings() â†’ None

get_settings()
â”œâ”€â”€ Returns: Settings (singleton)
â””â”€â”€ Usage: settings = get_settings()
```

---

## Utility Layer Architecture

The utility layer provides helper functions and shared utilities across the application.

### Text Processing Utilities

```
text_processor module
â”œâ”€â”€ Functions:
â”‚   â”œâ”€â”€ readability_scores(text: str) -> Dict[str, float]
â”‚   â”‚   â”œâ”€â”€ Returns: flesch_reading_ease, flesch_kincaid_grade, etc.
â”‚   â”‚   â””â”€â”€ Uses: textstat library
â”‚   â”œâ”€â”€ extract_keywords(text: str, top_k: int) -> List[str]
â”‚   â”‚   â”œâ”€â”€ Returns: List of top keywords
â”‚   â”‚   â””â”€â”€ Uses: TF-IDF or RAKE
â”‚   â”œâ”€â”€ clean_text(text: str) -> str
â”‚   â”‚   â”œâ”€â”€ Removes: HTML tags, special characters
â”‚   â”‚   â””â”€â”€ Returns: Cleaned text
â”‚   â”œâ”€â”€ tokenize(text: str) -> List[str]
â”‚   â”‚   â””â”€â”€ Returns: List of tokens
â”‚   â””â”€â”€ normalize_text(text: str) -> str
â”‚       â”œâ”€â”€ Lowercases, removes punctuation
â”‚       â””â”€â”€ Returns: Normalized text

content_extractor module
â”œâ”€â”€ Functions:
â”‚   â”œâ”€â”€ extract_from_pdf(file_path: Path) -> str
â”‚   â”‚   â””â”€â”€ Uses: PyPDF2 or pdfplumber
â”‚   â”œâ”€â”€ extract_from_html(html: str) -> str
â”‚   â”‚   â””â”€â”€ Uses: BeautifulSoup
â”‚   â”œâ”€â”€ extract_metadata(file_path: Path) -> Dict[str, Any]
â”‚   â”‚   â””â”€â”€ Returns: Title, author, date, etc.
â”‚   â””â”€â”€ extract_citations(text: str) -> List[str]
â”‚       â””â”€â”€ Returns: List of citation strings
```

### Performance Monitoring Utilities

```
performance_monitoring module
â”œâ”€â”€ Classes:
â”‚   â””â”€â”€ PerformanceMonitor
â”‚       â”œâ”€â”€ Attributes:
â”‚       â”‚   â”œâ”€â”€ metrics: Dict[str, List[float]]
â”‚       â”‚   â””â”€â”€ start_times: Dict[str, float]
â”‚       â”œâ”€â”€ Methods:
â”‚       â”‚   â”œâ”€â”€ start_timer(name: str) -> None
â”‚       â”‚   â”œâ”€â”€ stop_timer(name: str) -> float
â”‚       â”‚   â”œâ”€â”€ record_metric(name: str, value: float) -> None
â”‚       â”‚   â”œâ”€â”€ get_average(name: str) -> float
â”‚       â”‚   â”œâ”€â”€ get_percentile(name: str, percentile: float) -> float
â”‚       â”‚   â””â”€â”€ get_summary() -> Dict[str, Any]
â”‚
â”œâ”€â”€ Decorators:
â”‚   â”œâ”€â”€ @time_function
â”‚   â”‚   â””â”€â”€ Measures function execution time
â”‚   â””â”€â”€ @log_performance
â”‚       â””â”€â”€ Logs performance metrics

recommendation_metrics module
â”œâ”€â”€ Functions:
â”‚   â”œâ”€â”€ precision_at_k(predictions, ground_truth, k) -> float
â”‚   â”œâ”€â”€ recall_at_k(predictions, ground_truth, k) -> float
â”‚   â”œâ”€â”€ ndcg_at_k(predictions, ground_truth, k) -> float
â”‚   â”œâ”€â”€ mean_average_precision(predictions, ground_truth) -> float
â”‚   â””â”€â”€ hit_rate_at_k(predictions, ground_truth, k) -> float
```

---

## ML Monitoring Architecture

The ML monitoring layer provides observability for machine learning models and predictions.

```
PredictionMonitor
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ predictions: List[Dict[str, Any]]
â”‚   â”œâ”€â”€ metrics: Dict[str, float]
â”‚   â””â”€â”€ alert_thresholds: Dict[str, float]
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ log_prediction(model_name, input_data, prediction, confidence, latency_ms) -> None
â”‚   â”œâ”€â”€ get_metrics(window_minutes: int) -> Dict[str, Any]
â”‚   â”œâ”€â”€ get_prediction_distribution() -> Dict[str, int]
â”‚   â”œâ”€â”€ get_average_confidence() -> float
â”‚   â”œâ”€â”€ get_average_latency() -> float
â”‚   â”œâ”€â”€ check_drift(baseline_distribution) -> bool
â”‚   â””â”€â”€ export_metrics() -> Dict[str, Any]

AlertManager
â”œâ”€â”€ Attributes:
â”‚   â”œâ”€â”€ alerts: List[Alert]
â”‚   â””â”€â”€ notification_channels: List[NotificationChannel]
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ create_alert(alert_type, severity, message, metadata) -> Alert
â”‚   â”œâ”€â”€ check_thresholds(metrics: Dict[str, float]) -> List[Alert]
â”‚   â”œâ”€â”€ send_notification(alert: Alert) -> None
â”‚   â””â”€â”€ get_active_alerts() -> List[Alert]

HealthCheck
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ check_model_health(model_name: str) -> Dict[str, Any]
â”‚   â”œâ”€â”€ check_database_health() -> Dict[str, Any]
â”‚   â”œâ”€â”€ check_service_health(service_name: str) -> Dict[str, Any]
â”‚   â””â”€â”€ get_system_health() -> Dict[str, Any]

JSONLogging
â”œâ”€â”€ Functions:
â”‚   â”œâ”€â”€ setup_json_logging(log_level: str) -> None
â”‚   â”œâ”€â”€ log_structured(level, message, **kwargs) -> None
â”‚   â””â”€â”€ get_logger(name: str) -> logging.Logger
```

---

## Complete System Flow Diagrams

### Classification Flow

```
User Request
    â†“
FastAPI Router (POST /api/classification/classify)
    â†“
MLClassificationService.predict(text, top_k)
    â†“
    â”œâ”€â†’ _load_model() [if not loaded]
    â”‚   â”œâ”€â†’ _import_ml_libraries()
    â”‚   â”œâ”€â†’ _load_tokenizer()
    â”‚   â”œâ”€â†’ _determine_checkpoint_path()
    â”‚   â”œâ”€â†’ _load_model_from_checkpoint()
    â”‚   â””â”€â†’ _move_model_to_device()
    â”‚
    â”œâ”€â†’ Tokenize input text
    â”œâ”€â†’ Model inference (forward pass)
    â”œâ”€â†’ Apply sigmoid activation
    â”œâ”€â†’ Sort by confidence
    â”œâ”€â†’ Take top_k predictions
    â”‚
    â””â”€â†’ Create ClassificationResult domain object
        â”œâ”€â†’ ClassificationPrediction objects
        â””â”€â†’ Validate all predictions
    â†“
PredictionMonitor.log_prediction()
    â†“
Return ClassificationResult
    â†“
Convert to JSON response
    â†“
User receives predictions
```

### Quality Assessment Flow

```
User Request
    â†“
FastAPI Router (POST /api/quality/compute/{resource_id})
    â†“
QualityService.compute_quality(resource_id, weights)
    â†“
    â”œâ”€â†’ Validate weights
    â”œâ”€â†’ Query Resource from database
    â”‚
    â”œâ”€â†’ _compute_accuracy_dimension(resource)
    â”œâ”€â†’ _compute_completeness_dimension(resource)
    â”œâ”€â†’ _compute_consistency_dimension(resource)
    â”œâ”€â†’ _compute_timeliness_dimension(resource)
    â””â”€â†’ _compute_relevance_dimension(resource)
    â†“
Create QualityScore domain object
    â”œâ”€â†’ Validate all dimensions (0.0-1.0)
    â””â”€â†’ Calculate overall_score()
    â†“
_update_resource_quality_fields(resource, ...)
    â†“
Database commit
    â†“
Return QualityScore
    â†“
Convert to JSON response
    â†“
User receives quality assessment
```

### Recommendation Flow (Strategy Pattern)

```
User Request
    â†“
FastAPI Router (GET /api/recommendations/user/{user_id})
    â†“
generate_recommendations(db, resource_id, limit, strategy, user_id)
    â†“
RecommendationStrategyFactory.create(strategy_type, db)
    â†“
    â”œâ”€â†’ strategy="collaborative" â†’ CollaborativeFilteringStrategy
    â”œâ”€â†’ strategy="content" â†’ ContentBasedStrategy
    â”œâ”€â†’ strategy="graph" â†’ GraphBasedStrategy
    â””â”€â†’ strategy="hybrid" â†’ HybridStrategy
    â†“
Strategy.generate(user_id, limit)
    â†“
    [CollaborativeFilteringStrategy]
    â”œâ”€â†’ _build_user_item_matrix()
    â”œâ”€â†’ Compute user similarities
    â”œâ”€â†’ Generate predictions
    â””â”€â†’ Create Recommendation objects
    
    [ContentBasedStrategy]
    â”œâ”€â†’ Query UserInteraction
    â”œâ”€â†’ _build_user_profile(interactions)
    â”œâ”€â†’ Query Resources with embeddings
    â”œâ”€â†’ _compute_similarity(profile, embedding)
    â””â”€â†’ Create Recommendation objects
    
    [GraphBasedStrategy]
    â”œâ”€â†’ _traverse_citation_network(resource_id, depth)
    â”œâ”€â†’ Score by citation distance
    â””â”€â†’ Create Recommendation objects
    
    [HybridStrategy]
    â”œâ”€â†’ Execute all sub-strategies
    â”œâ”€â†’ _merge_recommendations(results, weights)
    â””â”€â†’ Create Recommendation objects
    â†“
Return List[Recommendation]
    â†“
Convert to List[Dict] for API compatibility
    â†“
User receives recommendations
```

### Search Flow (Three-Way Hybrid)

```
User Request
    â†“
FastAPI Router (POST /api/search/three-way)
    â†“
HybridSearchQuery(db, query, enable_reranking, adaptive_weights)
    â†“
execute()
    â†“
    â”œâ”€â†’ _ensure_tables_exist()
    â”œâ”€â†’ _check_services_available()
    â”œâ”€â†’ _analyze_query() â†’ query characteristics
    â”‚
    â”œâ”€â†’ PHASE 1: _execute_retrieval_phase()
    â”‚   â”œâ”€â†’ _search_fts5() â†’ FTS5 keyword results
    â”‚   â”œâ”€â†’ _search_dense() â†’ Dense vector results
    â”‚   â””â”€â†’ _search_sparse() â†’ Sparse vector results
    â”‚   â””â”€â†’ Return RetrievalCandidates
    â”‚
    â”œâ”€â†’ PHASE 2: _execute_fusion_phase(candidates)
    â”‚   â”œâ”€â†’ _compute_weights() â†’ adaptive RRF weights
    â”‚   â”œâ”€â†’ ReciprocalRankFusionService.fuse_results()
    â”‚   â”œâ”€â†’ _compute_method_contributions()
    â”‚   â””â”€â†’ Return FusedCandidates
    â”‚
    â”œâ”€â†’ PHASE 3: _execute_reranking_phase(fused)
    â”‚   â”œâ”€â†’ RerankingService.rerank() [if enabled]
    â”‚   â””â”€â†’ Return final ranked results
    â”‚
    â”œâ”€â†’ _fetch_paginated_resources(results)
    â”œâ”€â†’ _compute_facets(results)
    â””â”€â†’ _generate_snippets(resources)
    â†“
Return (resources, total, facets, snippets, metadata)
    â†“
Convert to JSON response
    â†“
User receives search results
```

### Refactoring Detection Flow

```
Developer runs CLI
    â†“
refactoring.cli.detect_smells(directory_path)
    â†“
CodeSmellDetector()
    â”œâ”€â†’ Initialize validators:
    â”‚   â”œâ”€â†’ FunctionLengthChecker()
    â”‚   â”œâ”€â†’ ClassSizeChecker()
    â”‚   â”œâ”€â†’ TypeHintCoverageChecker()
    â”‚   â””â”€â†’ CodeDuplicationDetector()
    â†“
analyze_directory(dir_path)
    â†“
    For each Python file:
    â”œâ”€â†’ analyze_file(file_path)
    â”‚   â”œâ”€â†’ FunctionLengthChecker.check_file()
    â”‚   â”‚   â”œâ”€â†’ Parse AST
    â”‚   â”‚   â”œâ”€â†’ _extract_functions()
    â”‚   â”‚   â”œâ”€â†’ _analyze_function()
    â”‚   â”‚   â””â”€â†’ _create_smell() if violation
    â”‚   â”‚
    â”‚   â”œâ”€â†’ ClassSizeChecker.check_file()
    â”‚   â”‚   â”œâ”€â†’ Parse AST
    â”‚   â”‚   â”œâ”€â†’ _extract_classes()
    â”‚   â”‚   â”œâ”€â†’ _analyze_class()
    â”‚   â”‚   â””â”€â†’ _create_smell() if violation
    â”‚   â”‚
    â”‚   â”œâ”€â†’ TypeHintCoverageChecker.check_file()
    â”‚   â”‚   â”œâ”€â†’ Parse AST
    â”‚   â”‚   â”œâ”€â†’ _has_complete_type_hints()
    â”‚   â”‚   â””â”€â†’ _create_smell() if missing
    â”‚   â”‚
    â”‚   â”œâ”€â†’ _detect_feature_envy()
    â”‚   â”œâ”€â†’ _detect_long_parameter_lists()
    â”‚   â”œâ”€â†’ _count_lines()
    â”‚   â””â”€â†’ _calculate_complexity()
    â”‚   â†“
    â”‚   Return SmellReport
    â”‚
    â””â”€â†’ CodeDuplicationDetector.check_files(all_files)
        â”œâ”€â†’ _extract_function_bodies()
        â”œâ”€â†’ Compare all pairs
        â”œâ”€â†’ _calculate_similarity()
        â””â”€â†’ _create_smell() if duplicate
    â†“
prioritize_smells(reports)
    â”œâ”€â†’ Sort by severity (HIGH, MEDIUM, LOW)
    â””â”€â†’ Return PrioritizedSmells
    â†“
generate_summary_report(reports)
    â†“
Display results to developer
```

---

## Related Documentation

- [Architecture Overview](overview.md) - System design
- [Event System](event-system.md) - Event-driven communication
- [Database](database.md) - Schema and models
- [Design Decisions](decisions.md) - ADRs


<div style='page-break-after: always;'></div>

---



# 24. Architecture Decisions

*Source: `backend/docs/architecture/decisions.md`*

---

# Architecture Decision Records

Key architectural decisions for Neo Alexandria 2.0.

## ADR-001: Vertical Slice Architecture

**Status:** Accepted (Phase 13.5)

**Context:**
The original layered architecture (routers â†’ services â†’ models) led to:
- Tight coupling between components
- Circular import issues
- Difficult testing
- Hard to understand feature boundaries

**Decision:**
Adopt vertical slice architecture where each feature is a self-contained module with all layers.

**Consequences:**
- âœ… High cohesion within modules
- âœ… Low coupling between modules
- âœ… Easier to understand and test
- âœ… Modules can be extracted to microservices
- âš ï¸ Some code duplication between modules
- âš ï¸ Requires discipline to maintain boundaries

---

## ADR-002: Event-Driven Communication

**Status:** Accepted (Phase 12.5)

**Context:**
Direct service-to-service calls created:
- Circular dependencies
- Tight coupling
- Difficult to add new features

**Decision:**
Use publish-subscribe event bus for inter-module communication.

**Consequences:**
- âœ… Loose coupling between modules
- âœ… Easy to add new subscribers
- âœ… Supports async processing
- âš ï¸ Eventual consistency (not immediate)
- âš ï¸ Harder to trace execution flow
- âš ï¸ Need to handle event failures

---

## ADR-003: Dual Database Support

**Status:** Accepted (Phase 13)

**Context:**
SQLite is convenient for development but has limitations:
- Single writer (no concurrent writes)
- No advanced indexing
- Not suitable for production

**Decision:**
Support both SQLite (development) and PostgreSQL (production) with automatic detection.

**Consequences:**
- âœ… Easy local development
- âœ… Production-grade database option
- âœ… Automatic configuration
- âš ï¸ Must maintain compatibility
- âš ï¸ Some features PostgreSQL-only
- âš ï¸ Migration scripts needed

---

## ADR-004: Domain Objects for Business Logic

**Status:** Accepted (Phase 11)

**Context:**
Business logic was scattered across services with primitive types, making it hard to:
- Validate business rules
- Reuse logic
- Test in isolation

**Decision:**
Create domain objects (value objects, entities) to encapsulate business logic.

**Consequences:**
- âœ… Centralized validation
- âœ… Reusable business logic
- âœ… Self-documenting code
- âœ… Easier testing
- âš ï¸ More classes to maintain
- âš ï¸ Mapping between layers

---

## ADR-005: Hybrid Search Strategy

**Status:** Accepted (Phase 4, enhanced Phase 8)

**Context:**
Pure keyword search misses semantic meaning. Pure vector search misses exact matches.

**Decision:**
Implement hybrid search combining:
- FTS5 keyword search (BM25)
- Dense vector search (semantic)
- Sparse vector search (SPLADE) - Phase 8
- Reciprocal Rank Fusion for combining results

**Consequences:**
- âœ… Best of both approaches
- âœ… Configurable weighting
- âœ… Better search quality
- âš ï¸ Higher latency
- âš ï¸ More complex implementation
- âš ï¸ Requires embedding generation

---

## ADR-006: Aggregate Embeddings for Collections

**Status:** Accepted (Phase 7)

**Context:**
Collections needed semantic representation for:
- Finding similar collections
- Recommending resources to add
- Collection-based search

**Decision:**
Compute aggregate embedding as normalized mean of member resource embeddings.

**Consequences:**
- âœ… Enables collection similarity
- âœ… Supports recommendations
- âœ… Simple algorithm
- âš ï¸ Must recompute on membership changes
- âš ï¸ Large collections may dilute signal

---

## ADR-007: Multi-Dimensional Quality Assessment

**Status:** Accepted (Phase 9)

**Context:**
Single quality score didn't capture different aspects of resource quality.

**Decision:**
Implement 5-dimensional quality assessment:
- Accuracy (30%)
- Completeness (25%)
- Consistency (20%)
- Timeliness (15%)
- Relevance (10%)

**Consequences:**
- âœ… Granular quality insights
- âœ… Actionable improvement suggestions
- âœ… Configurable weights
- âš ï¸ More complex computation
- âš ï¸ Requires more storage

---

## ADR-008: Strategy Pattern for Recommendations

**Status:** Accepted (Phase 10-11)

**Context:**
Different recommendation approaches work better for different scenarios.

**Decision:**
Use strategy pattern with multiple recommendation strategies:
- Collaborative filtering
- Content-based
- Graph-based
- Hybrid (combines all)

**Consequences:**
- âœ… Flexible recommendation system
- âœ… Easy to add new strategies
- âœ… Can tune per user/context
- âš ï¸ More complex architecture
- âš ï¸ Need to balance strategies

---

## ADR-009: Materialized Paths for Taxonomy

**Status:** Accepted (Phase 8.5)

**Context:**
Hierarchical taxonomy queries (ancestors, descendants) were slow with recursive queries.

**Decision:**
Use materialized path pattern storing full path in each node (e.g., `/science/computer-science/ml`).

**Consequences:**
- âœ… O(1) ancestor queries
- âœ… O(1) descendant queries via LIKE
- âœ… Simple breadcrumb generation
- âš ï¸ Must update paths on move
- âš ï¸ Path length limits

---

## ADR-010: Async Ingestion Pipeline

**Status:** Accepted (Phase 3.5)

**Context:**
Content ingestion involves slow operations:
- HTTP fetching
- PDF extraction
- AI summarization
- Embedding generation

**Decision:**
Make ingestion asynchronous with status tracking.

**Consequences:**
- âœ… Fast API response
- âœ… Can process in background
- âœ… Supports batch ingestion
- âš ï¸ Need status polling
- âš ï¸ Error handling complexity

---

## Decision Template

```markdown
## ADR-XXX: [Title]

**Status:** [Proposed | Accepted | Deprecated | Superseded]

**Context:**
[What is the issue that we're seeing that is motivating this decision?]

**Decision:**
[What is the change that we're proposing and/or doing?]

**Consequences:**
[What becomes easier or more difficult to do because of this change?]
- âœ… Positive consequence
- âš ï¸ Trade-off or risk
```

## Related Documentation

- [Architecture Overview](overview.md) - System design
- [Modules](modules.md) - Vertical slice details
- [Event System](event-system.md) - Event-driven communication


<div style='page-break-after: always;'></div>

---



# 25. Setup Guide

*Source: `backend/docs/guides/setup.md`*

---

# Development Setup Guide

Installation and environment configuration for Neo Alexandria 2.0.

> **Phase 14 Complete**: Neo Alexandria now uses a fully modular vertical slice architecture with 13 self-contained modules, enhanced shared kernel, and event-driven communication.

## Prerequisites

- Python 3.8 or higher
- Git
- SQLite (included with Python) or PostgreSQL 15+ (recommended for production)
- 4GB RAM minimum (8GB recommended for AI features)
- 2GB free disk space

## Installation Steps

### 1. Clone the Repository

```bash
git clone <repository-url>
cd backend
```

### 2. Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment

Create a `.env` file in the backend directory:

```bash
cp .env.example .env
```

Edit `.env` with your configuration:

```bash
# Database Configuration
DATABASE_URL=sqlite:///backend.db
TEST_DATABASE_URL=sqlite:///:memory:

# AI Model Configuration
EMBEDDING_MODEL_NAME=nomic-ai/nomic-embed-text-v1
SUMMARIZER_MODEL=facebook/bart-large-cnn
TAGGER_MODEL=facebook/bart-large-mnli

# Search Configuration
DEFAULT_HYBRID_SEARCH_WEIGHT=0.5
EMBEDDING_CACHE_SIZE=1000

# Graph Configuration
GRAPH_WEIGHT_VECTOR=0.6
GRAPH_WEIGHT_TAGS=0.3
GRAPH_WEIGHT_CLASSIFICATION=0.1

# Development Settings
DEBUG=true
LOG_LEVEL=INFO
```

### 5. Run Database Migrations

```bash
alembic upgrade head
```

### 6. Start Development Server

```bash
uvicorn app.main:app --reload
```

The API will be available at `http://127.0.0.1:8000`

## Verify Installation

### Check API Documentation

Open in browser:
- Swagger UI: http://127.0.0.1:8000/docs
- ReDoc: http://127.0.0.1:8000/redoc

### Test Health Endpoint

```bash
curl http://127.0.0.1:8000/health
```

Expected response:
```json
{"status": "healthy", "timestamp": "2024-01-01T10:00:00Z"}
```

### Verify Module Registration

Check that all 13 modules are loaded:

```bash
curl http://127.0.0.1:8000/monitoring/health
```

Expected response should show all modules as healthy:
```json
{
  "status": "healthy",
  "modules": {
    "collections": "healthy",
    "resources": "healthy",
    "search": "healthy",
    "annotations": "healthy",
    "scholarly": "healthy",
    "authority": "healthy",
    "curation": "healthy",
    "quality": "healthy",
    "taxonomy": "healthy",
    "graph": "healthy",
    "recommendations": "healthy",
    "monitoring": "healthy"
  },
  "event_bus": {
    "status": "healthy",
    "handlers_registered": 12
  }
}
```

### Run Tests

```bash
pytest tests/ -v
```

## Understanding the Module Structure

### Phase 14 Architecture

Neo Alexandria uses a **vertical slice architecture** where each feature is a self-contained module:

```
app/
â”œâ”€â”€ shared/              # Shared kernel (no business logic)
â”‚   â”œâ”€â”€ database.py      # Database session management
â”‚   â”œâ”€â”€ event_bus.py     # Event-driven communication
â”‚   â”œâ”€â”€ base_model.py    # Base SQLAlchemy model
â”‚   â”œâ”€â”€ embeddings.py    # Embedding generation service
â”‚   â”œâ”€â”€ ai_core.py       # AI/ML operations
â”‚   â””â”€â”€ cache.py         # Caching service
â””â”€â”€ modules/             # 13 self-contained modules
    â”œâ”€â”€ collections/     # Collection management
    â”œâ”€â”€ resources/       # Resource CRUD
    â”œâ”€â”€ search/          # Hybrid search
    â”œâ”€â”€ annotations/     # Text highlights & notes
    â”œâ”€â”€ scholarly/       # Academic metadata
    â”œâ”€â”€ authority/       # Subject authority
    â”œâ”€â”€ curation/        # Content review
    â”œâ”€â”€ quality/         # Quality assessment
    â”œâ”€â”€ taxonomy/        # ML classification
    â”œâ”€â”€ graph/           # Knowledge graph & citations
    â”œâ”€â”€ recommendations/ # Hybrid recommendations
    â””â”€â”€ monitoring/      # System health & metrics
```

### Module Standard Structure

Each module follows this pattern:

```
modules/{module_name}/
â”œâ”€â”€ __init__.py      # Public interface
â”œâ”€â”€ router.py        # API endpoints
â”œâ”€â”€ service.py       # Business logic
â”œâ”€â”€ schema.py        # Pydantic models
â”œâ”€â”€ model.py         # SQLAlchemy models (optional)
â”œâ”€â”€ handlers.py      # Event handlers
â””â”€â”€ README.md        # Documentation
```

### Key Principles

1. **Module Independence**: Modules don't import from each other
2. **Event-Driven**: Modules communicate via events, not direct calls
3. **Shared Kernel**: Common infrastructure (database, events, cache) in `shared/`
4. **Standard Structure**: All modules follow the same layout
5. **Self-Contained**: Each module has its own router, service, schema, and tests

## Database Configuration

### SQLite (Default)

No additional setup required. Database file created automatically.

```bash
DATABASE_URL=sqlite:///backend.db
```

### PostgreSQL (Production)

1. Install PostgreSQL 15+
2. Create database:
```bash
createdb neo_alexandria
```
3. Update `.env`:
```bash
DATABASE_URL=postgresql://user:password@localhost:5432/neo_alexandria
```
4. Run migrations:
```bash
alembic upgrade head
```

## AI Model Setup

Models are downloaded automatically on first use. To pre-download:

```python
from transformers import AutoModel, AutoTokenizer

# Embedding model
AutoModel.from_pretrained("nomic-ai/nomic-embed-text-v1")
AutoTokenizer.from_pretrained("nomic-ai/nomic-embed-text-v1")

# Summarization model
AutoModel.from_pretrained("facebook/bart-large-cnn")
AutoTokenizer.from_pretrained("facebook/bart-large-cnn")
```

## IDE Setup

### VS Code

Recommended extensions:
- Python
- Pylance
- Black Formatter
- isort

Settings (`.vscode/settings.json`):
```json
{
  "python.defaultInterpreterPath": ".venv/bin/python",
  "python.formatting.provider": "black",
  "editor.formatOnSave": true,
  "[python]": {
    "editor.codeActionsOnSave": {
      "source.organizeImports": true
    }
  }
}
```

### PyCharm

1. Set interpreter to `.venv/bin/python`
2. Enable Black formatter
3. Configure pytest as test runner

## Common Issues

### Import Errors

Ensure virtual environment is activated:
```bash
source .venv/bin/activate
which python  # Should show .venv path
```

### Module Not Loading

Check application startup logs for module registration:
```bash
uvicorn app.main:app --reload --log-level debug
```

Look for lines like:
```
INFO: âœ“ Registered router for module: collections
INFO: âœ“ Registered event handlers for module: collections
```

If a module fails to load, check:
1. Module `__init__.py` exists and exports correctly
2. No circular imports within the module
3. All dependencies are installed

### Database Locked (SQLite)

SQLite doesn't support concurrent writes. For development:
- Use single process
- Or switch to PostgreSQL

### Model Download Fails

Check internet connection and disk space. Models require ~2GB.

### Memory Errors

AI models require significant RAM. Options:
- Increase system RAM to 8GB+
- Use smaller models
- Disable AI features for testing

### Event Handlers Not Firing

Check that event handlers are registered during startup:
```bash
curl http://127.0.0.1:8000/monitoring/events
```

Should show events being emitted and delivered. If not:
1. Verify `register_handlers()` is called in module `__init__.py`
2. Check application logs for handler registration errors
3. Ensure event types match exactly (case-sensitive)

## Next Steps

- [Development Workflows](workflows.md) - Common tasks and module development patterns
- [Testing Guide](testing.md) - Running tests
- [Migration Guide](../MIGRATION_GUIDE.md) - Understanding the modular architecture
- [API Documentation](../api/) - API reference

## Related Documentation

- [Architecture Overview](../architecture/overview.md) - System architecture and module structure
- [Module Documentation](../architecture/modules.md) - Complete module reference
- [Event System](../architecture/event-system.md) - Event-driven communication patterns
- [Database Configuration](../architecture/database.md)
- [Troubleshooting](troubleshooting.md)



<div style='page-break-after: always;'></div>

---



# 26. Development Workflows

*Source: `backend/docs/guides/workflows.md`*

---

# Development Workflows

Common development tasks and patterns for Neo Alexandria 2.0.

> **Phase 14 Complete**: This guide reflects the fully modular vertical slice architecture with 13 self-contained modules, enhanced shared kernel, and event-driven communication patterns.

## Quick Reference

### Module Structure
All modules follow a standard structure:
```
modules/{module_name}/
â”œâ”€â”€ __init__.py      # Public interface
â”œâ”€â”€ router.py        # API endpoints
â”œâ”€â”€ service.py       # Business logic
â”œâ”€â”€ schema.py        # Pydantic models
â”œâ”€â”€ model.py         # SQLAlchemy models (optional)
â”œâ”€â”€ handlers.py      # Event handlers
â””â”€â”€ README.md        # Documentation
```

### Current Modules (13 Total)
1. **collections** - Collection management
2. **resources** - Resource CRUD operations
3. **search** - Hybrid search (keyword + semantic)
4. **annotations** - Text highlights and notes
5. **scholarly** - Academic metadata extraction
6. **authority** - Subject authority control
7. **curation** - Content review and batch operations
8. **quality** - Multi-dimensional quality assessment
9. **taxonomy** - ML-based classification
10. **graph** - Knowledge graph and citations
11. **recommendations** - Hybrid recommendation engine
12. **monitoring** - System health and metrics

### Shared Kernel Services
- **database.py** - Database session management
- **event_bus.py** - Event-driven communication
- **base_model.py** - Base SQLAlchemy model
- **embeddings.py** - Embedding generation (dense & sparse)
- **ai_core.py** - AI/ML operations (summarization, entity extraction)
- **cache.py** - Caching service with TTL support

## Code Quality

### Formatting

```bash
# Format with Black
black backend/

# Sort imports
isort backend/

# Both at once
black backend/ && isort backend/
```

### Linting

```bash
# Lint with Ruff
ruff check backend/

# Auto-fix issues
ruff check backend/ --fix

# Type checking
mypy backend/app/
```

### Pre-commit Hooks

Install pre-commit hooks:
```bash
pre-commit install
```

Run manually:
```bash
pre-commit run --all-files
```

## Database Management

### Create Migration

```bash
cd backend
alembic revision --autogenerate -m "Add new field to resources"
```

### Apply Migrations

```bash
alembic upgrade head
```

### Rollback Migration

```bash
# Rollback one step
alembic downgrade -1

# Rollback to specific revision
alembic downgrade abc123
```

### Check Current Version

```bash
alembic current
```

### View Migration History

```bash
alembic history
```

## Module Development Patterns

### Using Shared Kernel Services

#### Embedding Generation

```python
# In your module service
from app.shared.embeddings import EmbeddingService

class MyModuleService:
    def __init__(self, db: Session):
        self.db = db
        self.embedding_service = EmbeddingService()
    
    def process_text(self, text: str):
        # Generate dense embedding
        embedding = self.embedding_service.generate_embedding(text)
        
        # Generate sparse embedding (SPLADE)
        sparse_embedding = self.embedding_service.generate_sparse_embedding(text)
        
        # Batch generation
        embeddings = self.embedding_service.batch_generate([text1, text2, text3])
```

#### AI/ML Operations

```python
# In your module service
from app.shared.ai_core import AICore

class MyModuleService:
    def __init__(self, db: Session):
        self.db = db
        self.ai_core = AICore()
    
    def process_content(self, text: str):
        # Generate summary
        summary = self.ai_core.summarize(text)
        
        # Extract entities
        entities = self.ai_core.extract_entities(text)
        
        # Zero-shot classification
        labels = ["science", "technology", "business"]
        scores = self.ai_core.classify_text(text, labels)
```

#### Caching

```python
# In your module service
from app.shared.cache import CacheService

class MyModuleService:
    def __init__(self, db: Session):
        self.db = db
        self.cache = CacheService()
    
    def get_expensive_data(self, key: str):
        # Try cache first
        cached = self.cache.get(f"mymodule:{key}")
        if cached:
            return cached
        
        # Compute if not cached
        data = self._compute_expensive_operation(key)
        
        # Cache with TTL (seconds)
        self.cache.set(f"mymodule:{key}", data, ttl=3600)
        return data
    
    def invalidate_cache(self, pattern: str):
        # Invalidate by pattern
        self.cache.invalidate(f"mymodule:{pattern}*")
```

### Event-Driven Communication

#### Emitting Events

```python
# In your module service
from app.shared.event_bus import event_bus

class MyModuleService:
    def create_item(self, db: Session, data: ItemCreate):
        # Create item
        item = MyItem(**data.dict())
        db.add(item)
        db.commit()
        db.refresh(item)
        
        # Emit event for other modules
        event_bus.emit("mymodule.item_created", {
            "item_id": str(item.id),
            "name": item.name,
            "timestamp": datetime.now(timezone.utc).isoformat()
        })
        
        return item
```

#### Subscribing to Events

```python
# In your module handlers.py
from app.shared.event_bus import event_bus
from app.shared.database import SessionLocal
from .service import MyModuleService

def handle_resource_created(payload: dict):
    """Handle resource creation event."""
    resource_id = payload.get("resource_id")
    
    # Create fresh database session
    db = SessionLocal()
    try:
        service = MyModuleService(db)
        service.process_new_resource(resource_id)
    except Exception as e:
        logger.error(f"Error handling resource.created: {e}", exc_info=True)
    finally:
        db.close()

def register_handlers():
    """Register all event handlers for this module."""
    event_bus.subscribe("resource.created", handle_resource_created)
    event_bus.subscribe("resource.updated", handle_resource_updated)
```

#### Event Handler Best Practices

1. **Always create fresh database sessions** in handlers
2. **Always close sessions** in finally block
3. **Catch exceptions** - don't let one handler break others
4. **Log errors** with full traceback
5. **Keep handlers fast** (<100ms) - offload heavy work to Celery
6. **Make handlers idempotent** - safe to run multiple times

```python
def handle_event(payload: dict):
    """Example handler with best practices."""
    from app.shared.database import SessionLocal
    
    db = SessionLocal()
    try:
        # Process event
        service = MyService(db)
        service.process(payload)
        
        logger.info(f"Successfully processed event: {payload}")
    except Exception as e:
        logger.error(f"Error processing event: {e}", exc_info=True)
        # Don't re-raise - let other handlers continue
    finally:
        db.close()
```

## Adding New Features

### 1. Create Module (Vertical Slice)

```bash
mkdir -p app/modules/new_feature
touch app/modules/new_feature/__init__.py
touch app/modules/new_feature/router.py
touch app/modules/new_feature/service.py
touch app/modules/new_feature/schema.py
touch app/modules/new_feature/model.py
touch app/modules/new_feature/handlers.py
touch app/modules/new_feature/README.md
```

### 2. Define Model

```python
# app/modules/new_feature/model.py
from app.shared.base_model import BaseModel
from sqlalchemy import Column, String, Text

class NewFeature(BaseModel):
    __tablename__ = "new_features"
    
    name = Column(String(255), nullable=False)
    description = Column(Text)
```

### 3. Create Schema

```python
# app/modules/new_feature/schema.py
from pydantic import BaseModel
from typing import Optional
from uuid import UUID

class NewFeatureCreate(BaseModel):
    name: str
    description: Optional[str] = None

class NewFeatureResponse(BaseModel):
    id: UUID
    name: str
    description: Optional[str]
    
    class Config:
        from_attributes = True
```

### 4. Implement Service

```python
# app/modules/new_feature/service.py
from sqlalchemy.orm import Session
from .model import NewFeature
from .schema import NewFeatureCreate
from app.shared.event_bus import event_bus

class NewFeatureService:
    def __init__(self, db: Session):
        self.db = db
    
    def create_feature(self, data: NewFeatureCreate) -> NewFeature:
        feature = NewFeature(**data.dict())
        self.db.add(feature)
        self.db.commit()
        self.db.refresh(feature)
        
        # Publish event
        event_bus.emit("new_feature.created", {
            "id": str(feature.id),
            "name": feature.name
        })
        
        return feature
```

### 5. Create Router

```python
# app/modules/new_feature/router.py
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.shared.database import get_db
from .service import NewFeatureService
from .schema import NewFeatureCreate, NewFeatureResponse

router = APIRouter(prefix="/new-features", tags=["new-features"])

@router.post("/", response_model=NewFeatureResponse)
def create(data: NewFeatureCreate, db: Session = Depends(get_db)):
    service = NewFeatureService(db)
    return service.create_feature(data)
```

### 6. Create Event Handlers

```python
# app/modules/new_feature/handlers.py
from app.shared.event_bus import event_bus
from app.shared.database import SessionLocal
from .service import NewFeatureService

def handle_external_event(payload: dict):
    """Handle events from other modules."""
    db = SessionLocal()
    try:
        service = NewFeatureService(db)
        service.process_event(payload)
    except Exception as e:
        logger.error(f"Error handling event: {e}", exc_info=True)
    finally:
        db.close()

def register_handlers():
    """Register all event handlers for this module."""
    event_bus.subscribe("external.event", handle_external_event)
```

### 7. Create Public Interface

```python
# app/modules/new_feature/__init__.py
"""New Feature Module - Public Interface"""

__version__ = "1.0.0"
__domain__ = "new_feature"

from .router import router as new_feature_router
from .service import NewFeatureService
from .schema import NewFeatureCreate, NewFeatureResponse
from .handlers import register_handlers

__all__ = [
    "new_feature_router",
    "NewFeatureService",
    "NewFeatureCreate",
    "NewFeatureResponse",
    "register_handlers",
]
```

### 8. Register Module

Add to `app/__init__.py`:

```python
modules = [
    # Existing modules
    ("collections", "backend.app.modules.collections", "collections_router"),
    ("resources", "backend.app.modules.resources", "resources_router"),
    ("search", "backend.app.modules.search", "search_router"),
    
    # New module
    ("new_feature", "backend.app.modules.new_feature", "new_feature_router"),
]
```

### 9. Create Migration

```bash
alembic revision --autogenerate -m "Add new_features table"
alembic upgrade head
```

### 10. Write Tests

```python
# app/modules/new_feature/tests/test_service.py
import pytest
from app.modules.new_feature.service import NewFeatureService
from app.modules.new_feature.schema import NewFeatureCreate

def test_create_feature(db_session):
    service = NewFeatureService(db_session)
    data = NewFeatureCreate(name="Test", description="Test description")
    
    feature = service.create_feature(data)
    
    assert feature.name == "Test"
    assert feature.description == "Test description"
    assert feature.id is not None
```

## Adding API Endpoints

### GET Endpoint

```python
@router.get("/{item_id}", response_model=ItemResponse)
def get_item(item_id: UUID, db: Session = Depends(get_db)):
    service = ItemService(db)
    item = service.get_item(item_id)
    if not item:
        raise HTTPException(status_code=404, detail="Item not found")
    return item
```

### POST Endpoint

```python
@router.post("/", response_model=ItemResponse, status_code=201)
def create_item(data: ItemCreate, db: Session = Depends(get_db)):
    service = ItemService(db)
    return service.create_item(data)
```

### PUT Endpoint

```python
@router.put("/{item_id}", response_model=ItemResponse)
def update_item(
    item_id: UUID,
    data: ItemUpdate,
    db: Session = Depends(get_db)
):
    service = ItemService(db)
    item = service.update_item(item_id, data)
    if not item:
        raise HTTPException(status_code=404, detail="Item not found")
    return item
```

### DELETE Endpoint

```python
@router.delete("/{item_id}", status_code=204)
def delete_item(item_id: UUID, db: Session = Depends(get_db)):
    service = ItemService(db)
    success = service.delete_item(item_id)
    if not success:
        raise HTTPException(status_code=404, detail="Item not found")
```

## Debugging

### Enable Debug Logging

```bash
LOG_LEVEL=DEBUG uvicorn app.main:app --reload
```

### Database Query Logging

```python
# In settings or main.py
import logging
logging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)
```

### Event Bus Debugging

Check event metrics:
```bash
curl http://localhost:8000/monitoring/events
```

View event history:
```bash
curl http://localhost:8000/monitoring/events/history
```

### Interactive Debugging

```python
# Add breakpoint in code
import pdb; pdb.set_trace()

# Or use VS Code debugger with launch.json
```

### Module Isolation Validation

Check for circular dependencies:
```bash
python backend/scripts/check_module_isolation.py
```

This will detect:
- Direct imports between modules
- Circular dependencies
- Violations of module boundaries

## Common Patterns

### Async Background Tasks

For long-running operations, use Celery:

```python
# In your service
from app.tasks.celery_tasks import process_heavy_task

def trigger_processing(self, item_id: str):
    # Queue task for background processing
    process_heavy_task.delay(item_id)
    return {"status": "queued"}
```

### Pagination

```python
from fastapi import Query

@router.get("/items")
def list_items(
    skip: int = Query(0, ge=0),
    limit: int = Query(25, ge=1, le=100),
    db: Session = Depends(get_db)
):
    service = ItemService(db)
    items = service.list_items(skip=skip, limit=limit)
    total = service.count_items()
    
    return {
        "items": items,
        "total": total,
        "skip": skip,
        "limit": limit
    }
```

### Error Handling

```python
from fastapi import HTTPException

def get_item(self, item_id: str):
    item = self.db.query(Item).filter(Item.id == item_id).first()
    if not item:
        raise HTTPException(
            status_code=404,
            detail=f"Item {item_id} not found"
        )
    return item
```

## Related Documentation

- [Setup Guide](setup.md) - Installation
- [Testing Guide](testing.md) - Running tests
- [Architecture](../architecture/) - System design
- [Migration Guide](../MIGRATION_GUIDE.md) - Understanding the modular architecture
- [Event System](../architecture/event-system.md) - Event-driven patterns



<div style='page-break-after: always;'></div>

---



# 27. Testing Guide

*Source: `backend/docs/guides/testing.md`*

---

# Testing Guide

Testing strategies and practices for Neo Alexandria 2.0.

## Running Tests

### All Tests

```bash
cd backend
pytest tests/ -v
```

### With Coverage

```bash
pytest tests/ --cov=app --cov-report=html
```

Coverage report generated in `htmlcov/index.html`

### Specific Test File

```bash
pytest tests/test_resources.py -v
```

### Specific Test Function

```bash
pytest tests/test_resources.py::test_create_resource -v
```

### By Marker

```bash
# Run only unit tests
pytest tests/ -m unit -v

# Run only integration tests
pytest tests/ -m integration -v

# Run PostgreSQL-specific tests
pytest tests/ -m postgresql -v
```

## Test Structure

```
tests/
â”œâ”€â”€ conftest.py              # Shared fixtures
â”œâ”€â”€ unit/                    # Unit tests
â”‚   â”œâ”€â”€ test_services.py
â”‚   â”œâ”€â”€ test_schemas.py
â”‚   â””â”€â”€ test_domain.py
â”œâ”€â”€ integration/             # Integration tests
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_database.py
â”‚   â””â”€â”€ test_events.py
â””â”€â”€ performance/             # Performance tests
    â””â”€â”€ test_benchmarks.py
```

## Test Fixtures

### Database Session

```python
# conftest.py
import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.database.base import Base

@pytest.fixture(scope="session")
def db_engine():
    """Create test database engine."""
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    yield engine
    Base.metadata.drop_all(engine)

@pytest.fixture
def db_session(db_engine):
    """Create test database session."""
    Session = sessionmaker(bind=db_engine)
    session = Session()
    yield session
    session.rollback()
    session.close()
```

### Test Client

```python
@pytest.fixture
def client(db_session):
    """Create test API client."""
    from fastapi.testclient import TestClient
    from app.main import app
    from app.shared.database import get_db
    
    def override_get_db():
        yield db_session
    
    app.dependency_overrides[get_db] = override_get_db
    yield TestClient(app)
    app.dependency_overrides.clear()
```

### Sample Data

```python
@pytest.fixture
def sample_resource(db_session):
    """Create sample resource for testing."""
    from app.modules.resources.model import Resource
    
    resource = Resource(
        title="Test Resource",
        description="Test description",
        source="https://example.com/test"
    )
    db_session.add(resource)
    db_session.commit()
    db_session.refresh(resource)
    return resource
```

## Writing Tests

### Unit Tests

Test individual functions in isolation:

```python
# tests/unit/test_quality_service.py
import pytest
from app.services.quality_service import compute_accuracy_score

def test_compute_accuracy_score_with_citations():
    """Test accuracy score with valid citations."""
    resource = MockResource(
        citations=["https://doi.org/10.1234/test"],
        source="https://arxiv.org/paper"
    )
    
    score = compute_accuracy_score(resource)
    
    assert 0.0 <= score <= 1.0
    assert score > 0.5  # Should be above baseline

def test_compute_accuracy_score_no_citations():
    """Test accuracy score without citations."""
    resource = MockResource(citations=[], source="https://example.com")
    
    score = compute_accuracy_score(resource)
    
    assert score == 0.5  # Baseline score
```

### Integration Tests

Test API endpoints end-to-end:

```python
# tests/integration/test_resources_api.py
def test_create_resource(client):
    """Test resource creation via API."""
    response = client.post(
        "/resources",
        json={"url": "https://example.com/article"}
    )
    
    assert response.status_code == 202
    data = response.json()
    assert "id" in data
    assert data["status"] == "pending"

def test_get_resource(client, sample_resource):
    """Test resource retrieval via API."""
    response = client.get(f"/resources/{sample_resource.id}")
    
    assert response.status_code == 200
    data = response.json()
    assert data["title"] == sample_resource.title

def test_get_resource_not_found(client):
    """Test 404 for non-existent resource."""
    response = client.get("/resources/00000000-0000-0000-0000-000000000000")
    
    assert response.status_code == 404
```

### Event Tests

Test event publishing and handling:

```python
# tests/integration/test_events.py
from app.shared.event_bus import event_bus, Event

def test_resource_deleted_updates_collections(db_session, sample_resource, sample_collection):
    """Test that deleting a resource updates collections."""
    # Add resource to collection
    add_resource_to_collection(db_session, sample_collection.id, sample_resource.id)
    
    # Delete resource (triggers event)
    delete_resource(db_session, sample_resource.id)
    
    # Verify collection updated
    collection = get_collection(db_session, sample_collection.id)
    assert sample_resource.id not in [r.id for r in collection.resources]
```

### Database Tests

Test with different databases:

```python
# tests/test_postgresql.py
import pytest

@pytest.mark.postgresql
def test_jsonb_containment_query(db_session):
    """Test PostgreSQL JSONB containment query."""
    # Create resource with subjects
    resource = Resource(
        title="ML Paper",
        subject=["Machine Learning", "AI"]
    )
    db_session.add(resource)
    db_session.commit()
    
    # Query using JSONB containment
    results = db_session.query(Resource).filter(
        Resource.subject.contains(["Machine Learning"])
    ).all()
    
    assert len(results) == 1
    assert results[0].id == resource.id
```

## Test Configuration

### pytest.ini

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_functions = test_*
markers =
    unit: Unit tests
    integration: Integration tests
    postgresql: PostgreSQL-specific tests
    slow: Slow tests
addopts = -v --tb=short
```

### Environment Variables

```bash
# Use in-memory SQLite for tests
TEST_DATABASE_URL=sqlite:///:memory:

# Or test against PostgreSQL
TEST_DATABASE_URL=postgresql://user:pass@localhost:5432/test_db
```

## Mocking

### Mock External Services

```python
from unittest.mock import Mock, patch

def test_ingestion_with_mock_http(db_session):
    """Test ingestion with mocked HTTP client."""
    with patch('httpx.get') as mock_get:
        mock_get.return_value = Mock(
            status_code=200,
            text="<html><body>Test content</body></html>"
        )
        
        result = ingest_url(db_session, "https://example.com/test")
        
        assert result.title is not None
        mock_get.assert_called_once()
```

### Mock AI Models

```python
def test_classification_with_mock_model(db_session):
    """Test classification with mocked ML model."""
    with patch('app.services.ml_classification_service.model') as mock_model:
        mock_model.predict.return_value = [
            {"label": "Computer Science", "score": 0.95}
        ]
        
        result = classify_resource(db_session, resource_id)
        
        assert result.classification_code == "004"
```

## Performance Testing

```python
# tests/performance/test_benchmarks.py
import pytest
import time

@pytest.mark.slow
def test_search_performance(client, many_resources):
    """Test search completes within time limit."""
    start = time.time()
    
    response = client.post(
        "/search",
        json={"text": "machine learning", "limit": 100}
    )
    
    elapsed = time.time() - start
    
    assert response.status_code == 200
    assert elapsed < 0.5  # Should complete in <500ms
```

## CI/CD Integration

### GitHub Actions

```yaml
# .github/workflows/test.yml
name: Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - run: pip install -r requirements.txt
      - run: pytest tests/ --cov=app --cov-report=xml
      - uses: codecov/codecov-action@v3
```

## Related Documentation

- [Setup Guide](setup.md) - Installation
- [Workflows](workflows.md) - Development tasks
- [Troubleshooting](troubleshooting.md) - Common issues


<div style='page-break-after: always;'></div>

---



# 28. Deployment Guide

*Source: `backend/docs/guides/deployment.md`*

---

# Deployment Guide

Docker and production deployment for Neo Alexandria 2.0.

## Docker Deployment

### Quick Start

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

### Docker Compose Configuration

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/neo_alexandria
    depends_on:
      - db
    volumes:
      - ./storage:/app/storage

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=neo_alexandria
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:
```

### Dockerfile

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Run with Gunicorn
CMD ["gunicorn", "app.main:app", "-c", "gunicorn.conf.py"]
```

### Build and Run

```bash
# Build image
docker build -t neo-alexandria .

# Run container
docker run -d \
  -p 8000:8000 \
  -e DATABASE_URL=postgresql://user:pass@host:5432/db \
  -v $(pwd)/storage:/app/storage \
  neo-alexandria
```

## Production Configuration

### Gunicorn Settings

```python
# gunicorn.conf.py
bind = "0.0.0.0:8000"
workers = 4  # (2 * CPU cores) + 1
worker_class = "uvicorn.workers.UvicornWorker"
timeout = 120
keepalive = 5
max_requests = 1000
max_requests_jitter = 50
accesslog = "-"
errorlog = "-"
loglevel = "info"
```

### Environment Variables

```bash
# Production .env
DATABASE_URL=postgresql://user:password@host:5432/neo_alexandria
DEBUG=false
LOG_LEVEL=WARNING

# AI Models
EMBEDDING_MODEL_NAME=nomic-ai/nomic-embed-text-v1
SUMMARIZER_MODEL=facebook/bart-large-cnn

# Search
DEFAULT_HYBRID_SEARCH_WEIGHT=0.5
EMBEDDING_CACHE_SIZE=5000

# Security (future)
# API_KEY_REQUIRED=true
# CORS_ORIGINS=https://your-domain.com
```

### PostgreSQL Production Setup

```bash
# Create database
createdb neo_alexandria

# Create user with limited privileges
psql -c "CREATE USER neo_app WITH PASSWORD 'secure_password';"
psql -c "GRANT CONNECT ON DATABASE neo_alexandria TO neo_app;"
psql -c "GRANT USAGE ON SCHEMA public TO neo_app;"
psql -c "GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO neo_app;"

# Run migrations
DATABASE_URL=postgresql://neo_app:secure_password@localhost:5432/neo_alexandria \
  alembic upgrade head
```

## Reverse Proxy (Nginx)

```nginx
# /etc/nginx/sites-available/neo-alexandria
server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;

    ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket support (if needed)
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # Static files (if any)
    location /static {
        alias /app/static;
        expires 30d;
    }
}
```

## Systemd Service

```ini
# /etc/systemd/system/neo-alexandria.service
[Unit]
Description=Neo Alexandria API
After=network.target postgresql.service

[Service]
User=neo-app
Group=neo-app
WorkingDirectory=/opt/neo-alexandria
Environment="PATH=/opt/neo-alexandria/.venv/bin"
Environment="DATABASE_URL=postgresql://user:pass@localhost:5432/neo_alexandria"
ExecStart=/opt/neo-alexandria/.venv/bin/gunicorn app.main:app -c gunicorn.conf.py
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
```

```bash
# Enable and start service
sudo systemctl enable neo-alexandria
sudo systemctl start neo-alexandria
sudo systemctl status neo-alexandria
```

## Health Checks

### Kubernetes Probes

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /monitoring/status
    port: 8000
  initialDelaySeconds: 5
  periodSeconds: 5
```

### Docker Health Check

```dockerfile
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1
```

## Backup Strategy

### Automated PostgreSQL Backup

```bash
#!/bin/bash
# /opt/neo-alexandria/scripts/backup.sh

BACKUP_DIR=/var/backups/neo-alexandria
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# Create backup
pg_dump -h localhost -U postgres neo_alexandria | gzip > $BACKUP_DIR/backup_$DATE.sql.gz

# Remove old backups
find $BACKUP_DIR -name "backup_*.sql.gz" -mtime +$RETENTION_DAYS -delete
```

```bash
# Cron job (daily at 2 AM)
0 2 * * * /opt/neo-alexandria/scripts/backup.sh
```

### Storage Backup

```bash
# Backup storage directory
rsync -avz /opt/neo-alexandria/storage/ /backup/storage/
```

## Monitoring

### Prometheus Metrics (Planned)

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'neo-alexandria'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: /metrics
```

### Log Aggregation

```bash
# Send logs to centralized logging
docker-compose logs -f | logger -t neo-alexandria
```

## Scaling

### Horizontal Scaling

```yaml
# docker-compose.scale.yml
services:
  api:
    deploy:
      replicas: 3
    
  nginx:
    image: nginx
    ports:
      - "80:80"
    depends_on:
      - api
```

### Database Connection Pooling

For high-traffic deployments, use PgBouncer:

```ini
# pgbouncer.ini
[databases]
neo_alexandria = host=localhost dbname=neo_alexandria

[pgbouncer]
listen_port = 6432
listen_addr = 127.0.0.1
pool_mode = transaction
max_client_conn = 1000
default_pool_size = 20
```

## Related Documentation

- [Setup Guide](setup.md) - Development setup
- [Database Architecture](../architecture/database.md) - Database configuration
- [Troubleshooting](troubleshooting.md) - Common issues


<div style='page-break-after: always;'></div>

---



# 29. Troubleshooting

*Source: `backend/docs/guides/troubleshooting.md`*

---

# Troubleshooting Guide

Common issues and solutions for Neo Alexandria 2.0.

## Installation Issues

### Import Errors

**Symptom:** `ModuleNotFoundError: No module named 'app'`

**Solution:**
```bash
# Ensure virtual environment is activated
source .venv/bin/activate

# Verify Python path
which python  # Should show .venv/bin/python

# Reinstall dependencies
pip install -r requirements.txt
```

### Dependency Conflicts

**Symptom:** `ERROR: Cannot install package due to conflicting dependencies`

**Solution:**
```bash
# Create fresh virtual environment
rm -rf .venv
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Model Download Fails

**Symptom:** `OSError: Can't load tokenizer for 'nomic-ai/nomic-embed-text-v1'`

**Solution:**
```bash
# Check internet connection
ping huggingface.co

# Check disk space (models need ~2GB)
df -h

# Try manual download
python -c "from transformers import AutoModel; AutoModel.from_pretrained('nomic-ai/nomic-embed-text-v1')"
```

## Database Issues

### Database Locked (SQLite)

**Symptom:** `sqlite3.OperationalError: database is locked`

**Cause:** SQLite doesn't support concurrent writes.

**Solutions:**
1. Use single process for development
2. Switch to PostgreSQL for multi-user scenarios
3. Increase timeout:
```python
connect_args={"timeout": 30}
```

### Migration Fails

**Symptom:** `alembic.util.exc.CommandError: Can't locate revision`

**Solution:**
```bash
# Check current state
alembic current

# Stamp to known state
alembic stamp head

# Re-run migrations
alembic upgrade head
```

### Connection Pool Exhausted

**Symptom:** `QueuePool limit of size X overflow Y reached`

**Solution:**
```python
# Increase pool size in database configuration
postgresql_params = {
    'pool_size': 30,      # Increase from 20
    'max_overflow': 60,   # Increase from 40
}
```

### PostgreSQL Connection Refused

**Symptom:** `psycopg2.OperationalError: could not connect to server`

**Solution:**
```bash
# Check PostgreSQL is running
sudo systemctl status postgresql

# Check connection string
psql -h localhost -U postgres -d neo_alexandria

# Verify pg_hba.conf allows connections
sudo cat /etc/postgresql/15/main/pg_hba.conf
```

## API Issues

### 422 Validation Error

**Symptom:** `{"detail":[{"loc":["body","field"],"msg":"field required"}]}`

**Solution:**
- Check request body matches schema
- Verify Content-Type header is `application/json`
- Check for typos in field names

### 500 Internal Server Error

**Symptom:** Generic server error with no details

**Solution:**
```bash
# Enable debug mode
DEBUG=true uvicorn app.main:app --reload

# Check application logs
tail -f /var/log/neo-alexandria/error.log
```

### Slow API Responses

**Symptom:** Requests take >1 second

**Solutions:**
1. Check database query performance:
```sql
EXPLAIN ANALYZE SELECT * FROM resources WHERE ...;
```

2. Add missing indexes:
```sql
CREATE INDEX idx_resources_subject ON resources USING GIN (subject);
```

3. Enable query logging:
```python
import logging
logging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)
```

## Search Issues

### No Search Results

**Symptom:** Search returns empty results for known content

**Solutions:**
1. Check FTS5 index exists:
```sql
SELECT * FROM resources_fts;
```

2. Rebuild search index:
```bash
python -c "from app.services.search_service import rebuild_fts_index; rebuild_fts_index()"
```

3. Verify embeddings exist:
```sql
SELECT COUNT(*) FROM resources WHERE embedding IS NOT NULL;
```

### Search Quality Issues

**Symptom:** Irrelevant results ranked highly

**Solutions:**
1. Adjust hybrid weight:
```json
{"text": "query", "hybrid_weight": 0.7}  // More semantic
{"text": "query", "hybrid_weight": 0.3}  // More keyword
```

2. Check embedding model is loaded:
```python
from app.services.ai_core import AICore
ai = AICore()
print(ai.embedding_model)  # Should not be None
```

## AI/ML Issues

### Out of Memory

**Symptom:** `RuntimeError: CUDA out of memory` or system OOM

**Solutions:**
1. Reduce batch size:
```python
batch_size = 8  # Reduce from 32
```

2. Use CPU instead of GPU:
```python
device = "cpu"  # Instead of "cuda"
```

3. Increase system RAM to 8GB+

### Model Loading Slow

**Symptom:** First request takes 30+ seconds

**Cause:** Models loaded lazily on first use.

**Solutions:**
1. Pre-load models at startup:
```python
# In main.py
@app.on_event("startup")
async def load_models():
    ai_core = AICore()
    ai_core.load_embedding_model()
```

2. Use smaller models for development

### Classification Accuracy Low

**Symptom:** ML classification gives wrong categories

**Solutions:**
1. Retrain with more labeled data
2. Adjust confidence threshold:
```python
min_confidence = 0.5  # Increase from 0.3
```

3. Use active learning to improve model

## Event System Issues

### Events Not Firing

**Symptom:** Event handlers not called

**Solutions:**
1. Verify handler is registered:
```python
print(event_bus._subscribers)  # Check handlers
```

2. Check for exceptions in handlers:
```python
def handle_event(event):
    try:
        # handler code
    except Exception as e:
        logger.error(f"Handler error: {e}")
```

### Circular Import Errors

**Symptom:** `ImportError: cannot import name 'X' from partially initialized module`

**Solution:**
- Use string-based relationships in models
- Import inside functions, not at module level
- Use event bus instead of direct imports

## Performance Issues

### High CPU Usage

**Symptom:** CPU at 100% during normal operation

**Solutions:**
1. Profile the application:
```python
import cProfile
cProfile.run('function_to_profile()')
```

2. Check for infinite loops in event handlers
3. Optimize database queries

### High Memory Usage

**Symptom:** Memory grows over time

**Solutions:**
1. Check for memory leaks:
```python
import tracemalloc
tracemalloc.start()
# ... run code ...
snapshot = tracemalloc.take_snapshot()
```

2. Clear embedding cache periodically
3. Use streaming for large responses

## Docker Issues

### Container Won't Start

**Symptom:** Container exits immediately

**Solution:**
```bash
# Check logs
docker logs container_name

# Run interactively
docker run -it neo-alexandria /bin/bash
```

### Volume Permission Errors

**Symptom:** `PermissionError: [Errno 13] Permission denied`

**Solution:**
```bash
# Fix ownership
sudo chown -R 1000:1000 ./storage

# Or run as root (not recommended)
docker run --user root ...
```

## Getting Help

### Collect Debug Information

```bash
# System info
python --version
pip freeze > requirements_actual.txt

# Database info
alembic current
psql -c "SELECT version();"

# Application logs
tail -100 /var/log/neo-alexandria/app.log
```

### Report Issues

Include:
1. Error message and stack trace
2. Steps to reproduce
3. Environment details (OS, Python version)
4. Relevant configuration

## Related Documentation

- [Setup Guide](setup.md) - Installation
- [Testing Guide](testing.md) - Running tests
- [Deployment Guide](deployment.md) - Production setup


<div style='page-break-after: always;'></div>

---



# 30. Backend Overview

*Source: `backend/README.md`*

---

# Neo Alexandria 2.0 - Advanced Knowledge Management API

## Overview

Neo Alexandria 2.0 is a comprehensive knowledge management system that provides intelligent content processing, advanced search capabilities, and personalized recommendations through a RESTful API. The system combines traditional information retrieval with modern AI-powered features to deliver a complete solution for knowledge curation and discovery.

## Key Features

### Content Ingestion and Processing
- **Asynchronous URL Ingestion**: Submit web content for intelligent processing
- **AI-Powered Analysis**: Automatic summarization, tagging, and classification
- **Multi-Format Support**: HTML, PDF, and plain text content extraction
- **Quality Assessment**: Comprehensive content quality scoring and evaluation

### Advanced Search and Discovery
- **Hybrid Search**: Combines keyword and semantic search with configurable weighting
- **Vector Embeddings**: Semantic similarity search using state-of-the-art embedding models
- **Faceted Search**: Advanced filtering by classification, language, quality, and subjects
- **Full-Text Search**: SQLite FTS5 integration with graceful fallbacks

### Knowledge Graph and Relationships
- **Hybrid Graph Scoring**: Multi-signal relationship detection combining vector similarity, shared subjects, and classification matches
- **Mind-Map Visualization**: Resource-centric neighbor discovery for exploration
- **Global Overview**: System-wide relationship analysis and connection mapping

### Citation Network & Link Intelligence
- **Multi-Format Citation Extraction**: Automatically extract citations from HTML, PDF, and Markdown content
- **Internal Citation Resolution**: Link citations to existing resources in your library
- **PageRank Importance Scoring**: Compute citation importance using network analysis
- **Citation Graph Visualization**: Build and explore citation networks with configurable depth
- **Smart Citation Classification**: Automatically categorize citations as datasets, code, references, or general links

### Personalized Recommendations
- **Content-Based Filtering**: Learn user preferences from existing library content
- **Fresh Content Discovery**: Source and rank new content from external providers
- **Explainable Recommendations**: Provide reasoning for recommendation decisions

### Collection Management
- **Curated Collections**: Organize resources into named, thematic collections with descriptions
- **Hierarchical Organization**: Create nested collections for complex topic structures
- **Visibility Controls**: Set collections as private, shared, or public for flexible collaboration
- **Aggregate Embeddings**: Automatic semantic representation computed from member resources
- **Collection Recommendations**: Discover similar resources and collections based on semantic similarity
- **Batch Operations**: Add or remove up to 100 resources in a single request
- **Automatic Cleanup**: Collections update automatically when resources are deleted
- **Access Control**: Owner-based permissions with visibility-based read access

### Annotation & Active Reading System
- **Precise Text Highlighting**: Character-offset-based text selection with context preservation
- **Rich Note-Taking**: Add personal notes to highlights with automatic semantic embedding
- **Tag Organization**: Categorize annotations with custom tags and color-coding
- **Full-Text Search**: Search across all annotation notes and highlighted text (<100ms for 10K annotations)
- **Semantic Search**: Find conceptually related annotations using AI-powered similarity
- **Export Capabilities**: Export annotations to Markdown or JSON for external tools
- **Collection Integration**: Associate annotations with research collections
- **Privacy Controls**: Annotations are private by default with optional sharing

### Authority Control and Classification
- **Subject Normalization**: Intelligent tag standardization and canonical forms
- **Hierarchical Classification**: UDC-inspired classification system with automatic assignment
- **Usage Tracking**: Monitor and optimize metadata usage patterns

### ML-Powered Classification & Taxonomy
- **Transformer-Based Classification**: Fine-tuned BERT/DistilBERT models for accurate resource categorization
- **Hierarchical Taxonomy Management**: Create and manage multi-level category trees with parent-child relationships
- **Multi-Label Classification**: Resources can belong to multiple categories with confidence scores
- **Semi-Supervised Learning**: Train effective models with minimal labeled data (<500 examples)
- **Active Learning**: System identifies uncertain predictions for targeted human review
- **Confidence Scoring**: Every classification includes a confidence score (0.0-1.0) for transparency
- **Model Versioning**: Track and manage multiple model versions with rollback capability
- **GPU Acceleration**: Automatic GPU utilization with graceful CPU fallback
- **Continuous Improvement**: Models improve automatically through human feedback loops

## API-First Architecture

Neo Alexandria 2.0 is built with an API-first approach, enabling seamless integration with external systems and applications. The RESTful API provides comprehensive endpoints for all system functionality, making it suitable for both internal knowledge management and external service integration.

## Quick Start

### Prerequisites

- Python 3.8 or higher
- SQLite (default) or PostgreSQL database
- 4GB RAM minimum (8GB recommended for AI features)

### Installation

1. **Clone the repository and navigate to the project directory**

2. **Create a virtual environment**
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r backend/requirements.txt
```

4. **Run database migrations**
```bash
cd backend
alembic upgrade head
```

5. **Start the API server**
```bash
uvicorn backend.app.main:app --reload
```

The API will be available at `http://127.0.0.1:8000`

### First API Call

Test the API by ingesting your first resource:

```bash
curl -X POST http://127.0.0.1:8000/resources \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com/article"}'
```

## API Documentation

### Base URL
```
http://127.0.0.1:8000
```

### Authentication
Currently, no authentication is required for development and testing. Future releases will include API key authentication and rate limiting.

### Core Endpoints

#### Content Management
- `POST /resources` - Ingest new content from URLs
- `GET /resources` - List resources with filtering and pagination
- `GET /resources/{id}` - Retrieve specific resource details
- `PUT /resources/{id}` - Update resource metadata
- `DELETE /resources/{id}` - Remove resources
- `GET /resources/{id}/status` - Check ingestion status

#### Search and Discovery
- `POST /search` - Advanced search with hybrid keyword/semantic capabilities
- `GET /search/three-way-hybrid` - Three-way hybrid search with RRF and reranking
- `GET /search/compare-methods` - Compare different search methods side-by-side
- `POST /search/evaluate` - Evaluate search quality with IR metrics
- `POST /admin/sparse-embeddings/generate` - Batch generate sparse embeddings
- `GET /recommendations` - Get personalized content recommendations

#### Knowledge Graph
- `GET /graph/resource/{id}/neighbors` - Find related resources for mind-map visualization
- `GET /graph/overview` - Get global relationship overview

#### Citation Network
- `GET /citations/resources/{id}/citations` - Get citations for a resource (inbound/outbound)
- `GET /citations/graph/citations` - Get citation network for visualization
- `POST /citations/resources/{id}/citations/extract` - Trigger citation extraction
- `POST /citations/resolve` - Resolve internal citations
- `POST /citations/importance/compute` - Compute PageRank importance scores

#### Collection Management
- `POST /collections` - Create a new collection
- `GET /collections/{id}` - Retrieve collection details with member resources
- `PUT /collections/{id}` - Update collection metadata
- `DELETE /collections/{id}` - Delete collection and subcollections
- `GET /collections` - List collections with filtering and pagination
- `POST /collections/{id}/resources` - Add resources to collection
- `DELETE /collections/{id}/resources` - Remove resources from collection
- `GET /collections/{id}/recommendations` - Get similar resources and collections
- `GET /collections/{id}/embedding` - Retrieve collection aggregate embedding

#### Annotation Management
- `POST /resources/{resource_id}/annotations` - Create annotation on resource
- `GET /resources/{resource_id}/annotations` - List resource annotations
- `GET /annotations` - List user annotations with pagination
- `GET /annotations/{id}` - Retrieve specific annotation
- `PUT /annotations/{id}` - Update annotation note, tags, or color
- `DELETE /annotations/{id}` - Delete annotation
- `GET /annotations/search/fulltext` - Full-text search across annotations
- `GET /annotations/search/semantic` - Semantic search with similarity scores
- `GET /annotations/search/tags` - Tag-based annotation search
- `GET /annotations/export/markdown` - Export annotations to Markdown
- `GET /annotations/export/json` - Export annotations to JSON

#### Authority and Classification
- `GET /authority/subjects/suggest` - Get subject suggestions for autocomplete
- `GET /authority/classification/tree` - Retrieve hierarchical classification structure

#### Taxonomy Management (Phase 8.5)
- `POST /taxonomy/nodes` - Create new taxonomy node
- `PUT /taxonomy/nodes/{node_id}` - Update taxonomy node metadata
- `DELETE /taxonomy/nodes/{node_id}` - Delete taxonomy node (with cascade option)
- `POST /taxonomy/nodes/{node_id}/move` - Move node to different parent
- `GET /taxonomy/tree` - Retrieve hierarchical taxonomy tree
- `GET /taxonomy/nodes/{node_id}/ancestors` - Get ancestor nodes (breadcrumb trail)
- `GET /taxonomy/nodes/{node_id}/descendants` - Get all descendant nodes

#### ML Classification (Phase 8.5)
- `POST /taxonomy/classify/{resource_id}` - Classify resource using ML model
- `GET /taxonomy/active-learning/uncertain` - Get uncertain predictions for review
- `POST /taxonomy/active-learning/feedback` - Submit human classification feedback
- `POST /taxonomy/train` - Initiate model fine-tuning with training data

#### Curation and Quality Control
- `GET /curation/review-queue` - Access low-quality items for review
- `POST /curation/batch-update` - Apply batch updates to multiple resources

## Data Models

### Resource Model
The core data model follows Dublin Core metadata standards with custom extensions:

```json
{
  "id": "uuid",
  "title": "string",
  "description": "string",
  "creator": "string",
  "publisher": "string",
  "source": "string",
  "language": "string",
  "type": "string",
  "subject": ["string"],
  "classification_code": "string",
  "quality_score": 0.85,
  "read_status": "unread",
  "created_at": "2024-01-01T00:00:00Z",
  "updated_at": "2024-01-01T00:00:00Z"
}
```

### Search Request Model
```json
{
  "text": "search query",
  "hybrid_weight": 0.5,
  "filters": {
    "classification_code": ["004"],
    "language": ["en"],
    "min_quality": 0.7,
    "subject_any": ["Machine Learning"]
  },
  "limit": 25,
  "offset": 0,
  "sort_by": "relevance",
  "sort_dir": "desc"
}
```

### Recommendation Response Model
```json
{
  "items": [
    {
      "url": "https://example.com/article",
      "title": "Article Title",
      "snippet": "Brief description...",
      "relevance_score": 0.85,
      "reasoning": ["Aligned with Machine Learning, Python"]
    }
  ]
}
```

## Configuration

### Database Configuration

Neo Alexandria 2.0 supports both SQLite and PostgreSQL databases. Choose the appropriate database based on your deployment scenario:

#### SQLite (Development)
- **Use Case**: Local development, testing, small deployments
- **Advantages**: Zero configuration, file-based, portable
- **Limitations**: Limited concurrency, no advanced features
- **Configuration**:
  ```bash
  DATABASE_URL=sqlite:///./backend.db
  ```

#### PostgreSQL (Production)
- **Use Case**: Production deployments, high concurrency, large datasets
- **Advantages**: Advanced indexing, JSONB support, full-text search, high concurrency
- **Requirements**: PostgreSQL 15 or higher
- **Configuration**:
  ```bash
  DATABASE_URL=postgresql://user:password@host:5432/database
  ```

#### Database Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `DATABASE_URL` | Yes | `sqlite:///./backend.db` | Primary database connection string |
| `TEST_DATABASE_URL` | No | `sqlite:///:memory:` | Test database connection string (overrides default test database) |
| `ENV` | No | `dev` | Environment name (`dev`, `staging`, `prod`) |

#### Database URL Format

**SQLite:**
```bash
# File-based database
DATABASE_URL=sqlite:///./backend.db

# In-memory database (testing only)
DATABASE_URL=sqlite:///:memory:

# Absolute path
DATABASE_URL=sqlite:////absolute/path/to/database.db
```

**PostgreSQL:**
```bash
# Basic connection
DATABASE_URL=postgresql://username:password@hostname:5432/database_name

# With SSL (recommended for production)
DATABASE_URL=postgresql://username:password@hostname:5432/database_name?sslmode=require

# With connection pool parameters
DATABASE_URL=postgresql://username:password@hostname:5432/database_name?pool_size=20&max_overflow=40
```

#### Environment-Specific Configuration Files

Neo Alexandria provides example configuration files for different environments:

- **`.env.development`** - Local development with SQLite
- **`.env.staging`** - Staging environment with PostgreSQL
- **`.env.production`** - Production environment with PostgreSQL

Copy the appropriate file to `.env` and customize for your environment:

```bash
# For local development
cp .env.development .env

# For staging
cp .env.staging .env
# Edit .env and update database credentials

# For production
cp .env.production .env
# Edit .env and update database credentials
```

#### Testing with Different Databases

By default, tests use in-memory SQLite for speed. To test against PostgreSQL:

```bash
# Set TEST_DATABASE_URL in your .env file
TEST_DATABASE_URL=postgresql://user:password@localhost:5432/test_db

# Or set it inline when running tests
TEST_DATABASE_URL=postgresql://user:password@localhost:5432/test_db pytest backend/tests/
```

#### Database Migration

When switching from SQLite to PostgreSQL or vice versa:

1. **Run migrations** to ensure schema is up to date:
   ```bash
   cd backend
   alembic upgrade head
   ```

2. **Migrate data** (if switching databases):
   ```bash
   # SQLite to PostgreSQL (forward migration)
   python backend/scripts/migrate_sqlite_to_postgresql.py \
     --source sqlite:///./backend.db \
     --target postgresql://user:password@host:5432/database \
     --validate
   
   # PostgreSQL to SQLite (rollback/reverse migration)
   python backend/scripts/migrate_postgresql_to_sqlite.py \
     --source postgresql://user:password@host:5432/database \
     --target sqlite:///./backend.db \
     --validate
   ```

3. **Verify migration** by checking row counts and running tests

#### Rollback Procedures

If you need to rollback from PostgreSQL to SQLite:

1. **Stop the application**:
   ```bash
   # Docker Compose
   docker-compose down
   
   # Or kill the process
   pkill -f "uvicorn backend.app.main:app"
   ```

2. **Restore SQLite backup** (if available):
   ```bash
   cp backend.db.backup backend.db
   ```

3. **Or run reverse migration** (if no backup):
   ```bash
   python backend/scripts/migrate_postgresql_to_sqlite.py \
     --source postgresql://user:password@host:5432/database \
     --target sqlite:///./backend.db \
     --validate
   ```

4. **Update environment configuration**:
   ```bash
   # Update .env file
   DATABASE_URL=sqlite:///./backend.db
   ```

5. **Restart the application**:
   ```bash
   uvicorn backend.app.main:app --reload
   ```

**âš ï¸ Important Rollback Limitations:**
- JSONB columns are converted to JSON text (no binary optimization)
- PostgreSQL full-text search vectors are not migrated (FTS5 must be rebuilt)
- Some PostgreSQL-specific indexes cannot be recreated in SQLite
- Array types are converted to JSON arrays

For detailed rollback procedures and troubleshooting, see:
- **[PostgreSQL Migration Guide](backend/docs/POSTGRESQL_MIGRATION_GUIDE.md)** - Complete migration and rollback procedures
- **[SQLite Compatibility Maintenance](backend/docs/SQLITE_COMPATIBILITY_MAINTENANCE.md)** - Maintaining compatibility during transition

#### Connection Pool Configuration

PostgreSQL connection pooling is automatically configured with optimal defaults:

- **Pool Size**: 20 base connections
- **Max Overflow**: 40 additional connections for burst traffic
- **Pool Recycle**: 3600 seconds (1 hour)
- **Pool Pre-Ping**: Enabled (validates connections before use)

Monitor connection pool usage via the monitoring endpoint:
```bash
curl http://localhost:8000/monitoring/database
```

### Environment Variables
```bash
# Database Configuration
DATABASE_URL=sqlite:///backend.db
TEST_DATABASE_URL=sqlite:///:memory:

# AI Model Configuration
EMBEDDING_MODEL_NAME=nomic-ai/nomic-embed-text-v1
SUMMARIZER_MODEL=facebook/bart-large-cnn
TAGGER_MODEL=facebook/bart-large-mnli

# Search Configuration
DEFAULT_HYBRID_SEARCH_WEIGHT=0.5
EMBEDDING_CACHE_SIZE=1000

# Recommendation Configuration
RECOMMENDATION_PROFILE_SIZE=50
RECOMMENDATION_KEYWORD_COUNT=5
RECOMMENDATION_CANDIDATES_PER_KEYWORD=10
SEARCH_PROVIDER=ddgs
SEARCH_TIMEOUT=10

# Graph Configuration
GRAPH_WEIGHT_VECTOR=0.6
GRAPH_WEIGHT_TAGS=0.3
GRAPH_WEIGHT_CLASSIFICATION=0.1
GRAPH_VECTOR_MIN_SIM_THRESHOLD=0.85
```

## Error Handling

The API uses standard HTTP status codes and returns structured error responses:

```json
{
  "detail": "Error description",
  "error_code": "VALIDATION_ERROR",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

### Common Status Codes
- `200 OK` - Successful request
- `202 Accepted` - Request accepted for processing
- `400 Bad Request` - Invalid request parameters
- `404 Not Found` - Resource not found
- `422 Unprocessable Entity` - Validation error
- `500 Internal Server Error` - Server error

## Rate Limits

Currently, no rate limits are enforced. Future releases will implement:
- 1000 requests per hour per API key
- 100 ingestion requests per hour per API key
- Burst allowance for short-term spikes

## Examples

### Basic Content Ingestion
```bash
# Submit URL for processing
curl -X POST http://127.0.0.1:8000/resources \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com/machine-learning-guide"}'

# Check processing status
curl http://127.0.0.1:8000/resources/{resource_id}/status

# Retrieve processed resource
curl http://127.0.0.1:8000/resources/{resource_id}
```

### Advanced Search
```bash
# Hybrid search with semantic similarity
curl -X POST http://127.0.0.1:8000/search \
  -H "Content-Type: application/json" \
  -d '{
    "text": "artificial intelligence algorithms",
    "hybrid_weight": 0.7,
    "filters": {
      "min_quality": 0.8,
      "subject_any": ["Machine Learning", "AI"]
    },
    "limit": 10
  }'
```

### Knowledge Graph Exploration
```bash
# Find related resources for mind-map
curl "http://127.0.0.1:8000/graph/resource/{resource_id}/neighbors?limit=7"

# Get global relationship overview
curl "http://127.0.0.1:8000/graph/overview?limit=50&vector_threshold=0.85"
```

### Personalized Recommendations
```bash
# Get content recommendations
curl "http://127.0.0.1:8000/recommendations?limit=10"
```

### Collection Management
```bash
# Create a new collection
curl -X POST http://127.0.0.1:8000/collections \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Machine Learning Papers",
    "description": "Curated collection of ML research",
    "visibility": "public"
  }'

# Add resources to collection
curl -X POST http://127.0.0.1:8000/collections/{collection_id}/resources \
  -H "Content-Type: application/json" \
  -d '{
    "resource_ids": [
      "550e8400-e29b-41d4-a716-446655440000",
      "660e8400-e29b-41d4-a716-446655440001"
    ]
  }'

# Get collection with member resources
curl "http://127.0.0.1:8000/collections/{collection_id}"

# Get recommendations based on collection
curl "http://127.0.0.1:8000/collections/{collection_id}/recommendations?limit=10"

# Create nested collection
curl -X POST http://127.0.0.1:8000/collections \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Deep Learning Subset",
    "parent_id": "{parent_collection_id}",
    "visibility": "public"
  }'
```

### Annotation and Active Reading
```bash
# Create annotation on a resource
curl -X POST http://127.0.0.1:8000/resources/{resource_id}/annotations \
  -H "Content-Type: application/json" \
  -d '{
    "start_offset": 150,
    "end_offset": 200,
    "highlighted_text": "This is the key finding of the paper",
    "note": "Important result - contradicts previous assumptions",
    "tags": ["key-finding", "methodology"],
    "color": "#FFD700"
  }'

# Search annotations semantically
curl "http://127.0.0.1:8000/annotations/search/semantic?query=machine+learning+algorithms&limit=10"

# Export annotations to Markdown
curl "http://127.0.0.1:8000/annotations/export/markdown?resource_id={resource_id}"

# List all user annotations
curl "http://127.0.0.1:8000/annotations?limit=50&sort_by=recent"
```

### Three-Way Hybrid Search (Phase 8)
```bash
# Three-way hybrid search with reranking
curl -X GET "http://127.0.0.1:8000/search/three-way-hybrid?query=machine+learning&limit=20&enable_reranking=true&adaptive_weighting=true"

# Compare all search methods side-by-side
curl -X GET "http://127.0.0.1:8000/search/compare-methods?query=neural+networks&limit=10"

# Evaluate search quality with metrics
curl -X POST http://127.0.0.1:8000/search/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "query": "deep learning",
    "relevance_judgments": {
      "resource_id_1": 3,
      "resource_id_2": 2,
      "resource_id_3": 1
    }
  }'

# Generate sparse embeddings for existing resources
curl -X POST http://127.0.0.1:8000/admin/sparse-embeddings/generate \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 32}'

# Three-way search without reranking (faster)
curl -X GET "http://127.0.0.1:8000/search/three-way-hybrid?query=artificial+intelligence&limit=20&enable_reranking=false"

# Three-way search with custom weighting (disable adaptive)
curl -X GET "http://127.0.0.1:8000/search/three-way-hybrid?query=data+science&limit=20&adaptive_weighting=false"
```

### ML Classification & Taxonomy Management (Phase 8.5)
```bash
# Create a taxonomy node
curl -X POST http://127.0.0.1:8000/taxonomy/nodes \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Machine Learning",
    "description": "ML and deep learning topics",
    "keywords": ["neural networks", "deep learning"],
    "allow_resources": true
  }'

# Create a child node
curl -X POST http://127.0.0.1:8000/taxonomy/nodes \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Deep Learning",
    "parent_id": "{parent_node_id}",
    "description": "Neural networks with multiple layers"
  }'

# Get the full taxonomy tree
curl "http://127.0.0.1:8000/taxonomy/tree"

# Get a subtree starting from a specific node
curl "http://127.0.0.1:8000/taxonomy/tree?root_id={node_id}&max_depth=3"

# Get ancestors (breadcrumb trail)
curl "http://127.0.0.1:8000/taxonomy/nodes/{node_id}/ancestors"

# Get all descendants
curl "http://127.0.0.1:8000/taxonomy/nodes/{node_id}/descendants"

# Move a node to a different parent
curl -X POST http://127.0.0.1:8000/taxonomy/nodes/{node_id}/move \
  -H "Content-Type: application/json" \
  -d '{"new_parent_id": "{new_parent_id}"}'

# Classify a resource using ML
curl -X POST "http://127.0.0.1:8000/taxonomy/classify/{resource_id}"

# Get uncertain predictions for human review
curl "http://127.0.0.1:8000/taxonomy/active-learning/uncertain?limit=50"

# Submit human feedback on classification
curl -X POST http://127.0.0.1:8000/taxonomy/active-learning/feedback \
  -H "Content-Type: application/json" \
  -d '{
    "resource_id": "{resource_id}",
    "correct_taxonomy_ids": ["{node_id_1}", "{node_id_2}"]
  }'

# Train/fine-tune the ML model
curl -X POST http://127.0.0.1:8000/taxonomy/train \
  -H "Content-Type: application/json" \
  -d '{
    "labeled_data": [
      {
        "text": "Introduction to neural networks and backpropagation",
        "taxonomy_ids": ["{ml_node_id}", "{dl_node_id}"]
      }
    ],
    "unlabeled_texts": [
      "Article about convolutional neural networks",
      "Tutorial on recurrent neural networks"
    ],
    "epochs": 3,
    "batch_size": 16
  }'
```

## Testing

Run the comprehensive test suite:

```bash
# All tests
pytest backend/tests/ -v

# With coverage reporting
pytest backend/tests/ --cov=backend --cov-report=html

# Specific test categories
pytest backend/tests/ -m "recommendation"  # Recommendation system tests
pytest backend/tests/ -m "integration"     # Integration tests
```

## Development Phases

### Phase 0: Foundation
- Database schema and models
- Migration system
- Configuration management

### Phase 1: Content Ingestion
- URL processing and content extraction
- Basic metadata extraction
- Local content archiving

### Phase 2: CRUD Operations
- Resource management endpoints
- Curation workflows
- Batch operations

### Phase 3: Search and Discovery
- Full-text search with FTS5
- Faceted search capabilities
- Advanced filtering

### Phase 3.5: AI Integration
- Asynchronous processing
- AI-powered summarization and tagging
- Quality assessment algorithms

### Phase 4: Vector Search
- Semantic embeddings
- Hybrid search fusion
- Vector similarity search

### Phase 5: Knowledge Graph
- Relationship detection
- Graph-based exploration
- Mind-map visualization

### Phase 5.5: Recommendations
- Personalized content recommendations
- External content sourcing
- Explainable recommendation reasoning

### Phase 6: Citation Network & Link Intelligence âœ…
- Citation extraction from HTML, PDF, and Markdown
- Internal citation resolution (link resources together)
- PageRank-style importance scoring
- Citation graph visualization endpoints
- Integration with knowledge graph service

### Phase 6.5: Advanced Metadata Extraction & Scholarly Processing âœ…
- Fine-tuned metadata extraction for academic papers (authors, DOI, affiliations, funding)
- Mathematical equation extraction with LaTeX format preservation
- Table extraction with structure preservation (camelot-py + tabula-py)
- Figure/image extraction with caption detection
- OCR processing for scanned PDFs with error correction
- Metadata validation and completeness scoring
- Scholarly metadata API endpoints for comprehensive access
- Integration with quality service for metadata quality scoring

### Phase 7: Collection Management âœ…
- User-curated collections for organizing resources into thematic groups
- Hierarchical collection organization with parent/child relationships
- Flexible visibility controls (private, shared, public) for collaboration
- Aggregate embedding computation for collection-level semantic representation
- Intelligent recommendations based on collection similarity
- Resource membership management with batch operations
- Automatic collection updates when resources are deleted
- Integration with existing search and recommendation infrastructure

### Phase 7.5: Annotation & Active Reading System âœ…
- Character-offset-based text highlighting with precise positioning
- Rich annotation notes with automatic semantic embedding generation
- Tag-based organization with color-coding for visual categorization
- Full-text search across notes and highlighted text (<100ms for 10K annotations)
- Semantic search using cosine similarity for conceptual discovery
- Markdown and JSON export for integration with external note-taking tools
- Collection integration for project-based annotation organization
- Privacy-first design with optional annotation sharing
- Performance: <50ms annotation creation, <500ms semantic search, <2s export for 1K annotations

### Phase 8: Three-Way Hybrid Search with Sparse Vectors & Reranking âœ…
- Sparse vector embeddings using BGE-M3 model for learned keyword representations
- Three-way retrieval combining FTS5, dense vectors, and sparse vectors
- Reciprocal Rank Fusion (RRF) for score-agnostic result merging
- Query-adaptive weighting that automatically adjusts method importance
- ColBERT-style cross-encoder reranking for maximum precision
- Comprehensive search metrics (nDCG, Recall, Precision, MRR)
- Method comparison endpoints for debugging and optimization
- Batch sparse embedding generation with progress tracking
- Performance: <200ms three-way search, <1s reranking, 30%+ nDCG improvement

### Phase 8: Three-Way Hybrid Search with Sparse Vectors & Reranking âœ…
- Sparse vector embeddings using BGE-M3 model for learned keyword representations
- Three-way retrieval combining FTS5, dense vectors, and sparse vectors
- Reciprocal Rank Fusion (RRF) for score-agnostic result merging
- Query-adaptive weighting that automatically adjusts method importance
- ColBERT-style cross-encoder reranking for maximum precision
- Comprehensive search metrics (nDCG, Recall, Precision, MRR)
- Method comparison endpoints for debugging and optimization
- Batch sparse embedding generation with progress tracking
- Performance: <200ms three-way search, <1s reranking, 30%+ nDCG improvement

### Phase 8.5: ML Classification & Hierarchical Taxonomy âœ…
- Transformer-based classification using fine-tuned BERT/DistilBERT models
- Hierarchical taxonomy tree with unlimited depth and parent-child relationships
- Multi-label classification with confidence scores (0.0-1.0) for each category
- Semi-supervised learning to leverage unlabeled data with <500 labeled examples
- Active learning workflow to identify uncertain predictions for human review
- Materialized path pattern for efficient ancestor/descendant queries
- Model versioning and checkpoint management for rollback capability
- GPU acceleration support with automatic CPU fallback
- Automatic classification during resource ingestion pipeline
- Performance: <100ms inference, F1 score >0.85, 60%+ reduction in labeling effort

## Production Deployment

### System Requirements
- **CPU**: 4+ cores recommended
- **RAM**: 8GB minimum, 16GB recommended for AI features
- **Storage**: SSD recommended for database performance (minimum 20GB free space)
- **Network**: Stable internet connection for content ingestion
- **Database**: PostgreSQL 15+ for production (SQLite for development)

### Database Selection Guide

#### SQLite (Development & Small Deployments)
**Use Cases:**
- Local development and testing
- Single-user deployments
- Prototyping and demos
- Small datasets (<10,000 resources)

**Advantages:**
- Zero configuration required
- File-based (portable)
- No separate database server needed
- Perfect for development

**Limitations:**
- Limited concurrent writes (single writer)
- No advanced indexing (GIN, JSONB)
- File locking can cause issues under load
- Not suitable for production with multiple users

#### PostgreSQL (Production & High Concurrency)
**Use Cases:**
- Production deployments
- Multi-user environments
- High concurrency requirements (100+ simultaneous users)
- Large datasets (>10,000 resources)
- Advanced search and analytics

**Advantages:**
- Excellent concurrent write performance
- Advanced indexing (GIN indexes for JSONB, full-text search)
- Native JSONB support for efficient JSON queries
- Connection pooling with health checks
- Production-grade reliability and ACID compliance
- Point-in-time recovery and replication support

**Requirements:**
- PostgreSQL 15 or higher
- Dedicated database server or managed service (AWS RDS, Google Cloud SQL, Azure Database)
- Regular backups and monitoring

### PostgreSQL Setup for Production

#### Option 1: Docker Compose (Recommended for Development/Staging)
```bash
# Start PostgreSQL with Docker
cd backend/docker
docker-compose up -d postgres

# Verify PostgreSQL is running
docker-compose ps

# Check logs
docker-compose logs postgres
```

#### Option 2: Managed Database Service (Recommended for Production)
**AWS RDS:**
```bash
# Create PostgreSQL RDS instance
aws rds create-db-instance \
  --db-instance-identifier neo-alexandria-prod \
  --db-instance-class db.t3.medium \
  --engine postgres \
  --engine-version 15.4 \
  --master-username admin \
  --master-user-password <secure-password> \
  --allocated-storage 100 \
  --backup-retention-period 7 \
  --multi-az
```

**Google Cloud SQL:**
```bash
# Create PostgreSQL instance
gcloud sql instances create neo-alexandria-prod \
  --database-version=POSTGRES_15 \
  --tier=db-custom-2-7680 \
  --region=us-central1 \
  --backup \
  --backup-start-time=02:00
```

#### Option 3: Self-Hosted PostgreSQL
```bash
# Install PostgreSQL 15 (Ubuntu/Debian)
sudo apt update
sudo apt install postgresql-15 postgresql-contrib-15

# Create database and user
sudo -u postgres psql
CREATE DATABASE neo_alexandria;
CREATE USER neo_user WITH ENCRYPTED PASSWORD 'secure_password';
GRANT ALL PRIVILEGES ON DATABASE neo_alexandria TO neo_user;
\q
```

### Migration from SQLite to PostgreSQL

**Prerequisites:**
- Backup your SQLite database
- PostgreSQL 15+ installed and running
- Python environment with all dependencies

**Migration Steps:**
```bash
# 1. Backup SQLite database
cp backend.db backend.db.backup

# 2. Set up PostgreSQL connection
export DATABASE_URL="postgresql://user:password@host:5432/database"

# 3. Run schema migrations
cd backend
alembic upgrade head

# 4. Migrate data from SQLite to PostgreSQL
python scripts/migrate_sqlite_to_postgresql.py \
  --source sqlite:///./backend.db \
  --target postgresql://user:password@host:5432/database \
  --validate

# 5. Verify migration
# Check row counts match between source and target

# 6. Update environment configuration
# Edit .env file
DATABASE_URL=postgresql://user:password@host:5432/database

# 7. Restart application
uvicorn backend.app.main:app --host 0.0.0.0 --port 8000
```

**Migration Validation:**
```bash
# Compare row counts
python -c "
from sqlalchemy import create_engine, inspect
sqlite_engine = create_engine('sqlite:///./backend.db')
pg_engine = create_engine('postgresql://user:password@host:5432/database')

for table in inspect(sqlite_engine).get_table_names():
    sqlite_count = sqlite_engine.execute(f'SELECT COUNT(*) FROM {table}').scalar()
    pg_count = pg_engine.execute(f'SELECT COUNT(*) FROM {table}').scalar()
    print(f'{table}: SQLite={sqlite_count}, PostgreSQL={pg_count}')
"
```

### Database Backup Strategy

#### PostgreSQL Backups
```bash
# Full database backup
pg_dump -h localhost -U postgres -d neo_alexandria > backup_$(date +%Y%m%d).sql

# Compressed backup
pg_dump -h localhost -U postgres -d neo_alexandria | gzip > backup_$(date +%Y%m%d).sql.gz

# Custom format (supports parallel restore)
pg_dump -h localhost -U postgres -d neo_alexandria -Fc > backup_$(date +%Y%m%d).dump
```

**Automated Backup Script:**
```bash
# Use the provided backup script
chmod +x backend/scripts/backup_postgresql.sh
./backend/scripts/backup_postgresql.sh

# Schedule with cron (daily at 2 AM)
crontab -e
0 2 * * * /path/to/backend/scripts/backup_postgresql.sh
```

**Backup Retention Policy:**
- Daily backups: Keep for 7 days
- Weekly backups: Keep for 4 weeks
- Monthly backups: Keep for 12 months

#### SQLite Backups
```bash
# Simple file copy
cp backend.db backend.db.backup_$(date +%Y%m%d)

# Using SQLite backup command
sqlite3 backend.db ".backup 'backend.db.backup_$(date +%Y%m%d)'"
```

### Monitoring and Performance

#### Connection Pool Monitoring
```bash
# Check connection pool status
curl http://localhost:8000/monitoring/database

# Response includes:
# - database_type: "postgresql" or "sqlite"
# - pool_size: 20 (PostgreSQL)
# - connections_in_use: current active connections
# - connections_available: idle connections
# - overflow_connections: connections beyond pool_size
```

#### Performance Tuning (PostgreSQL)
```sql
-- Check slow queries
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

-- Check index usage
SELECT schemaname, tablename, indexname, idx_scan
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY idx_scan DESC;

-- Check cache hit ratio (should be >90%)
SELECT 
  sum(heap_blks_read) as heap_read,
  sum(heap_blks_hit) as heap_hit,
  sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) as ratio
FROM pg_statio_user_tables;
```

### Rollback Procedures

If you need to rollback from PostgreSQL to SQLite:

```bash
# 1. Stop the application
pkill -f "uvicorn backend.app.main:app"

# 2. Run reverse migration
python backend/scripts/migrate_postgresql_to_sqlite.py \
  --source postgresql://user:password@host:5432/database \
  --target sqlite:///./backend.db \
  --validate

# 3. Update environment
DATABASE_URL=sqlite:///./backend.db

# 4. Restart application
uvicorn backend.app.main:app --reload
```

**âš ï¸ Rollback Limitations:**
- JSONB columns converted to JSON text (no binary optimization)
- PostgreSQL full-text search vectors not migrated (FTS5 must be rebuilt)
- Some PostgreSQL-specific indexes cannot be recreated in SQLite
- Performance may degrade for large datasets

### Security Considerations
- **Database Security:**
  - Use strong passwords for database users
  - Enable SSL/TLS for database connections in production
  - Restrict database access to application servers only
  - Regular security updates for PostgreSQL
  
- **Application Security:**
  - API key authentication (future release)
  - Rate limiting and abuse prevention
  - Input validation and sanitization
  - Secure content storage and access controls

### Additional Resources
- **[PostgreSQL Migration Guide](backend/docs/POSTGRESQL_MIGRATION_GUIDE.md)** - Complete migration procedures
- **[PostgreSQL Backup Guide](backend/docs/POSTGRESQL_BACKUP_GUIDE.md)** - Backup and recovery procedures
- **[SQLite Compatibility Guide](backend/docs/SQLITE_COMPATIBILITY_MAINTENANCE.md)** - Maintaining compatibility
- **[Developer Guide](backend/docs/DEVELOPER_GUIDE.md)** - Database configuration details

## Support and Documentation

### Comprehensive Documentation
- **[API Reference](docs/API_DOCUMENTATION.md)** - Complete endpoint documentation
- **[Developer Guide](docs/DEVELOPER_GUIDE.md)** - Architecture and development setup
- **[Examples](docs/EXAMPLES.md)** - Practical usage examples and tutorials
- **[Changelog](docs/CHANGELOG.md)** - Version history and release notes

### Community and Support
- GitHub Issues for bug reports and feature requests
- Documentation updates and improvements
- Community contributions and feedback

## License

This project is licensed under the MIT License. See the LICENSE file for details.

## Contributing

We welcome contributions to Neo Alexandria 2.0. Please see our contributing guidelines in the documentation for details on:
- Code style and standards
- Testing requirements
- Documentation standards
- Pull request process

## Roadmap

### Upcoming Features
- API key authentication and rate limiting
- Advanced analytics and reporting
- Multi-user support and permissions
- Enhanced recommendation algorithms
- Real-time collaboration features
- Mobile API optimizations

### Long-term Vision
- Distributed knowledge graph federation
- Advanced AI model integration
- Enterprise-grade security and compliance
- Scalable cloud deployment options
- Integration with popular knowledge management tools

<div style='page-break-after: always;'></div>

---

